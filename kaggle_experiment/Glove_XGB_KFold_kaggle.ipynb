{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KenObata/TISMIR_notebooks/blob/main/Glove_XGB_KFold_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS8WVxEoWZG0"
      },
      "source": [
        "## This notebook uses Glove word matrix-> SMOTE. \n",
        "\n",
        "Dataset: kaggle 250,000 songs\n",
        "Situation: English only (=multi-class).\n",
        "\n",
        "Split: StratifiedKfold.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFKYiMJngx30"
      },
      "source": [
        "### set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X4EVNJYgx30",
        "outputId": "168de325-ad93-4cc9-bee7-6c6b608402f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 7.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U1jBXvpvgx31"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from collections import Counter\n",
        "\n",
        "from skmultilearn.model_selection import IterativeStratification   \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K6VTlTxg8JVQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWxfNJqYBfjD"
      },
      "source": [
        "### Data Preparation(Kfold split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbT7Qs4whnTX"
      },
      "source": [
        "Create dataframe for Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "OFZz5Xp0gx32",
        "outputId": "b01dea50-30e6-4381-9ca4-737a9cc1e1eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Genre                                             Lyrics\n",
              "0       Hip-Hop  Most folks spend their days daydreaming of fin...\n",
              "1         Indie  Take your cold hands and put them on my face\\n...\n",
              "2         Metal  Are you ready it's time for war\\nWe'll break d...\n",
              "3           Pop  You ask me why I change the color of my hair\\n...\n",
              "4       Hip-Hop  Do you believe in magic in a young girl's hear...\n",
              "...         ...                                                ...\n",
              "258117      R&B  I'm the best friend he's got I'd give him the ...\n",
              "258118      Pop  Bad Boys Blue \"I Totally Miss You\" I did you w...\n",
              "258119      Pop  Forgive me for the things That I never said to...\n",
              "258120    Indie  The day they found a cure for AIDS The day the...\n",
              "258121      Pop  Fourth of July has come, it's custom that we g...\n",
              "\n",
              "[258122 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85229404-2e8c-4710-a3d9-abc4649bd3cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Genre</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Most folks spend their days daydreaming of fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Indie</td>\n",
              "      <td>Take your cold hands and put them on my face\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Metal</td>\n",
              "      <td>Are you ready it's time for war\\nWe'll break d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pop</td>\n",
              "      <td>You ask me why I change the color of my hair\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Do you believe in magic in a young girl's hear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258117</th>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>I'm the best friend he's got I'd give him the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258118</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Bad Boys Blue \"I Totally Miss You\" I did you w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258119</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Forgive me for the things That I never said to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258120</th>\n",
              "      <td>Indie</td>\n",
              "      <td>The day they found a cure for AIDS The day the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258121</th>\n",
              "      <td>Pop</td>\n",
              "      <td>Fourth of July has come, it's custom that we g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>258122 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85229404-2e8c-4710-a3d9-abc4649bd3cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85229404-2e8c-4710-a3d9-abc4649bd3cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85229404-2e8c-4710-a3d9-abc4649bd3cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "df_genre_by_lang = pd.read_csv(DIR + 'kaggle/df_kaggle.csv')\n",
        "df_genre_by_lang = df_genre_by_lang.drop(columns = ['Unnamed: 0'])\n",
        "df_genre_by_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PrRidTBHhmYp"
      },
      "outputs": [],
      "source": [
        "def load_data(df_col, y):\n",
        "    texts, labels = [], []\n",
        "    \n",
        "    for line in df_col:\n",
        "        # texts are already tokenized, just split on space\n",
        "        # in a real use-case we would put more effort in preprocessing\n",
        "        texts.append(line.split(' '))\n",
        "    return pd.DataFrame({'texts': texts, 'labels': y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n5VJWiA6iJu2"
      },
      "outputs": [],
      "source": [
        "data = load_data(df_genre_by_lang[\"Lyrics\"], df_genre_by_lang[\"Genre\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "bWI4V7oXiWw6",
        "outputId": "05dba4d3-dfc0-4e4c-b5e7-eb3f04277140"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    texts   labels\n",
              "0       [Most, folks, spend, their, days, daydreaming,...  Hip-Hop\n",
              "1       [Take, your, cold, hands, and, put, them, on, ...    Indie\n",
              "2       [Are, you, ready, it's, time, for, war\\nWe'll,...    Metal\n",
              "3       [You, ask, me, why, I, change, the, color, of,...      Pop\n",
              "4       [Do, you, believe, in, magic, in, a, young, gi...  Hip-Hop\n",
              "...                                                   ...      ...\n",
              "258117  [I'm, the, best, friend, he's, got, I'd, give,...      R&B\n",
              "258118  [Bad, Boys, Blue, \"I, Totally, Miss, You\", I, ...      Pop\n",
              "258119  [Forgive, me, for, the, things, That, I, never...      Pop\n",
              "258120  [The, day, they, found, a, cure, for, AIDS, Th...    Indie\n",
              "258121  [Fourth, of, July, has, come,, it's, custom, t...      Pop\n",
              "\n",
              "[258122 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af925cb0-80cc-46fa-98be-b66668541e88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Most, folks, spend, their, days, daydreaming,...</td>\n",
              "      <td>Hip-Hop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Take, your, cold, hands, and, put, them, on, ...</td>\n",
              "      <td>Indie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Are, you, ready, it's, time, for, war\\nWe'll,...</td>\n",
              "      <td>Metal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[You, ask, me, why, I, change, the, color, of,...</td>\n",
              "      <td>Pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Do, you, believe, in, magic, in, a, young, gi...</td>\n",
              "      <td>Hip-Hop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258117</th>\n",
              "      <td>[I'm, the, best, friend, he's, got, I'd, give,...</td>\n",
              "      <td>R&amp;B</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258118</th>\n",
              "      <td>[Bad, Boys, Blue, \"I, Totally, Miss, You\", I, ...</td>\n",
              "      <td>Pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258119</th>\n",
              "      <td>[Forgive, me, for, the, things, That, I, never...</td>\n",
              "      <td>Pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258120</th>\n",
              "      <td>[The, day, they, found, a, cure, for, AIDS, Th...</td>\n",
              "      <td>Indie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258121</th>\n",
              "      <td>[Fourth, of, July, has, come,, it's, custom, t...</td>\n",
              "      <td>Pop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>258122 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af925cb0-80cc-46fa-98be-b66668541e88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af925cb0-80cc-46fa-98be-b66668541e88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af925cb0-80cc-46fa-98be-b66668541e88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iTROinyfjc6u"
      },
      "outputs": [],
      "source": [
        "data['labels'] = data['labels'].astype('category')\n",
        "label_mapping = data['labels'].cat.categories\n",
        "data['labels'] = data['labels'].cat.codes\n",
        "X = data['texts']\n",
        "y = data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32Ub0-kjoOj",
        "outputId": "38cc2ee6-4ac8-4498-8f7b-c417aa4982c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GnAEWk_Lza7f"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df_glove(df, feature_list, y_name):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  y = df[y_name]\n",
        "  skf.get_n_splits(df[ feature_list ], y)\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(df[ feature_list ], y):\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = df[ feature_list ].loc[train_index], df[ feature_list ].loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1qOv6pF0BcrV"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df(X, y):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  #y = df[y_name]\n",
        "  skf.get_n_splits(X, y)#df[ feature_list ]\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(X, y):#df[ feature_list ]\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGZPLOeBg4R",
        "outputId": "fb0b21cc-54d3-4c2a-e7c4-df8ebb833366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [     1      2      4 ... 258118 258120 258121] TEST: [     0      3      6 ... 258105 258112 258119]\n",
            "TRAIN: [     0      1      2 ... 258119 258120 258121] TEST: [     7     15     20 ... 258110 258113 258114]\n",
            "TRAIN: [     0      1      3 ... 258118 258119 258121] TEST: [     2      5     12 ... 258091 258116 258120]\n",
            "TRAIN: [     0      2      3 ... 258119 258120 258121] TEST: [     1      8     10 ... 258102 258106 258118]\n",
            "TRAIN: [     0      1      2 ... 258118 258119 258120] TEST: [     4     13     16 ... 258115 258117 258121]\n"
          ]
        }
      ],
      "source": [
        "#feature_list = [\"texts\"] #this is BOW and TF-IDF\n",
        "#splits = StratifiedKFold_feature_and_df( data, feature_list, 'labels')\n",
        "splits = StratifiedKFold_feature_and_df( X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsQYbmVUWPU9",
        "outputId": "e04c7583-a4d0-4db7-8292-cf4c11b9fbc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDMBs_gWCSLa",
        "outputId": "4c0be957-05fc-4109-8cbb-b6dddaec623d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(206497,)\n",
            "(206497,)\n",
            "(51625,)\n",
            "(51625,)\n"
          ]
        }
      ],
      "source": [
        "split0=splits[0]\n",
        "print(split0['X_train'].shape)\n",
        "print(split0['y_train'].shape)\n",
        "print(split0['X_test'].shape)\n",
        "print(split0['y_test'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaMmpM44is_p",
        "outputId": "bf6a7c0d-977b-4fb2-d2f7-0f2b775da592"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1         [Take, your, cold, hands, and, put, them, on, ...\n",
              "2         [Are, you, ready, it's, time, for, war\\nWe'll,...\n",
              "4         [Do, you, believe, in, magic, in, a, young, gi...\n",
              "5         [People, starin', at, me, as, they, wheel, me,...\n",
              "7         [Tell, Mel, Shawn, to, come, in\\nWord,, yo,, o...\n",
              "                                ...                        \n",
              "258116    [It's, complicated, It, always, is, That's, ju...\n",
              "258117    [I'm, the, best, friend, he's, got, I'd, give,...\n",
              "258118    [Bad, Boys, Blue, \"I, Totally, Miss, You\", I, ...\n",
              "258120    [The, day, they, found, a, cure, for, AIDS, Th...\n",
              "258121    [Fourth, of, July, has, come,, it's, custom, t...\n",
              "Name: texts, Length: 206497, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "split0['X_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qTuHLEe8Aqg",
        "outputId": "dc37c7dd-5f9f-45de-99c1-98928d4c68cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1         4\n",
              "2         6\n",
              "4         3\n",
              "5         0\n",
              "7         3\n",
              "         ..\n",
              "258116    1\n",
              "258117    8\n",
              "258118    7\n",
              "258120    4\n",
              "258121    7\n",
              "Name: labels, Length: 206497, dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "split0['y_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEwhawfYngu6",
        "outputId": "e8817186-dfc2-4f60-f13f-7b2aecc5ec38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Electronic', 2664),\n",
              " ('Country', 2700),\n",
              " ('Hip-Hop', 3198),\n",
              " ('R&B', 3273),\n",
              " ('Indie', 7750),\n",
              " ('Folk', 8660),\n",
              " ('Jazz', 13974),\n",
              " ('Metal', 19943),\n",
              " ('Pop', 87405),\n",
              " ('Rock', 108555)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "counter_origin = Counter(df_genre_by_lang['Genre'])\n",
        "counter_origin = sorted(counter_origin.items(), key= lambda k:k[1])\n",
        "counter_origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GkeM5EnnZwG",
        "outputId": "041467bc-b79a-4f53-d192-7fb4e039b6c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 2131),\n",
              " (0, 2160),\n",
              " (3, 2558),\n",
              " (8, 2618),\n",
              " (4, 6200),\n",
              " (2, 6928),\n",
              " (5, 11180),\n",
              " (6, 15954),\n",
              " (7, 69924),\n",
              " (9, 86844)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "counter_code = Counter(split0['y_train'])\n",
        "counter_code= sorted(counter_code.items(), key= lambda k:k[1])\n",
        "counter_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93MA4icMnnKV",
        "outputId": "8c85a951-c548-4dc1-cadf-1fc83a5dfe88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Country',\n",
              " 1: 'Electronic',\n",
              " 3: 'Hip-Hop',\n",
              " 8: 'R&B',\n",
              " 4: 'Indie',\n",
              " 2: 'Folk',\n",
              " 5: 'Jazz',\n",
              " 6: 'Metal',\n",
              " 7: 'Pop',\n",
              " 9: 'Rock'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "code2genre = {\n",
        "    0: 'Country'\n",
        "    , 1: 'Electronic'\n",
        "    , 3:'Hip-Hop'\n",
        "    , 8:'R&B'\n",
        "    , 4: 'Indie'\n",
        "    ,2: 'Folk'\n",
        "    ,5: 'Jazz'\n",
        "    ,6: 'Metal'\n",
        "    ,7: 'Pop'\n",
        "    ,9: 'Rock'\n",
        "}\n",
        "code2genre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTasgChQX-iM"
      },
      "source": [
        "### (Part1) Gensim Implementation\n",
        "\n",
        "Parameter\n",
        "\n",
        "sg=1 means to use skip-gram\n",
        "\n",
        "min_count... is a threashhold that the algorithm requires a word need to appear at least x time ot be considered as part of skip-gram algorithm.\n",
        "\n",
        "size... is the # of dimensions.\n",
        "\n",
        "iterations ... ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJW8_e0XImFy",
        "outputId": "9d752764-7517-459c-c95f-e33ca84549c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/music4all/glove.6B.zip\n",
            "  inflating: /content/glove.6B.50d.txt  \n",
            "  inflating: /content/glove.6B.100d.txt  \n",
            "  inflating: /content/glove.6B.200d.txt  \n",
            "  inflating: /content/glove.6B.300d.txt  \n"
          ]
        }
      ],
      "source": [
        "GLOVE_ZIP_FILE =\"drive/MyDrive/music4all/glove.6B.zip\"\n",
        "\n",
        "!unzip drive/MyDrive/music4all/glove.6B.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtSCraBK7Opu"
      },
      "source": [
        "### Gensim Word2Vec Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFMukjMDZKjW"
      },
      "source": [
        "Ref:https://datascience.stackexchange.com/questions/10695/how-to-initialize-a-new-word2vec-model-with-pre-trained-model-weights\n",
        "Ref:https://gist.github.com/AbhishekAshokDubey/054af6f92d67d5ef8300fac58f59fcc9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4yLg9w6pb3WL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from gensim.models import Word2Vec, Phrases, phrases, KeyedVectors\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "class GensimWord2VecVectorizer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Word vectors are averaged across to create the document-level vectors/features.\n",
        "    gensim's own gensim.sklearn_api.W2VTransformer doesn't support out of vocabulary words,\n",
        "    hence we roll out our own.\n",
        "    All the parameters are gensim.models.Word2Vec's parameters.\n",
        "    https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, size=100, alpha=0.025, window=5, min_count=5, max_vocab_size=None,\n",
        "                 sample=0.001, seed=1, workers=3, min_alpha=0.0001, sg=0, hs=0, negative=5,\n",
        "                 ns_exponent=0.75, cbow_mean=1, hashfxn=hash, iter=5, null_word=0,\n",
        "                 trim_rule=None, sorted_vocab=1, batch_words=10000, compute_loss=False,\n",
        "                 callbacks=(), max_final_vocab=None):\n",
        "        self.size = size\n",
        "        self.alpha = alpha\n",
        "        self.window = window\n",
        "        self.min_count = min_count\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        self.sample = sample\n",
        "        self.seed = seed\n",
        "        self.workers = workers\n",
        "        self.min_alpha = min_alpha\n",
        "        self.sg = sg\n",
        "        self.hs = hs\n",
        "        self.negative = negative\n",
        "        self.ns_exponent = ns_exponent\n",
        "        self.cbow_mean = cbow_mean\n",
        "        self.hashfxn = hashfxn\n",
        "        self.iter = iter\n",
        "        self.null_word = null_word\n",
        "        self.trim_rule = trim_rule\n",
        "        self.sorted_vocab = sorted_vocab\n",
        "        self.batch_words = batch_words\n",
        "        self.compute_loss = compute_loss\n",
        "        self.callbacks = callbacks\n",
        "        self.max_final_vocab = max_final_vocab\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.model_ = Word2Vec(\n",
        "            sentences=X, corpus_file=None,\n",
        "            size=self.size, alpha=self.alpha, window=self.window, min_count=self.min_count,\n",
        "            max_vocab_size=self.max_vocab_size, sample=self.sample, seed=self.seed,\n",
        "            workers=self.workers, min_alpha=self.min_alpha, sg=self.sg, hs=self.hs,\n",
        "            negative=self.negative, ns_exponent=self.ns_exponent, cbow_mean=self.cbow_mean,\n",
        "            hashfxn=self.hashfxn, iter=self.iter, null_word=self.null_word,\n",
        "            trim_rule=self.trim_rule, sorted_vocab=self.sorted_vocab, batch_words=self.batch_words,\n",
        "            compute_loss=self.compute_loss, callbacks=self.callbacks,\n",
        "            max_final_vocab=self.max_final_vocab)\n",
        "\n",
        "        #My code added\n",
        "        #google_wv = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "        #Ref: https://radimrehurek.com/gensim/scripts/glove2word2vec.html\n",
        "        \n",
        "\n",
        "        print(\"Created glove_wv.\")\n",
        "        print(\"Before build_vocab(X), check if Word2Vec(sentences=X) builds a vocab : \", len(self.model_.wv.vocab))\n",
        "\n",
        "        #self.model_.build_vocab(X)\n",
        "        training_examples_count = self.model_.corpus_count\n",
        "        print(\"original training_examples_count:\", training_examples_count)\n",
        "        print(\"Before merge, vocab: \", len(self.model_.wv.vocab))\n",
        "\n",
        "        if self.size ==100:\n",
        "          # load the Stanford GloVe model\n",
        "          glove_input_file = 'glove.6B.100d.txt'\n",
        "          word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
        "          glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "          filename = word2vec_output_file\n",
        "          glove_wv = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
        "        elif self.size ==200:\n",
        "          glove_input_file = 'glove.6B.200d.txt'\n",
        "          word2vec_output_file = 'glove.6B.200d.txt.word2vec'\n",
        "          glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "          filename = word2vec_output_file\n",
        "          glove_wv = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
        "        elif self.size ==300:\n",
        "          glove_input_file = 'glove.6B.300d.txt'\n",
        "          word2vec_output_file = 'glove.6B.300d.txt.word2vec'\n",
        "          glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "          filename = word2vec_output_file\n",
        "          glove_wv = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
        "\n",
        "\n",
        "        self.model_.build_vocab([list(glove_wv.vocab.keys())], update=True)\n",
        "        print(\"Updated build_vocab by Glove.\")\n",
        "        #self.model_.intersect_word2vec_format(glove_file, binary=False, lockf=1.0)#try this\n",
        "        self.model_.intersect_word2vec_format(filename, binary=False, lockf=1.0)\n",
        "        print(\"intersect completed.\")\n",
        "        self.model_.train(X, total_examples=training_examples_count, epochs=self.model_.iter)\n",
        "\n",
        "        print(\"After merge, vocab: \", len(self.model_.wv.vocab))\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_embeddings = np.array([self._get_embedding(words) for words in X])\n",
        "        return X_embeddings\n",
        "\n",
        "    def _get_embedding(self, words):\n",
        "        valid_words = [word for word in words if word in self.model_.wv.vocab]\n",
        "        if valid_words:\n",
        "            embedding = np.zeros((len(valid_words), self.size), dtype=np.float32)\n",
        "            for idx, word in enumerate(valid_words):\n",
        "                embedding[idx] = self.model_.wv[word]\n",
        "\n",
        "            return np.mean(embedding, axis=0)\n",
        "        else:\n",
        "            return np.zeros(self.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XmBO4dBHWZjB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XFGZAzcHE6z1"
      },
      "outputs": [],
      "source": [
        "def X_train_test_prepare(X_train, X_test):\n",
        "  first_index =X_train.index[0]\n",
        "  if type(X_train[first_index]) is not list:\n",
        "    for idx, lyrics in X_train.items():\n",
        "      X_train[idx] = lyrics.split(' ')\n",
        "\n",
        "  first_index =X_test.index[0]\n",
        "  if type(X_test[first_index]) is not list:\n",
        "    for idx, lyrics in X_test.items():\n",
        "      X_test[idx] = lyrics.split(' ')\n",
        "\n",
        "  return X_train, X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSq40J4SV9f2"
      },
      "source": [
        "### Model: Skipgram with Negative sampling. Run KFold and take mean of the balanced accuracy. use the best parameter from the music4all experiment, using XGB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Y1O4wC6MV9f2"
      },
      "outputs": [],
      "source": [
        "balanced_accuracy = []\n",
        "DIM = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPjly7TZV9f3",
        "outputId": "8fe70c21-419a-41d0-a978-5fa9cfd756e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1         [Take, your, cold, hands, and, put, them, on, ...\n",
              "2         [Are, you, ready, it's, time, for, war\\nWe'll,...\n",
              "4         [Do, you, believe, in, magic, in, a, young, gi...\n",
              "5         [People, starin', at, me, as, they, wheel, me,...\n",
              "7         [Tell, Mel, Shawn, to, come, in\\nWord,, yo,, o...\n",
              "                                ...                        \n",
              "258116    [It's, complicated, It, always, is, That's, ju...\n",
              "258117    [I'm, the, best, friend, he's, got, I'd, give,...\n",
              "258118    [Bad, Boys, Blue, \"I, Totally, Miss, You\", I, ...\n",
              "258120    [The, day, they, found, a, cure, for, AIDS, Th...\n",
              "258121    [Fourth, of, July, has, come,, it's, custom, t...\n",
              "Name: texts, Length: 206497, dtype: object"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split0['X_train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ4ijpk1V9f3"
      },
      "source": [
        "### First Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6aJJYZcV9f3",
        "outputId": "fe58772f-4f49-42fc-f2c1-17c3f1e02c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========split:  0 =================\n",
            "Created glove_wv.\n",
            "Before build_vocab(X), check if Word2Vec(sentences=X) builds a vocab :  297432\n",
            "original training_examples_count: 206497\n",
            "Before merge, vocab:  297432\n",
            "Updated build_vocab by Glove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intersect completed.\n",
            "After merge, vocab:  297432\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#0. get X_train, X_test\n",
        "split0=splits[0]\n",
        "split0['X_train'], split0['X_test'] = X_train_test_prepare(split0['X_train'], split0['X_test'])\n",
        "print(\"=========split: \" , 0, \"=================\")\n",
        "#1.create model and clf\n",
        "gensim_word2vec_tr_temp = GensimWord2VecVectorizer(size=DIM, min_count=5, sg=1, alpha=0.025, iter=1, sample=1e-05)\n",
        "\n",
        "#Note: from parameter tuning we found n_estimator=200 is best so far.\n",
        "xgb_clf_SMOTE = XGBClassifier(learning_rate=0.01, n_estimators=200, n_jobs=-1)\n",
        "\n",
        "#2.create word embedding and vector representation for each song\n",
        "gensim_word2vec_tr_temp = gensim_word2vec_tr_temp.fit(split0['X_train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-rhRVzRV9f3"
      },
      "source": [
        "Continue from the last cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXwIrcrVV9f3",
        "outputId": "894bab49-2235-44aa-840c-fb19d55f04b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206497\n",
            "Counter({4: 86844, 6: 86844, 3: 86844, 0: 86844, 7: 86844, 5: 86844, 9: 86844, 1: 86844, 2: 86844, 8: 86844})\n"
          ]
        }
      ],
      "source": [
        "#2-1.I want to add vocab from Gloeve\n",
        "X_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_train'])\n",
        "print(len(X_embeddings_temp))\n",
        "#3.SMOTE on train\n",
        "X_resampled_temp, y_resampled_temp = SMOTE().fit_resample(X_embeddings_temp, split0['y_train'])\n",
        "print(Counter(y_resampled_temp))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.train\n",
        "xgb_clf_SMOTE.fit(X_resampled_temp, y_resampled_temp)\n",
        "\n",
        "import pickle\n",
        "filename = DIR + 'Glove_XGB_kaggle_split0.sav'\n",
        "pickle.dump(xgb_clf_SMOTE, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "wBAFr1ikhJ9s"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_test'])\n",
        "y_test_pred_SMOTE_temp = xgb_clf_SMOTE.predict(X_test_embeddings_temp)\n",
        "print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) )\n",
        "print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD2t9Zje_d1c",
        "outputId": "adfde228-6422-481a-e73b-fc43b8cd58f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.48      0.13       540\n",
            "           1       0.06      0.24      0.10       533\n",
            "           2       0.09      0.28      0.14      1732\n",
            "           3       0.12      0.70      0.20       640\n",
            "           4       0.05      0.14      0.07      1550\n",
            "           5       0.22      0.52      0.31      2794\n",
            "           6       0.29      0.55      0.38      3989\n",
            "           7       0.53      0.26      0.35     17481\n",
            "           8       0.03      0.22      0.05       655\n",
            "           9       0.57      0.12      0.20     21711\n",
            "\n",
            "    accuracy                           0.24     51625\n",
            "   macro avg       0.20      0.35      0.19     51625\n",
            "weighted avg       0.46      0.24      0.26     51625\n",
            "\n",
            "0.3506699630220461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "JHVwSefrV9f3",
        "outputId": "95d5f21a-307b-4c00-bcfc-2a21ceb27c57"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-da7a8998a213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Note: this is because test embedding shape changes for each loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_test_embeddings_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim_word2vec_tr_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my_test_pred_SMOTE_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_svm_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_embeddings_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred_SMOTE_temp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred_SMOTE_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clf_svm_temp' is not defined"
          ]
        }
      ],
      "source": [
        "#4.train\n",
        "xgb_clf_SMOTE.fit(X_resampled_temp, y_resampled_temp)\n",
        "\n",
        "#5.Create test embedding and then predict\n",
        "#Note: this is because test embedding shape changes for each loop\n",
        "X_test_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_test'])\n",
        "y_test_pred_SMOTE_temp = clf_svm_temp.predict(X_test_embeddings_temp)\n",
        "print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) )\n",
        "print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "balanced_accuracy.append(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "\n",
        "with open(DIR+ \"Glove_SVM_base_kaggle_log.txt\", \"a\") as f:\n",
        "  print(\"=========split: \" , i,  \"==n_estimator: 200\", \"=learn rate:0.01\", \"=================\", file=f)\n",
        "  print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)\n",
        "  print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)\n",
        "\n",
        "if (i, DIM, kernel_choice,gamma_choice, C_choice ) not in McNemar:\n",
        "  McNemar[(i, DIM, kernel_choice,gamma_choice, C_choice )] = []\n",
        "for ground_truth, pred in zip(split0['y_test'], y_test_pred_SMOTE_temp):\n",
        "  if ground_truth == pred:\n",
        "    McNemar[(i, DIM, kernel_choice,gamma_choice, C_choice )].append(True)\n",
        "  else:\n",
        "    McNemar[(i, DIM, kernel_choice,gamma_choice, C_choice )].append(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSBsHYuFxmAY"
      },
      "source": [
        "Took 1H46 to fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iaXqAY3xno7"
      },
      "source": [
        "Resume from the last cell, predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m95kRFKmx8JM"
      },
      "outputs": [],
      "source": [
        "McNemar={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fftCsEdBxrC6",
        "outputId": "ad1e0dd6-f24b-44fe-fefe-637028a14dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.06      0.44      0.10       540\n",
            "           1       0.05      0.24      0.09       533\n",
            "           2       0.09      0.27      0.14      1732\n",
            "           3       0.12      0.70      0.20       640\n",
            "           4       0.05      0.16      0.08      1550\n",
            "           5       0.24      0.51      0.32      2794\n",
            "           6       0.29      0.54      0.37      3989\n",
            "           7       0.55      0.25      0.35     17481\n",
            "           8       0.03      0.23      0.05       655\n",
            "           9       0.57      0.11      0.18     21711\n",
            "\n",
            "    accuracy                           0.23     51625\n",
            "   macro avg       0.20      0.35      0.19     51625\n",
            "weighted avg       0.47      0.23      0.25     51625\n",
            "\n",
            "0.34556170501658384\n"
          ]
        }
      ],
      "source": [
        "y_test_pred_SMOTE_temp = xgb_clf_SMOTE.predict(X_test_embeddings_temp)\n",
        "print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) )\n",
        "print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "balanced_accuracy.append(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "\n",
        "with open(DIR+ \"Glove_XGB_kaggle_log.txt\", \"a\") as f:\n",
        "  print(\"=========split: \" , 0,  \"==n_estimator: 200\", \"=learn rate:0.01\", \"=================\", file=f)\n",
        "  print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)\n",
        "  print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A3c2Ye5yI7G"
      },
      "source": [
        "### Second Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SdrcUb1yI7H",
        "outputId": "11e2db87-be2a-4867-f1df-96276783e25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========split:  1 =================\n",
            "Created glove_wv.\n",
            "Before build_vocab(X), check if Word2Vec(sentences=X) builds a vocab :  297235\n",
            "original training_examples_count: 206497\n",
            "Before merge, vocab:  297235\n",
            "Updated build_vocab by Glove.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "intersect completed.\n",
            "After merge, vocab:  297235\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#0. get X_train, X_test\n",
        "split0=splits[1]\n",
        "split0['X_train'], split0['X_test'] = X_train_test_prepare(split0['X_train'], split0['X_test'])\n",
        "print(\"=========split: \" , 1, \"=================\")\n",
        "#1.create model and clf\n",
        "gensim_word2vec_tr_temp = GensimWord2VecVectorizer(size=DIM, min_count=5, sg=1, alpha=0.025, iter=1, sample=1e-05)\n",
        "\n",
        "#Note: from parameter tuning we found n_estimator=200 is best so far.\n",
        "xgb_clf_SMOTE = XGBClassifier(learning_rate=0.01, n_estimators=200, n_jobs=-1)\n",
        "\n",
        "#2.create word embedding and vector representation for each song\n",
        "gensim_word2vec_tr_temp = gensim_word2vec_tr_temp.fit(split0['X_train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ewrt7kqgyI7I",
        "outputId": "b32b36bf-0a93-4327-f673-bec6cfdb2f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "206497\n",
            "Counter({3: 86844, 4: 86844, 6: 86844, 7: 86844, 0: 86844, 9: 86844, 8: 86844, 1: 86844, 2: 86844, 5: 86844})\n"
          ]
        }
      ],
      "source": [
        "#2-1.I want to add vocab from Gloeve\n",
        "X_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_train'])\n",
        "print(len(X_embeddings_temp))\n",
        "#3.SMOTE on train\n",
        "X_resampled_temp, y_resampled_temp = SMOTE().fit_resample(X_embeddings_temp, split0['y_train'])\n",
        "print(Counter(y_resampled_temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAxTSnM0yI7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d39482d1-fdc5-446e-ff9b-1d2953c27502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.47      0.12       540\n",
            "           1       0.06      0.27      0.10       533\n",
            "           2       0.08      0.28      0.12      1732\n",
            "           3       0.11      0.70      0.19       640\n",
            "           4       0.05      0.13      0.07      1550\n",
            "           5       0.22      0.52      0.31      2795\n",
            "           6       0.29      0.52      0.38      3988\n",
            "           7       0.54      0.27      0.36     17481\n",
            "           8       0.03      0.22      0.05       655\n",
            "           9       0.57      0.12      0.19     21711\n",
            "\n",
            "    accuracy                           0.24     51625\n",
            "   macro avg       0.20      0.35      0.19     51625\n",
            "weighted avg       0.46      0.24      0.26     51625\n",
            "\n",
            "0.34968158062765864\n"
          ]
        }
      ],
      "source": [
        "#4.train\n",
        "xgb_clf_SMOTE.fit(X_resampled_temp, y_resampled_temp)\n",
        "\n",
        "#5.Create test embedding and then predict\n",
        "#Note: this is because test embedding shape changes for each loop\n",
        "X_test_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_test'])\n",
        "y_test_pred_SMOTE_temp = xgb_clf_SMOTE.predict(X_test_embeddings_temp)\n",
        "print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) )\n",
        "print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "balanced_accuracy.append(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "\n",
        "with open(DIR+ \"Glove_SVM_base_kaggle_log.txt\", \"a\") as f:\n",
        "  print(\"=========split: \" , 1,  \"==n_estimator: 200\", \"=learn rate:0.01\", \"=================\", file=f)\n",
        "  print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)\n",
        "  print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPv78KU-yI7I"
      },
      "source": [
        "Took 1H46 to fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGLV5QWPDu4x"
      },
      "source": [
        "### Third Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc70e658-6d4c-4c36-f756-3911b31a9385",
        "id": "36Lxb8XxDu4x"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========split:  2 =================\n",
            "Created glove_wv.\n",
            "Before build_vocab(X), check if Word2Vec(sentences=X) builds a vocab :  297288\n",
            "original training_examples_count: 206498\n",
            "Before merge, vocab:  297288\n",
            "Updated build_vocab by Glove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intersect completed.\n",
            "After merge, vocab:  297288\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#0. get X_train, X_test\n",
        "split0=splits[2]\n",
        "split0['X_train'], split0['X_test'] = X_train_test_prepare(split0['X_train'], split0['X_test'])\n",
        "print(\"=========split: \" , 2, \"=================\")\n",
        "#1.create model and clf\n",
        "gensim_word2vec_tr_temp = GensimWord2VecVectorizer(size=DIM, min_count=5, sg=1, alpha=0.025, iter=1, sample=1e-05)\n",
        "\n",
        "#Note: from parameter tuning we found n_estimator=200 is best so far.\n",
        "xgb_clf_SMOTE = XGBClassifier(learning_rate=0.01, n_estimators=200, n_jobs=-1)\n",
        "\n",
        "#2.create word embedding and vector representation for each song\n",
        "gensim_word2vec_tr_temp = gensim_word2vec_tr_temp.fit(split0['X_train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxqZGotyDu4y",
        "outputId": "3cf61603-7d3c-4b1c-e2f3-32c3e0b5f6c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206498\n",
            "Counter({3: 86844, 4: 86844, 7: 86844, 0: 86844, 6: 86844, 5: 86844, 9: 86844, 8: 86844, 1: 86844, 2: 86844})\n"
          ]
        }
      ],
      "source": [
        "#2-1.I want to add vocab from Gloeve\n",
        "X_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_train'])\n",
        "print(len(X_embeddings_temp))\n",
        "#3.SMOTE on train\n",
        "X_resampled_temp, y_resampled_temp = SMOTE().fit_resample(X_embeddings_temp, split0['y_train'])\n",
        "print(Counter(y_resampled_temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL4Q7S1BDu4y",
        "outputId": "b26fc052-9b7e-4b3a-f459-563f4fdefe16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.07      0.41      0.12       540\n",
            "           1       0.07      0.27      0.11       532\n",
            "           2       0.09      0.29      0.14      1732\n",
            "           3       0.11      0.74      0.19       640\n",
            "           4       0.05      0.17      0.08      1550\n",
            "           5       0.22      0.50      0.30      2795\n",
            "           6       0.29      0.53      0.37      3988\n",
            "           7       0.57      0.25      0.34     17481\n",
            "           8       0.04      0.24      0.06       655\n",
            "           9       0.57      0.15      0.24     21711\n",
            "\n",
            "    accuracy                           0.25     51624\n",
            "   macro avg       0.21      0.35      0.20     51624\n",
            "weighted avg       0.47      0.25      0.28     51624\n",
            "\n",
            "0.35412064341860783\n"
          ]
        }
      ],
      "source": [
        "#4.train\n",
        "xgb_clf_SMOTE.fit(X_resampled_temp, y_resampled_temp)\n",
        "\n",
        "#5.Create test embedding and then predict\n",
        "#Note: this is because test embedding shape changes for each loop\n",
        "X_test_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_test'])\n",
        "y_test_pred_SMOTE_temp = xgb_clf_SMOTE.predict(X_test_embeddings_temp)\n",
        "print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) )\n",
        "print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "balanced_accuracy.append(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "\n",
        "with open(DIR+ \"Glove_XGB_kaggle_log.txt\", \"a\") as f:\n",
        "  print(\"=========split: \" , 2,  \"==n_estimator: 200\", \"=learn rate:0.01\", \"=================\", file=f)\n",
        "  print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)\n",
        "  print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "febSg0sVxcNn"
      },
      "source": [
        "Took 1H46 to fit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = DIR + 'checkpoints/Glove_XGB_kaggle_split2.sav'\n",
        "pickle.dump(xgb_clf_SMOTE, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "pIXP84CJZKTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl4lrX_ICtwc"
      },
      "source": [
        "### Fourth Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1818c7ac-647b-4364-94c4-d1ea4780ed53",
        "id": "biq9VetoCtwd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========split:  3 =================\n",
            "Created glove_wv.\n",
            "Before build_vocab(X), check if Word2Vec(sentences=X) builds a vocab :  296978\n",
            "original training_examples_count: 206498\n",
            "Before merge, vocab:  296978\n",
            "Updated build_vocab by Glove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intersect completed.\n",
            "After merge, vocab:  296978\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#0. get X_train, X_test\n",
        "split0=splits[3]\n",
        "split0['X_train'], split0['X_test'] = X_train_test_prepare(split0['X_train'], split0['X_test'])\n",
        "print(\"=========split: \" , 3, \"=================\")\n",
        "#1.create model and clf\n",
        "gensim_word2vec_tr_temp = GensimWord2VecVectorizer(size=DIM, min_count=5, sg=1, alpha=0.025, iter=1, sample=1e-05)\n",
        "\n",
        "#Note: from parameter tuning we found n_estimator=200 is best so far.\n",
        "xgb_clf_SMOTE = XGBClassifier(learning_rate=0.01, n_estimators=200, n_jobs=-1)\n",
        "\n",
        "#2.create word embedding and vector representation for each song\n",
        "gensim_word2vec_tr_temp = gensim_word2vec_tr_temp.fit(split0['X_train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3e7cef-2ae6-4557-a8b8-ccc79002123e",
        "id": "04I0uUpvCtwd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206498\n",
            "Counter({3: 86844, 6: 86844, 7: 86844, 0: 86844, 5: 86844, 9: 86844, 4: 86844, 8: 86844, 1: 86844, 2: 86844})\n"
          ]
        }
      ],
      "source": [
        "#2-1.I want to add vocab from Gloeve\n",
        "X_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_train'])\n",
        "print(len(X_embeddings_temp))\n",
        "#3.SMOTE on train\n",
        "X_resampled_temp, y_resampled_temp = SMOTE().fit_resample(X_embeddings_temp, split0['y_train'])\n",
        "print(Counter(y_resampled_temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWdptSz4Ctwd",
        "outputId": "82e99fe2-fc31-4000-fa42-a98d3dd63779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.49      0.13       540\n",
            "           1       0.07      0.28      0.11       533\n",
            "           2       0.09      0.28      0.13      1732\n",
            "           3       0.13      0.71      0.22       639\n",
            "           4       0.06      0.16      0.09      1550\n",
            "           5       0.23      0.52      0.31      2795\n",
            "           6       0.25      0.58      0.35      3989\n",
            "           7       0.55      0.23      0.33     17481\n",
            "           8       0.04      0.28      0.06       654\n",
            "           9       0.58      0.11      0.18     21711\n",
            "\n",
            "    accuracy                           0.23     51624\n",
            "   macro avg       0.21      0.37      0.19     51624\n",
            "weighted avg       0.47      0.23      0.25     51624\n",
            "\n",
            "0.3655926343925764\n"
          ]
        }
      ],
      "source": [
        "#4.train\n",
        "xgb_clf_SMOTE.fit(X_resampled_temp, y_resampled_temp)\n",
        "\n",
        "#5.Create test embedding and then predict\n",
        "#Note: this is because test embedding shape changes for each loop\n",
        "X_test_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_test'])\n",
        "y_test_pred_SMOTE_temp = xgb_clf_SMOTE.predict(X_test_embeddings_temp)\n",
        "print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) )\n",
        "print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "balanced_accuracy.append(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "\n",
        "with open(DIR+ \"Glove_XGB_kaggle_log.txt\", \"a\") as f:\n",
        "  print(\"=========split: \" , 3,  \"==n_estimator: 200\", \"=learn rate:0.01\", \"=================\", file=f)\n",
        "  print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)\n",
        "  print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = DIR + 'checkpoints/Glove_XGB_kaggle_split3.sav'\n",
        "pickle.dump(xgb_clf_SMOTE, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "YAgkM1XXZWd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0LhnCLVRPTJ"
      },
      "source": [
        "### Fifth Fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101d725b-9dc5-4d02-c22d-1e975262eb9b",
        "id": "Trp3nuYURPTL"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========split:  4 =================\n",
            "Created glove_wv.\n",
            "Before build_vocab(X), check if Word2Vec(sentences=X) builds a vocab :  297552\n",
            "original training_examples_count: 206498\n",
            "Before merge, vocab:  297552\n",
            "Updated build_vocab by Glove.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "intersect completed.\n",
            "After merge, vocab:  297552\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#0. get X_train, X_test\n",
        "split0=splits[4]\n",
        "split0['X_train'], split0['X_test'] = X_train_test_prepare(split0['X_train'], split0['X_test'])\n",
        "print(\"=========split: \" , 4, \"=================\")\n",
        "#1.create model and clf\n",
        "gensim_word2vec_tr_temp = GensimWord2VecVectorizer(size=DIM, min_count=5, sg=1, alpha=0.025, iter=1, sample=1e-05)\n",
        "\n",
        "#Note: from parameter tuning we found n_estimator=200 is best so far.\n",
        "xgb_clf_SMOTE = XGBClassifier(learning_rate=0.01, n_estimators=200, n_jobs=-1)\n",
        "\n",
        "#2.create word embedding and vector representation for each song\n",
        "gensim_word2vec_tr_temp = gensim_word2vec_tr_temp.fit(split0['X_train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c609b0ce-a9d9-4528-ea9c-d326a9e09da8",
        "id": "KqL5I9GARPTL"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206498\n",
            "Counter({3: 86844, 4: 86844, 6: 86844, 7: 86844, 0: 86844, 5: 86844, 9: 86844, 8: 86844, 1: 86844, 2: 86844})\n"
          ]
        }
      ],
      "source": [
        "#2-1.I want to add vocab from Gloeve\n",
        "X_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_train'])\n",
        "print(len(X_embeddings_temp))\n",
        "#3.SMOTE on train\n",
        "X_resampled_temp, y_resampled_temp = SMOTE().fit_resample(X_embeddings_temp, split0['y_train'])\n",
        "print(Counter(y_resampled_temp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9869ebd9-e72f-4d07-9188-5e4b091121ed",
        "id": "j42WEBPLRPTL"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.48      0.13       540\n",
            "           1       0.07      0.29      0.11       533\n",
            "           2       0.08      0.26      0.13      1732\n",
            "           3       0.12      0.68      0.20       639\n",
            "           4       0.05      0.12      0.07      1550\n",
            "           5       0.22      0.51      0.31      2795\n",
            "           6       0.29      0.57      0.38      3989\n",
            "           7       0.55      0.27      0.36     17481\n",
            "           8       0.03      0.21      0.05       654\n",
            "           9       0.58      0.13      0.22     21711\n",
            "\n",
            "    accuracy                           0.25     51624\n",
            "   macro avg       0.21      0.35      0.20     51624\n",
            "weighted avg       0.47      0.25      0.27     51624\n",
            "\n",
            "0.35396073222743846\n"
          ]
        }
      ],
      "source": [
        "#4.train\n",
        "xgb_clf_SMOTE.fit(X_resampled_temp, y_resampled_temp)\n",
        "\n",
        "#5.Create test embedding and then predict\n",
        "#Note: this is because test embedding shape changes for each loop\n",
        "X_test_embeddings_temp = gensim_word2vec_tr_temp.transform(split0['X_test'])\n",
        "y_test_pred_SMOTE_temp = xgb_clf_SMOTE.predict(X_test_embeddings_temp)\n",
        "print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) )\n",
        "print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "balanced_accuracy.append(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp))\n",
        "\n",
        "with open(DIR+ \"Glove_XGB_base_kaggle_log.txt\", \"a\") as f:\n",
        "  print(\"=========split: \" , 4,  \"==n_estimator: 200\", \"=learn rate:0.01\", \"=================\", file=f)\n",
        "  print(classification_report(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)\n",
        "  print(balanced_accuracy_score(split0['y_test'], y_test_pred_SMOTE_temp) , file=f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "QqcUOqiZY819"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = DIR + 'checkpoints/Glove_XGB_kaggle_split4.sav'\n",
        "pickle.dump(xgb_clf_SMOTE, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "8s2UEqMfY95v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "jFKYiMJngx30",
        "hWxfNJqYBfjD",
        "hTasgChQX-iM",
        "UtSCraBK7Opu",
        "fSq40J4SV9f2",
        "hJ4ijpk1V9f3",
        "2A3c2Ye5yI7G",
        "gGLV5QWPDu4x",
        "nl4lrX_ICtwc",
        "g0LhnCLVRPTJ"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1MhyiJwfCll_VoAfhIKMymNki6E4qFg4R",
      "authorship_tag": "ABX9TyPuDggzE9Pag55X28hF7MVz",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
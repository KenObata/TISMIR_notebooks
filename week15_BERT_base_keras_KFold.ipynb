{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KenObata/TISMIR_notebooks/blob/main/week15_BERT_base_keras_KFold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS8WVxEoWZG0"
      },
      "source": [
        "## This notebook uses Pre-Trained BERT model\n",
        "\n",
        "Situation: English only (=multi-class).\n",
        "Split: StratifiedKfold.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWL5DlwVTHgV"
      },
      "source": [
        "### set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Fdw4QzS4FD",
        "outputId": "db91525e-4f17-44e5-ebde-aa3eb1c6b57b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 6.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d5F3EmWPVWZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from collections import Counter\n",
        "\n",
        "from skmultilearn.model_selection import IterativeStratification   \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "def get_balanced_accuracy(model, McNemar, is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning):\n",
        "  test_y = test.map(map_func_only_y)\n",
        "  y_category=np.zeros((TEST_SIZE, ))\n",
        "  counter=0\n",
        "  for label_tensor in test_y.take(len(test_y)):\n",
        "    y_test = np.argmax(label_tensor, axis=1)\n",
        "    for label in y_test:\n",
        "      y_category[counter]=label\n",
        "      counter+=1\n",
        "\n",
        "  X_test, y_test = test.map(map_func_only_X), y_category\n",
        "  y_predict_test = np.asarray(model.predict(X_test))\n",
        "  y_predict_test = np.argmax(y_predict_test, axis=1)\n",
        "  print(classification_report(y_test, y_predict_test) )\n",
        "  print(balanced_accuracy_score(y_test, y_predict_test))\n",
        "\n",
        "  McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)] = []\n",
        "  for ground_truh, pred in zip(y_test, y_predict_test):\n",
        "        if ground_truh==pred:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(True)\n",
        "        else:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(False)\n",
        "  with open(DIR+ \"BERT_base_log.txt\", \"a\") as f:\n",
        "    print(\"======================================\", file=f)\n",
        "    print(\"is_fine_tuning?:\", is_fine_tuning, \"drop_out_rate: \", drop_out_rate, \"learning_rate_transfer_learning: \", learning_rate_transfer_learning,\n",
        "          \"learning_rate_fine_tuning: \", learning_rate_fine_tuning, file=f)\n",
        "    print(classification_report(y_test, y_predict_test) , file=f)\n",
        "    print(balanced_accuracy_score(y_test, y_predict_test), file=f)\n",
        "\n",
        "  return balanced_accuracy_score(y_test, y_predict_test), McNemar"
      ],
      "metadata": {
        "id": "K6VTlTxg8JVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save output into text\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "with open(DIR+ \"BERT_base_log.txt\", \"a\") as f:\n",
        "  print(\"File name: week15_BERT_baseline_keras.ipynb\", file=f)\n"
      ],
      "metadata": {
        "id": "nxtC5_Sgr2tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWxfNJqYBfjD"
      },
      "source": [
        "### Data Preparation(Kfold split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbT7Qs4whnTX"
      },
      "source": [
        "Create dataframe for Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le3tiKjOOp19",
        "outputId": "212a7598-784f-4f68-c29f-4da9d8fdf454"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                id             genres lang  \\\n",
              "0               0  0009fFIM1eYThaPg                pop   en   \n",
              "1               1  00P2bHdWFkghmDqz               soul   en   \n",
              "2               2  00b6fV3nx5z2b8Ls                pop   en   \n",
              "3               3  013QDoTqbexEwkHr                pop   en   \n",
              "4               4  01EKNot8qVgZpKM7               rock   en   \n",
              "...           ...               ...                ...  ...   \n",
              "13535       13535  zzT504Z94j1IAuc3         indie rock   en   \n",
              "13536       13536  zzgS4ZqyswamEWNj                pop   en   \n",
              "13537       13537  zzx8CWdM7qkxKQpC         indie rock   en   \n",
              "13538       13538  zzz0n04uuTUA7fNh                pop   en   \n",
              "13539       13539  zzzj3LYaZtYtbzSr  singer-songwriter   en   \n",
              "\n",
              "                                                   lyric  number_of_line  \n",
              "0      a sunny day so I got nowhere to hide Not a clo...              91  \n",
              "1      Tell me a tale that always was Sing me a song ...              36  \n",
              "2      A buh A buh You went to school to learn girl T...              74  \n",
              "3      like a conversation where stops to breathe Is ...              20  \n",
              "4      Say the words I cannot say Say them on another...              31  \n",
              "...                                                  ...             ...  \n",
              "13535  think what afraid of come in you know been mad...              18  \n",
              "13536  Oh yeah yeah Last night I took a walk in the s...              75  \n",
              "13537  Innocence it come easy in a sense it never wil...              34  \n",
              "13538  Girl you know how I feel I really Since you be...              65  \n",
              "13539  wwI oh must go on standing You break that whic...              64  \n",
              "\n",
              "[13540 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1beb482-13a1-4b5d-aa7b-502ee9bff37c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>genres</th>\n",
              "      <th>lang</th>\n",
              "      <th>lyric</th>\n",
              "      <th>number_of_line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0009fFIM1eYThaPg</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>a sunny day so I got nowhere to hide Not a clo...</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>00P2bHdWFkghmDqz</td>\n",
              "      <td>soul</td>\n",
              "      <td>en</td>\n",
              "      <td>Tell me a tale that always was Sing me a song ...</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>00b6fV3nx5z2b8Ls</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>A buh A buh You went to school to learn girl T...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>013QDoTqbexEwkHr</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>like a conversation where stops to breathe Is ...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>01EKNot8qVgZpKM7</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Say the words I cannot say Say them on another...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>13535</td>\n",
              "      <td>zzT504Z94j1IAuc3</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>think what afraid of come in you know been mad...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>13536</td>\n",
              "      <td>zzgS4ZqyswamEWNj</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Oh yeah yeah Last night I took a walk in the s...</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>13537</td>\n",
              "      <td>zzx8CWdM7qkxKQpC</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Innocence it come easy in a sense it never wil...</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>13538</td>\n",
              "      <td>zzz0n04uuTUA7fNh</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Girl you know how I feel I really Since you be...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>13539</td>\n",
              "      <td>zzzj3LYaZtYtbzSr</td>\n",
              "      <td>singer-songwriter</td>\n",
              "      <td>en</td>\n",
              "      <td>wwI oh must go on standing You break that whic...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1beb482-13a1-4b5d-aa7b-502ee9bff37c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1beb482-13a1-4b5d-aa7b-502ee9bff37c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1beb482-13a1-4b5d-aa7b-502ee9bff37c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "df_genre_by_lang = pd.read_csv(DIR + 'df_genre_by_lang_full.csv')\n",
        "df_genre_by_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrRidTBHhmYp"
      },
      "outputs": [],
      "source": [
        "def load_data(df_col, y):\n",
        "    texts, labels = [], []\n",
        "    \n",
        "    for line in df_col:\n",
        "        # texts are already tokenized, just split on space\n",
        "        # in a real use-case we would put more effort in preprocessing\n",
        "        texts.append(line.split(' '))\n",
        "    return pd.DataFrame({'texts': texts, 'labels': y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5VJWiA6iJu2"
      },
      "outputs": [],
      "source": [
        "data = load_data(df_genre_by_lang[\"lyric\"], df_genre_by_lang[\"genres\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWI4V7oXiWw6",
        "outputId": "6e5ddd51-7f0b-440e-a072-ae98ec8dff31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   texts             labels\n",
              "0      [a, sunny, day, so, I, got, nowhere, to, hide,...                pop\n",
              "1      [Tell, me, a, tale, that, always, was, Sing, m...               soul\n",
              "2      [A, buh, A, buh, You, went, to, school, to, le...                pop\n",
              "3      [like, a, conversation, where, stops, to, brea...                pop\n",
              "4      [Say, the, words, I, cannot, say, Say, them, o...               rock\n",
              "...                                                  ...                ...\n",
              "13535  [think, what, afraid, of, come, in, you, know,...         indie rock\n",
              "13536  [Oh, yeah, yeah, Last, night, I, took, a, walk...                pop\n",
              "13537  [Innocence, it, come, easy, in, a, sense, it, ...         indie rock\n",
              "13538  [Girl, you, know, how, I, feel, I, really, Sin...                pop\n",
              "13539  [wwI, oh, must, go, on, standing, You, break, ...  singer-songwriter\n",
              "\n",
              "[13540 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e81a5426-49a7-4a11-ba63-210fcf3cf841\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[a, sunny, day, so, I, got, nowhere, to, hide,...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Tell, me, a, tale, that, always, was, Sing, m...</td>\n",
              "      <td>soul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[A, buh, A, buh, You, went, to, school, to, le...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[like, a, conversation, where, stops, to, brea...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Say, the, words, I, cannot, say, Say, them, o...</td>\n",
              "      <td>rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>[think, what, afraid, of, come, in, you, know,...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>[Oh, yeah, yeah, Last, night, I, took, a, walk...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>[Innocence, it, come, easy, in, a, sense, it, ...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>[Girl, you, know, how, I, feel, I, really, Sin...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>[wwI, oh, must, go, on, standing, You, break, ...</td>\n",
              "      <td>singer-songwriter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e81a5426-49a7-4a11-ba63-210fcf3cf841')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e81a5426-49a7-4a11-ba63-210fcf3cf841 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e81a5426-49a7-4a11-ba63-210fcf3cf841');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTROinyfjc6u"
      },
      "outputs": [],
      "source": [
        "data['labels'] = data['labels'].astype('category')\n",
        "label_mapping = data['labels'].cat.categories\n",
        "data['labels'] = data['labels'].cat.codes\n",
        "X = data['texts']\n",
        "y = data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32Ub0-kjoOj",
        "outputId": "e57a941a-baa9-4806-fe99-9decfdb2862e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnAEWk_Lza7f"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df_glove(df, feature_list, y_name):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  y = df[y_name]\n",
        "  skf.get_n_splits(df[ feature_list ], y)\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(df[ feature_list ], y):\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = df[ feature_list ].loc[train_index], df[ feature_list ].loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qOv6pF0BcrV"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df(X, y):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  #y = df[y_name]\n",
        "  skf.get_n_splits(X, y)#df[ feature_list ]\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(X, y):#df[ feature_list ]\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGZPLOeBg4R",
        "outputId": "c3424897-0549-459f-bfc4-70ff76a90df5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [    0     1     3 ... 13537 13538 13539] TEST: [    2     4     5 ... 13526 13532 13535]\n",
            "TRAIN: [    0     2     4 ... 13535 13536 13539] TEST: [    1     3     7 ... 13530 13537 13538]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [    8    14    22 ... 13521 13531 13536]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [   10    12    15 ... 13523 13525 13534]\n",
            "TRAIN: [    1     2     3 ... 13536 13537 13538] TEST: [    0     6    11 ... 13529 13533 13539]\n"
          ]
        }
      ],
      "source": [
        "#feature_list = [\"texts\"] #this is BOW and TF-IDF\n",
        "#splits = StratifiedKFold_feature_and_df( data, feature_list, 'labels')\n",
        "splits = StratifiedKFold_feature_and_df( X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsQYbmVUWPU9",
        "outputId": "438aa35d-6b3b-47bf-e5e0-ad4413a984d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDMBs_gWCSLa",
        "outputId": "d9da631e-b1cb-4ec5-dfd7-a3b1b37b3c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,)\n",
            "(10832,)\n",
            "(2708,)\n",
            "(2708,)\n"
          ]
        }
      ],
      "source": [
        "split0=splits[0]\n",
        "print(split0['X_train'].shape)\n",
        "print(split0['y_train'].shape)\n",
        "print(split0['X_test'].shape)\n",
        "print(split0['y_test'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaMmpM44is_p",
        "outputId": "ade5f84c-7f94-487c-effe-da7463471f92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [a, sunny, day, so, I, got, nowhere, to, hide,...\n",
              "1        [Tell, me, a, tale, that, always, was, Sing, m...\n",
              "3        [like, a, conversation, where, stops, to, brea...\n",
              "6        [Locked, up, tight, Like, I, would, never, fee...\n",
              "7        [sittin, in, the, crib, dreamin, about, leer, ...\n",
              "                               ...                        \n",
              "13534    [grandma, cookies, nigga, Shout, out, to, fron...\n",
              "13536    [Oh, yeah, yeah, Last, night, I, took, a, walk...\n",
              "13537    [Innocence, it, come, easy, in, a, sense, it, ...\n",
              "13538    [Girl, you, know, how, I, feel, I, really, Sin...\n",
              "13539    [wwI, oh, must, go, on, standing, You, break, ...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "split0['X_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qTuHLEe8Aqg",
        "outputId": "c56f6622-dcd1-41fe-ff7d-d08ce51b2dd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "split0['y_train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONmunMa_h7T"
      },
      "source": [
        "### Use my self programmed balanced accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot3KP7Dl_kdf",
        "outputId": "b39a20db-171b-4ef7-bd3a-e1a9522eb463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "339/339 [==============================] - 225s 645ms/step - loss: 0.5565 - categorical_accuracy: 0.3878 - val_loss: 1.9337 - val_categorical_accuracy: 0.3273\n",
            "Epoch 2/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5397 - categorical_accuracy: 0.3626 - val_loss: 2.0651 - val_categorical_accuracy: 0.2764\n",
            "Epoch 3/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5375 - categorical_accuracy: 0.3392 - val_loss: 2.0931 - val_categorical_accuracy: 0.2273\n",
            "Epoch 4/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5378 - categorical_accuracy: 0.3197 - val_loss: 2.0576 - val_categorical_accuracy: 0.2459\n",
            "Epoch 5/10\n",
            "339/339 [==============================] - 219s 645ms/step - loss: 0.5333 - categorical_accuracy: 0.3077 - val_loss: 2.0292 - val_categorical_accuracy: 0.2816\n",
            "Epoch 6/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5373 - categorical_accuracy: 0.2967 - val_loss: 2.1738 - val_categorical_accuracy: 0.1895\n",
            "Epoch 7/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5396 - categorical_accuracy: 0.2930 - val_loss: 2.1382 - val_categorical_accuracy: 0.2181\n",
            "Epoch 8/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5431 - categorical_accuracy: 0.2710 - val_loss: 2.1512 - val_categorical_accuracy: 0.1965\n",
            "Epoch 9/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5450 - categorical_accuracy: 0.2729 - val_loss: 2.1854 - val_categorical_accuracy: 0.1092\n",
            "Epoch 10/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5495 - categorical_accuracy: 0.2553 - val_loss: 2.1354 - val_categorical_accuracy: 0.1594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'balanced_accuracy': 0.09744849916749872},\n",
              " {'balanced_accuracy': 0.10420636932765996},\n",
              " {'balanced_accuracy': 0.10970405736872939},\n",
              " {'balanced_accuracy': 0.10356561320774078},\n",
              " {'balanced_accuracy': 0.10792864804613309},\n",
              " {'balanced_accuracy': 0.09168989857066105},\n",
              " {'balanced_accuracy': 0.09926135499834263},\n",
              " {'balanced_accuracy': 0.10014630125778516},\n",
              " {'balanced_accuracy': 0.09807505457274496},\n",
              " {'balanced_accuracy': 0.09881853716030842}]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics = Metrics()\n",
        "history = model.fit(train, validation_data=val, epochs=10, class_weight=my_weight ,callbacks=[metrics])\n",
        "metrics.get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzqLBSC6H175"
      },
      "source": [
        "## From here, separate X_train, X_test from KFOldSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb0KcNXhbUSN"
      },
      "source": [
        "### Preprocess my lyrics data (Official train and test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4lLLyF-bUSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e27390-a95a-4a12-e62e-70ea795c0435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "!pip3 install transformers\n",
        "SEQ_LEN = 256#512"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUA-ps2gyvt",
        "outputId": "a9849467-d9df-4eeb-be75-ad68e28ce4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2        [A, buh, A, buh, You, went, to, school, to, le...\n",
              "4        [Say, the, words, I, cannot, say, Say, them, o...\n",
              "5        [I, was, alone, I, was, made, of, stone, You, ...\n",
              "9        [Again, the, burden, of, losing, rests, upon, ...\n",
              "20       [only, been, three, weeks, And, a, bag, of, sp...\n",
              "                               ...                        \n",
              "13517    [Like, the, legend, of, the, Phoenix, All, end...\n",
              "13522    [Mr, Telephone, man, something, wrong, with, m...\n",
              "13526    [can, you, imagine, what, it, would, be, like,...\n",
              "13532    [Love, of, my, life, hurt, me, broken, my, hea...\n",
              "13535    [think, what, afraid, of, come, in, you, know,...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_lyrics(X_series):\n",
        "  for i, token_list in X_series.items():\n",
        "    if type(token_list) is list:\n",
        "      X_series.loc[i] = ' '.join(token_list)\n",
        "  return X_series"
      ],
      "metadata": {
        "id": "PqFwOGTIbhiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "SEQ_LEN=256\n",
        "\n",
        "def get_Xid_Xmask(X_origin):\n",
        "  Xids_train = np.zeros((X_origin.shape[0], SEQ_LEN))\n",
        "  Xmask_train = np.zeros((X_origin.shape[0], SEQ_LEN))\n",
        "\n",
        "  for i, lyric in enumerate(X_origin):\n",
        "    tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "    Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "  return Xids_train, Xmask_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "9f44f7989f4e42d1adb6fd3f10532d3a",
            "ec487b13a30d4ec4ab7ff778fdf71875",
            "2ffc22a29ce1412dadc05f3d7b7a35ba",
            "abd99e9aadef4d2f80f927075923ba58",
            "84b8f1ac7cda4fe596dfbb924f55a632",
            "2aafa4f5400b4d7f8be311c2881a2af2",
            "765630ed0d6c47e5b41392db257591e0",
            "94747a85cb514f758c9b365d2b5dc48e",
            "e630d77e739c42e6a4a7399a891448f9",
            "ab610be6ba4349c2adff62277659b4d3",
            "09f31d6a4ba740dba521b97dd222c232",
            "b6b7569539af4eaeb3f324e040856dff",
            "4fdd2bef2722419cb005a6001ae7e19b",
            "dd487e15d8fa421db7b5259f9d66a7a6",
            "f5c8c8576b1c451a9b96f6d4e98a308b",
            "8133599680514d82b24e0d2ee4744b8d",
            "0fbd384a79c44145866b750154836bd9",
            "b425723d5a77435fa8f5f4bb24dc3124",
            "7d27039990f74964a14abb15c6416981",
            "e1075e83342943d287d1cd64d53d12f6",
            "75a3d8554e79481cac916794c545b139",
            "496ee739986f400f9cb251a13fd047dd",
            "8696072b50614fe7a14e4a7ba4f16acd",
            "a4b2326f603442c78268d0b0fce7a4c3",
            "9fb4b98a430243c68a16dabe8331af1a",
            "83183062ecc8488fadb4f87d924e79dd",
            "0398c45910974acebc11aac48d99ba82",
            "043be71c3a624b89aad0bc6ef6c59ef3",
            "d36299a1fd5b499ca3d3ee85be4e8681",
            "59be3300a46241c0bca72e5e75977ae5",
            "9f7085aa03504d14850d29b92f2fa670",
            "5383aa711b49493fba17a6c53b5e3c6a",
            "75bbcd3e5d38450093818c9f68d1c061",
            "33faf452d09340f99fc5444711e44b36",
            "ae8283a15eea4f4bb7cef7b8e64fcb37",
            "6f3b238dc6b94faeb3f3efe78b0e239c",
            "09028592f4c4486da8434580b2ef37dd",
            "8c4cc79788a6416ebdf65587eadb05a7",
            "f6eddbda476e44679a46acd357d20676",
            "8eda9b1e0f0841d3a2f35c102f017021",
            "35e8f4a2e94f43c3b79f5a06fc2507f4",
            "2f8ba8f9293e4266a4c72fd9f6b96a56",
            "2d1fdf93331b473fac1ae62ddb9af79c",
            "e8b979b56863404086279aae950e89e0"
          ]
        },
        "id": "hBAL5McoCfw4",
        "outputId": "572027fa-5332-4bbc-8c40-d574c31c2f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f44f7989f4e42d1adb6fd3f10532d3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b7569539af4eaeb3f324e040856dff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8696072b50614fe7a14e4a7ba4f16acd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/426k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33faf452d09340f99fc5444711e44b36"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7xk5236bUSR"
      },
      "outputs": [],
      "source": [
        "def map_func(input_ids, masks, labels):\n",
        "  return {'input_ids': input_ids, 'attention_mask':masks}, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "#tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')\n",
        "Xids_train, Xmask_train = get_Xid_Xmask(split0['X_train'])\n",
        "Xids_test, Xmask_test = get_Xid_Xmask(split0['X_test'])\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "DS_LEN = len(list(dataset_train))\n",
        "SPLIT=0.9\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "id": "sW85C_3QCtc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b689340-6fa0-4990-9ce0-56230566c807",
        "id": "wZDVrP0QYC_n"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10832"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "counter = Counter(split0['y_train'])\n",
        "SUM=0\n",
        "for item in list(counter.values()) :\n",
        "  SUM+=item\n",
        "#SUM = sum(counter.values())\n",
        "SUM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tutorial\n",
        "#weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "#weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "\n",
        "counter = Counter(split0['y_train'])\n",
        "my_weight2 = {}\n",
        "print(counter)\n",
        "\n",
        "for genre in counter:\n",
        "  #print(genre, counter[genre])\n",
        "  my_weight2[genre] = (1/counter[genre]) * (SUM/10)\n",
        "my_weight2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbDe9DVFAvjP",
        "outputId": "b77aaacf-845e-4fcf-bd67-52038268a8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({4: 4143, 7: 1159, 9: 1030, 3: 865, 6: 783, 0: 763, 1: 690, 8: 556, 2: 537, 5: 306})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 0.2614530533429882,\n",
              " 9: 1.051650485436893,\n",
              " 6: 1.383397190293742,\n",
              " 2: 2.0171322160148977,\n",
              " 0: 1.4196592398427261,\n",
              " 7: 0.9345987920621226,\n",
              " 1: 1.569855072463768,\n",
              " 5: 3.539869281045752,\n",
              " 8: 1.948201438848921,\n",
              " 3: 1.2522543352601156}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE = len(split0['X_test'])"
      ],
      "metadata": {
        "id": "v2k3GgdtcGz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hb8xkWQ3FOo"
      },
      "outputs": [],
      "source": [
        "def map_func_only_X(val_dictionary, labels):\n",
        "  return {'input_ids': val_dictionary['input_ids'], 'attention_mask':val_dictionary['attention_mask']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3S2rOmEq3FOp"
      },
      "outputs": [],
      "source": [
        "def map_func_only_y(val_dictionary, labels):\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Fold Do parameter tuning for dropout rate"
      ],
      "metadata": {
        "id": "tkFQndSlD2y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[0]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "DS_LEN = len(list(dataset_train))\n",
        "SPLIT = 0.9\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0yzE2a18YHz",
        "outputId": "5690f4c3-762e-412d-a1bf-f7ffa48898b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have intentionally separated cells for check point purpose, based on dropout rates"
      ],
      "metadata": {
        "id": "LOB9bJ7jdEov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameter = []#(drop_out_rate, initial_rate, fine_tune_learning_rate)"
      ],
      "metadata": {
        "id": "fTKuKu-KjYwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar={}\n",
        "balanced_accuracies_transfer_learning=[]\n",
        "balanced_accuracies_fine_tuning = []"
      ],
      "metadata": {
        "id": "bvizO_xTliMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(model1)"
      ],
      "metadata": {
        "id": "omnIdETZmbg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.1\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    #model2.summary()\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bf922c8f428444c08622abc048d16c57",
            "cdf80bd13f334c5985032c1206d793af",
            "0ba6cc9cf60e4e21ba2b097389544d3d",
            "f6b01f0a84314988bdc219e3a6772ac5",
            "de06093f8f35498cbb07ad8cfe599b45",
            "cc9b821cb0e84ef2a7e6ced1acc4521b",
            "09d2157428df45e69608ec3e66a9a082",
            "cc46237759d248dfba9999388d2ea923",
            "ca97ba6cd13044e5a43ee81bc98510be",
            "03f69e3b9a164d1c91a3341490e88a03",
            "b5d74376254e42da916bedc2615c74d4"
          ]
        },
        "id": "oFsobW4gcvIf",
        "outputId": "503c0ab5-dd6c-451f-c5ed-1aec51fde248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf922c8f428444c08622abc048d16c57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 96s 135ms/step - loss: 2.1319 - categorical_accuracy: 0.2347 - val_loss: 2.0921 - val_categorical_accuracy: 0.2105\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.9408 - categorical_accuracy: 0.2729 - val_loss: 2.0875 - val_categorical_accuracy: 0.2022\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8647 - categorical_accuracy: 0.2935 - val_loss: 2.0850 - val_categorical_accuracy: 0.2077\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8166 - categorical_accuracy: 0.3032 - val_loss: 2.0649 - val_categorical_accuracy: 0.2371\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.7702 - categorical_accuracy: 0.3107 - val_loss: 2.0454 - val_categorical_accuracy: 0.2417\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.7220 - categorical_accuracy: 0.3264 - val_loss: 2.0349 - val_categorical_accuracy: 0.2289\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.28      0.19       190\n",
            "         1.0       0.19      0.40      0.25       173\n",
            "         2.0       0.07      0.07      0.07       135\n",
            "         3.0       0.12      0.30      0.17       216\n",
            "         4.0       0.71      0.10      0.17      1036\n",
            "         5.0       0.16      0.18      0.17        76\n",
            "         6.0       0.78      0.69      0.73       195\n",
            "         7.0       0.12      0.02      0.04       290\n",
            "         8.0       0.09      0.25      0.13       139\n",
            "         9.0       0.22      0.40      0.28       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.26      0.27      0.22      2708\n",
            "weighted avg       0.41      0.22      0.21      2708\n",
            "\n",
            "0.26951872844155317\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 203s 306ms/step - loss: 1.6609 - categorical_accuracy: 0.3315 - val_loss: 2.0087 - val_categorical_accuracy: 0.2390\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.4871 - categorical_accuracy: 0.3785 - val_loss: 2.0253 - val_categorical_accuracy: 0.2574\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.3338 - categorical_accuracy: 0.4262 - val_loss: 1.9874 - val_categorical_accuracy: 0.2638\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.2325 - categorical_accuracy: 0.4674 - val_loss: 1.9207 - val_categorical_accuracy: 0.3015\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.1124 - categorical_accuracy: 0.5087 - val_loss: 1.8872 - val_categorical_accuracy: 0.3033\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.0131 - categorical_accuracy: 0.5400 - val_loss: 1.7818 - val_categorical_accuracy: 0.3171\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.36      0.23       190\n",
            "         1.0       0.26      0.38      0.31       173\n",
            "         2.0       0.11      0.10      0.10       135\n",
            "         3.0       0.22      0.30      0.25       216\n",
            "         4.0       0.66      0.21      0.32      1036\n",
            "         5.0       0.28      0.29      0.28        76\n",
            "         6.0       0.87      0.70      0.77       195\n",
            "         7.0       0.20      0.08      0.11       290\n",
            "         8.0       0.18      0.22      0.19       139\n",
            "         9.0       0.20      0.62      0.30       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.31      0.32      0.29      2708\n",
            "weighted avg       0.42      0.30      0.30      2708\n",
            "\n",
            "0.3237741050580876\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.1473 - categorical_accuracy: 0.2212 - val_loss: 2.2279 - val_categorical_accuracy: 0.1829\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9332 - categorical_accuracy: 0.2876 - val_loss: 2.1640 - val_categorical_accuracy: 0.2132\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8633 - categorical_accuracy: 0.3019 - val_loss: 2.1020 - val_categorical_accuracy: 0.2279\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8000 - categorical_accuracy: 0.3178 - val_loss: 2.1010 - val_categorical_accuracy: 0.2353\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.7647 - categorical_accuracy: 0.3313 - val_loss: 2.0504 - val_categorical_accuracy: 0.2390\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.7099 - categorical_accuracy: 0.3393 - val_loss: 2.1037 - val_categorical_accuracy: 0.2472\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.31      0.19       190\n",
            "         1.0       0.17      0.20      0.18       173\n",
            "         2.0       0.05      0.05      0.05       135\n",
            "         3.0       0.13      0.18      0.15       216\n",
            "         4.0       0.73      0.17      0.27      1036\n",
            "         5.0       0.15      0.28      0.20        76\n",
            "         6.0       0.74      0.69      0.72       195\n",
            "         7.0       0.14      0.06      0.08       290\n",
            "         8.0       0.09      0.50      0.16       139\n",
            "         9.0       0.21      0.19      0.20       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.26      0.26      0.22      2708\n",
            "weighted avg       0.41      0.22      0.24      2708\n",
            "\n",
            "0.2616760652211218\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 203s 307ms/step - loss: 1.6337 - categorical_accuracy: 0.3768 - val_loss: 2.0904 - val_categorical_accuracy: 0.2362\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.5721 - categorical_accuracy: 0.3933 - val_loss: 2.0658 - val_categorical_accuracy: 0.2509\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.5512 - categorical_accuracy: 0.3962 - val_loss: 2.0876 - val_categorical_accuracy: 0.2426\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.5234 - categorical_accuracy: 0.3987 - val_loss: 2.0804 - val_categorical_accuracy: 0.2445\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.4948 - categorical_accuracy: 0.4064 - val_loss: 2.0830 - val_categorical_accuracy: 0.2528\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.4758 - categorical_accuracy: 0.4143 - val_loss: 2.0677 - val_categorical_accuracy: 0.2491\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.32      0.19       190\n",
            "         1.0       0.17      0.27      0.21       173\n",
            "         2.0       0.08      0.10      0.09       135\n",
            "         3.0       0.15      0.24      0.19       216\n",
            "         4.0       0.74      0.17      0.27      1036\n",
            "         5.0       0.15      0.45      0.23        76\n",
            "         6.0       0.75      0.74      0.75       195\n",
            "         7.0       0.11      0.03      0.04       290\n",
            "         8.0       0.09      0.29      0.14       139\n",
            "         9.0       0.24      0.31      0.27       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.26      0.29      0.24      2708\n",
            "weighted avg       0.42      0.24      0.25      2708\n",
            "\n",
            "0.29083315501973894\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 95s 136ms/step - loss: 2.3780 - categorical_accuracy: 0.1911 - val_loss: 2.3196 - val_categorical_accuracy: 0.1691\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.1655 - categorical_accuracy: 0.2341 - val_loss: 2.2731 - val_categorical_accuracy: 0.1884\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.0569 - categorical_accuracy: 0.2648 - val_loss: 2.2394 - val_categorical_accuracy: 0.2022\n",
            "Epoch 4/6\n",
            " 50/609 [=>............................] - ETA: 1:06 - loss: 1.9891 - categorical_accuracy: 0.2837"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-5baa70aaa61f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m#step3: transfer learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_categorical_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_weight2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#step4: predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resume from the last cell"
      ],
      "metadata": {
        "id": "IhTmNwtg8lLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameter.append((0.1, 1e-3, 1e-5))\n",
        "seen_parameter.append((0.1, 1e-3, 1e-6))\n",
        "seen_parameter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeJmDtsk8oNV",
        "outputId": "72c99f89-5cf1-4b4f-bed4-c7e45e7c88b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.1, 0.001, 1e-05), (0.1, 0.001, 1e-06)]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameter.remove((0.1, [0.001, 0.0001], [1e-05, 1e-06]))\n",
        "seen_parameter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OLN5AouEKxd",
        "outputId": "381b4b0d-c8db-4caf-b30b-80617babd47c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.1, 0.001, 1e-05), (0.1, 0.001, 1e-06)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.1\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    if (drop_out_rate, learning_rate_transfer_learning, learning_rate_fine_tuning) not in seen_parameter:\n",
        "      seen_parameter.append( (drop_out_rate, learning_rate_transfer_learning, learning_rate_fine_tuning) )\n",
        "      print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "      , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "      #step1\n",
        "      bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "      input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "      mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "      embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "      X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "      X = tf.keras.layers.BatchNormalization()(X)\n",
        "      X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "      X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "      X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "      y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "      model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "      model1.layers[2].trainable = False\n",
        "      #model2.summary()\n",
        "\n",
        "      #step2\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "      metrics = []\n",
        "      metrics.append(\n",
        "          tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "      model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "      #model2.summary() #Check trainable params increased.\n",
        "\n",
        "      #step3: transfer learning\n",
        "      early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "      history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "      #step4: predict\n",
        "      balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "      balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "      #step5: fine tune\n",
        "      print(\"Fine tuning---------------\")\n",
        "      model1.layers[2].trainable = True\n",
        "\n",
        "      # It's important to recompile your model after you make any changes\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "      metrics = []\n",
        "      metrics.append(\n",
        "          tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "      model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "      history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "      balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "      balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "      print(\"----------------------------------------\")\n",
        "      del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POhlmaR281uQ",
        "outputId": "e9fb08ca-b386-4d22-8a32-3de30c886b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 134ms/step - loss: 2.3379 - categorical_accuracy: 0.1751 - val_loss: 2.2345 - val_categorical_accuracy: 0.1792\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.1498 - categorical_accuracy: 0.2226 - val_loss: 2.1989 - val_categorical_accuracy: 0.1820\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.0597 - categorical_accuracy: 0.2433 - val_loss: 2.1829 - val_categorical_accuracy: 0.1958\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.0020 - categorical_accuracy: 0.2677 - val_loss: 2.1751 - val_categorical_accuracy: 0.2151\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.9775 - categorical_accuracy: 0.2714 - val_loss: 2.1667 - val_categorical_accuracy: 0.2142\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.9377 - categorical_accuracy: 0.2838 - val_loss: 2.1869 - val_categorical_accuracy: 0.2059\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.24      0.18       190\n",
            "         1.0       0.13      0.35      0.19       173\n",
            "         2.0       0.06      0.10      0.07       135\n",
            "         3.0       0.12      0.07      0.09       216\n",
            "         4.0       0.66      0.11      0.18      1036\n",
            "         5.0       0.10      0.59      0.17        76\n",
            "         6.0       0.71      0.68      0.69       195\n",
            "         7.0       0.14      0.09      0.11       290\n",
            "         8.0       0.08      0.14      0.10       139\n",
            "         9.0       0.19      0.22      0.21       258\n",
            "\n",
            "    accuracy                           0.19      2708\n",
            "   macro avg       0.23      0.26      0.20      2708\n",
            "weighted avg       0.37      0.19      0.20      2708\n",
            "\n",
            "0.2593649889183469\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 202s 308ms/step - loss: 1.8963 - categorical_accuracy: 0.2941 - val_loss: 2.0672 - val_categorical_accuracy: 0.2344\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.7437 - categorical_accuracy: 0.3323 - val_loss: 2.0995 - val_categorical_accuracy: 0.2353\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.6397 - categorical_accuracy: 0.3580 - val_loss: 2.0585 - val_categorical_accuracy: 0.2785\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.5056 - categorical_accuracy: 0.3900 - val_loss: 1.9967 - val_categorical_accuracy: 0.2785\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.3985 - categorical_accuracy: 0.4325 - val_loss: 2.0502 - val_categorical_accuracy: 0.2546\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.3024 - categorical_accuracy: 0.4699 - val_loss: 2.0000 - val_categorical_accuracy: 0.2730\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.29      0.21       190\n",
            "         1.0       0.19      0.48      0.27       173\n",
            "         2.0       0.11      0.16      0.13       135\n",
            "         3.0       0.17      0.20      0.18       216\n",
            "         4.0       0.76      0.16      0.27      1036\n",
            "         5.0       0.18      0.45      0.25        76\n",
            "         6.0       0.75      0.81      0.78       195\n",
            "         7.0       0.13      0.07      0.09       290\n",
            "         8.0       0.11      0.12      0.12       139\n",
            "         9.0       0.25      0.54      0.34       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.28      0.33      0.26      2708\n",
            "weighted avg       0.44      0.27      0.27      2708\n",
            "\n",
            "0.3273937031540135\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 93s 134ms/step - loss: 2.3302 - categorical_accuracy: 0.1521 - val_loss: 2.2585 - val_categorical_accuracy: 0.1710\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.1365 - categorical_accuracy: 0.2204 - val_loss: 2.2393 - val_categorical_accuracy: 0.1884\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0479 - categorical_accuracy: 0.2556 - val_loss: 2.2114 - val_categorical_accuracy: 0.2040\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9987 - categorical_accuracy: 0.2705 - val_loss: 2.1893 - val_categorical_accuracy: 0.2160\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9606 - categorical_accuracy: 0.2868 - val_loss: 2.1765 - val_categorical_accuracy: 0.2215\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9335 - categorical_accuracy: 0.2916 - val_loss: 2.1924 - val_categorical_accuracy: 0.2142\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.18      0.13       190\n",
            "         1.0       0.15      0.34      0.20       173\n",
            "         2.0       0.06      0.06      0.06       135\n",
            "         3.0       0.14      0.14      0.14       216\n",
            "         4.0       0.68      0.18      0.29      1036\n",
            "         5.0       0.10      0.57      0.18        76\n",
            "         6.0       0.72      0.69      0.70       195\n",
            "         7.0       0.15      0.09      0.11       290\n",
            "         8.0       0.09      0.21      0.12       139\n",
            "         9.0       0.21      0.20      0.21       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.24      0.27      0.21      2708\n",
            "weighted avg       0.39      0.22      0.24      2708\n",
            "\n",
            "0.2655522630561761\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 203s 306ms/step - loss: 1.8778 - categorical_accuracy: 0.2889 - val_loss: 2.1768 - val_categorical_accuracy: 0.2169\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.8521 - categorical_accuracy: 0.3012 - val_loss: 2.1548 - val_categorical_accuracy: 0.2142\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.8291 - categorical_accuracy: 0.2991 - val_loss: 2.1823 - val_categorical_accuracy: 0.2151\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.8017 - categorical_accuracy: 0.3156 - val_loss: 2.1226 - val_categorical_accuracy: 0.2325\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.7792 - categorical_accuracy: 0.3224 - val_loss: 2.1187 - val_categorical_accuracy: 0.2362\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.7477 - categorical_accuracy: 0.3291 - val_loss: 2.1155 - val_categorical_accuracy: 0.2381\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.20      0.16       190\n",
            "         1.0       0.17      0.46      0.25       173\n",
            "         2.0       0.06      0.05      0.06       135\n",
            "         3.0       0.15      0.13      0.14       216\n",
            "         4.0       0.71      0.22      0.34      1036\n",
            "         5.0       0.10      0.62      0.18        76\n",
            "         6.0       0.72      0.74      0.73       195\n",
            "         7.0       0.14      0.06      0.09       290\n",
            "         8.0       0.11      0.22      0.15       139\n",
            "         9.0       0.23      0.26      0.25       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.25      0.30      0.23      2708\n",
            "weighted avg       0.41      0.26      0.27      2708\n",
            "\n",
            "0.2970803838278379\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.2\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    #model2.summary()\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOMVmR3_D5W1",
        "outputId": "dab0a33d-8e04-4be0-9d61-716a806d3e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 92s 133ms/step - loss: 2.1491 - categorical_accuracy: 0.2292 - val_loss: 2.1187 - val_categorical_accuracy: 0.2362\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 78s 129ms/step - loss: 1.9675 - categorical_accuracy: 0.2652 - val_loss: 2.1160 - val_categorical_accuracy: 0.2233\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 78s 128ms/step - loss: 1.9018 - categorical_accuracy: 0.2834 - val_loss: 2.1071 - val_categorical_accuracy: 0.2381\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 78s 128ms/step - loss: 1.8360 - categorical_accuracy: 0.3011 - val_loss: 2.0411 - val_categorical_accuracy: 0.2675\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 78s 128ms/step - loss: 1.8013 - categorical_accuracy: 0.2990 - val_loss: 2.0653 - val_categorical_accuracy: 0.2583\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 78s 129ms/step - loss: 1.7748 - categorical_accuracy: 0.3103 - val_loss: 2.0972 - val_categorical_accuracy: 0.2279\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.27      0.18       190\n",
            "         1.0       0.14      0.38      0.21       173\n",
            "         2.0       0.12      0.19      0.14       135\n",
            "         3.0       0.15      0.21      0.17       216\n",
            "         4.0       0.77      0.19      0.30      1036\n",
            "         5.0       0.13      0.50      0.20        76\n",
            "         6.0       0.76      0.67      0.71       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.08      0.24      0.12       139\n",
            "         9.0       0.29      0.25      0.27       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.26      0.29      0.23      2708\n",
            "weighted avg       0.42      0.24      0.25      2708\n",
            "\n",
            "0.28828399026951834\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 202s 306ms/step - loss: 1.7087 - categorical_accuracy: 0.3258 - val_loss: 2.0464 - val_categorical_accuracy: 0.2224\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.5673 - categorical_accuracy: 0.3625 - val_loss: 1.9821 - val_categorical_accuracy: 0.2665\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.4333 - categorical_accuracy: 0.4021 - val_loss: 1.9711 - val_categorical_accuracy: 0.2353\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.3306 - categorical_accuracy: 0.4271 - val_loss: 1.9967 - val_categorical_accuracy: 0.2583\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.2276 - categorical_accuracy: 0.4626 - val_loss: 1.9567 - val_categorical_accuracy: 0.2941\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.1260 - categorical_accuracy: 0.4968 - val_loss: 1.9989 - val_categorical_accuracy: 0.2822\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.25      0.18       190\n",
            "         1.0       0.18      0.57      0.27       173\n",
            "         2.0       0.13      0.19      0.15       135\n",
            "         3.0       0.17      0.23      0.19       216\n",
            "         4.0       0.76      0.21      0.32      1036\n",
            "         5.0       0.18      0.41      0.25        76\n",
            "         6.0       0.77      0.78      0.78       195\n",
            "         7.0       0.19      0.03      0.05       290\n",
            "         8.0       0.10      0.17      0.13       139\n",
            "         9.0       0.28      0.45      0.35       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.29      0.33      0.27      2708\n",
            "weighted avg       0.45      0.28      0.28      2708\n",
            "\n",
            "0.3283639772665433\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 93s 133ms/step - loss: 2.1620 - categorical_accuracy: 0.2290 - val_loss: 2.1240 - val_categorical_accuracy: 0.2390\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 78s 129ms/step - loss: 1.9556 - categorical_accuracy: 0.2834 - val_loss: 2.1211 - val_categorical_accuracy: 0.2426\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.9017 - categorical_accuracy: 0.2955 - val_loss: 2.0691 - val_categorical_accuracy: 0.2472\n",
            "Epoch 4/6\n",
            "581/609 [===========================>..] - ETA: 3s - loss: 1.8363 - categorical_accuracy: 0.3096"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resume from the last"
      ],
      "metadata": {
        "id": "YOkZnI-knPgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameters=[]\n",
        "seen_parameters.append((0.2,1e-3,1e-5))"
      ],
      "metadata": {
        "id": "ruOpXRy9nQ_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.2\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    if (drop_out_rate, learning_rate_transfer_learning, learning_rate_fine_tuning) not in seen_parameters:\n",
        "      seen_parameters.append( (drop_out_rate, learning_rate_transfer_learning, learning_rate_fine_tuning) )\n",
        "      print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "      , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "      #step1\n",
        "      bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "      input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "      mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "      embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "      X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "      X = tf.keras.layers.BatchNormalization()(X)\n",
        "      X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "      X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "      X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "      y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "      model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "      model1.layers[2].trainable = False\n",
        "      #model2.summary()\n",
        "\n",
        "      #step2\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "      metrics = []\n",
        "      metrics.append(\n",
        "          tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "      model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "      #model2.summary() #Check trainable params increased.\n",
        "\n",
        "      #step3: transfer learning\n",
        "      early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "      history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "      #step4: predict\n",
        "      balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "      balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "      #step5: fine tune\n",
        "      print(\"Fine tuning---------------\")\n",
        "      model1.layers[2].trainable = True\n",
        "\n",
        "      # It's important to recompile your model after you make any changes\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "      metrics = []\n",
        "      metrics.append(\n",
        "          tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "      model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "      history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "      balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "      balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "      print(\"----------------------------------------\")\n",
        "      del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "98d36cfd45f44e26bc7761ce59547224",
            "81af9be098414483a2e849398b4452bc",
            "24bf4b150cda4c6a9225b58a3dab4205",
            "4ebdb75059d24ee0958be4681081a12d",
            "70831f80e4664f5698feab1ae159677c",
            "4f610941746d4e3d8315daa1f4c1c7e6",
            "f7e0775716c94358b7e2e77526a293c3",
            "fa26e687eb3a484383c9533ade31c304",
            "837e939a7d6540d6b77a96c842661f98",
            "72d229c28fb145f7aa3cef7d7be72abb",
            "5373dde9ca214785a80323cd11f48937"
          ]
        },
        "id": "43vl44rSnep2",
        "outputId": "fa539fb8-a6d4-4188-92d0-3a838b6b8500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98d36cfd45f44e26bc7761ce59547224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 95s 135ms/step - loss: 2.1516 - categorical_accuracy: 0.2358 - val_loss: 2.1618 - val_categorical_accuracy: 0.2151\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.9699 - categorical_accuracy: 0.2759 - val_loss: 2.1554 - val_categorical_accuracy: 0.2132\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9137 - categorical_accuracy: 0.2942 - val_loss: 2.0845 - val_categorical_accuracy: 0.2316\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8559 - categorical_accuracy: 0.2944 - val_loss: 2.1245 - val_categorical_accuracy: 0.2188\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8044 - categorical_accuracy: 0.3085 - val_loss: 2.1073 - val_categorical_accuracy: 0.2371\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.7854 - categorical_accuracy: 0.3059 - val_loss: 2.0825 - val_categorical_accuracy: 0.2270\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.22      0.17       190\n",
            "         1.0       0.15      0.58      0.24       173\n",
            "         2.0       0.07      0.10      0.08       135\n",
            "         3.0       0.12      0.14      0.13       216\n",
            "         4.0       0.78      0.14      0.23      1036\n",
            "         5.0       0.11      0.25      0.15        76\n",
            "         6.0       0.71      0.75      0.73       195\n",
            "         7.0       0.16      0.05      0.07       290\n",
            "         8.0       0.05      0.13      0.08       139\n",
            "         9.0       0.27      0.32      0.29       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.26      0.27      0.22      2708\n",
            "weighted avg       0.43      0.22      0.23      2708\n",
            "\n",
            "0.26717698764606007\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 202s 305ms/step - loss: 1.7083 - categorical_accuracy: 0.3323 - val_loss: 2.0581 - val_categorical_accuracy: 0.2472\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6699 - categorical_accuracy: 0.3341 - val_loss: 2.0557 - val_categorical_accuracy: 0.2574\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6432 - categorical_accuracy: 0.3485 - val_loss: 2.0499 - val_categorical_accuracy: 0.2546\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6294 - categorical_accuracy: 0.3431 - val_loss: 2.0597 - val_categorical_accuracy: 0.2482\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6033 - categorical_accuracy: 0.3543 - val_loss: 2.0543 - val_categorical_accuracy: 0.2555\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.24      0.18       190\n",
            "         1.0       0.17      0.56      0.26       173\n",
            "         2.0       0.07      0.11      0.09       135\n",
            "         3.0       0.15      0.15      0.15       216\n",
            "         4.0       0.77      0.17      0.28      1036\n",
            "         5.0       0.13      0.47      0.21        76\n",
            "         6.0       0.77      0.74      0.76       195\n",
            "         7.0       0.19      0.06      0.09       290\n",
            "         8.0       0.07      0.14      0.10       139\n",
            "         9.0       0.26      0.35      0.30       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.27      0.30      0.24      2708\n",
            "weighted avg       0.44      0.25      0.26      2708\n",
            "\n",
            "0.2996607275202534\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.3913 - categorical_accuracy: 0.2151 - val_loss: 2.3193 - val_categorical_accuracy: 0.1875\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1941 - categorical_accuracy: 0.2423 - val_loss: 2.2854 - val_categorical_accuracy: 0.2077\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.1124 - categorical_accuracy: 0.2613 - val_loss: 2.2725 - val_categorical_accuracy: 0.2031\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.0562 - categorical_accuracy: 0.2767 - val_loss: 2.2420 - val_categorical_accuracy: 0.2151\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.0091 - categorical_accuracy: 0.2894 - val_loss: 2.2246 - val_categorical_accuracy: 0.2188\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.9640 - categorical_accuracy: 0.2984 - val_loss: 2.1857 - val_categorical_accuracy: 0.2206\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.26      0.15       190\n",
            "         1.0       0.16      0.37      0.22       173\n",
            "         2.0       0.05      0.08      0.06       135\n",
            "         3.0       0.15      0.15      0.15       216\n",
            "         4.0       0.70      0.19      0.30      1036\n",
            "         5.0       0.09      0.30      0.14        76\n",
            "         6.0       0.70      0.68      0.69       195\n",
            "         7.0       0.12      0.14      0.13       290\n",
            "         8.0       0.03      0.03      0.03       139\n",
            "         9.0       0.24      0.18      0.20       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.23      0.24      0.21      2708\n",
            "weighted avg       0.39      0.22      0.24      2708\n",
            "\n",
            "0.2380639106664288\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 201s 305ms/step - loss: 1.9258 - categorical_accuracy: 0.3061 - val_loss: 2.0286 - val_categorical_accuracy: 0.2849\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.7943 - categorical_accuracy: 0.3421 - val_loss: 2.3040 - val_categorical_accuracy: 0.2105\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6855 - categorical_accuracy: 0.3704 - val_loss: 2.1378 - val_categorical_accuracy: 0.2739\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.5812 - categorical_accuracy: 0.4054 - val_loss: 2.1208 - val_categorical_accuracy: 0.2583\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.24      0.21       190\n",
            "         1.0       0.14      0.73      0.24       173\n",
            "         2.0       0.06      0.07      0.07       135\n",
            "         3.0       0.22      0.13      0.16       216\n",
            "         4.0       0.71      0.19      0.29      1036\n",
            "         5.0       0.17      0.38      0.24        76\n",
            "         6.0       0.74      0.77      0.75       195\n",
            "         7.0       0.15      0.07      0.10       290\n",
            "         8.0       0.07      0.06      0.06       139\n",
            "         9.0       0.24      0.37      0.29       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.27      0.30      0.24      2708\n",
            "weighted avg       0.41      0.26      0.26      2708\n",
            "\n",
            "0.3008972561338559\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.4167 - categorical_accuracy: 0.1215 - val_loss: 2.3608 - val_categorical_accuracy: 0.1241\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1944 - categorical_accuracy: 0.1866 - val_loss: 2.2745 - val_categorical_accuracy: 0.1517\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1009 - categorical_accuracy: 0.2241 - val_loss: 2.2354 - val_categorical_accuracy: 0.1590\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.0422 - categorical_accuracy: 0.2475 - val_loss: 2.2182 - val_categorical_accuracy: 0.1737\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9931 - categorical_accuracy: 0.2672 - val_loss: 2.1976 - val_categorical_accuracy: 0.1801\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9613 - categorical_accuracy: 0.2813 - val_loss: 2.1860 - val_categorical_accuracy: 0.1866\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.26      0.17       190\n",
            "         1.0       0.14      0.35      0.20       173\n",
            "         2.0       0.05      0.08      0.07       135\n",
            "         3.0       0.09      0.07      0.08       216\n",
            "         4.0       0.72      0.10      0.18      1036\n",
            "         5.0       0.07      0.47      0.13        76\n",
            "         6.0       0.74      0.70      0.72       195\n",
            "         7.0       0.10      0.02      0.03       290\n",
            "         8.0       0.07      0.17      0.10       139\n",
            "         9.0       0.23      0.29      0.26       258\n",
            "\n",
            "    accuracy                           0.19      2708\n",
            "   macro avg       0.24      0.25      0.19      2708\n",
            "weighted avg       0.39      0.19      0.19      2708\n",
            "\n",
            "0.2520201054579968\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 201s 305ms/step - loss: 1.9227 - categorical_accuracy: 0.2879 - val_loss: 2.1677 - val_categorical_accuracy: 0.1912\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.8981 - categorical_accuracy: 0.2856 - val_loss: 2.1523 - val_categorical_accuracy: 0.1866\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.8679 - categorical_accuracy: 0.3030 - val_loss: 2.1551 - val_categorical_accuracy: 0.1884\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.8315 - categorical_accuracy: 0.3069 - val_loss: 2.1518 - val_categorical_accuracy: 0.1967\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.8190 - categorical_accuracy: 0.3153 - val_loss: 2.1215 - val_categorical_accuracy: 0.2040\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.7975 - categorical_accuracy: 0.3138 - val_loss: 2.1320 - val_categorical_accuracy: 0.1976\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.27      0.20       190\n",
            "         1.0       0.17      0.42      0.24       173\n",
            "         2.0       0.08      0.11      0.09       135\n",
            "         3.0       0.08      0.04      0.06       216\n",
            "         4.0       0.76      0.11      0.20      1036\n",
            "         5.0       0.09      0.66      0.16        76\n",
            "         6.0       0.70      0.76      0.73       195\n",
            "         7.0       0.10      0.01      0.02       290\n",
            "         8.0       0.10      0.18      0.13       139\n",
            "         9.0       0.21      0.36      0.27       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.25      0.29      0.21      2708\n",
            "weighted avg       0.41      0.22      0.21      2708\n",
            "\n",
            "0.29241712238875217\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.3\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    #model2.summary()\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXi-tHm1z2jA",
        "outputId": "95115eac-3cc3-45ec-b3c7-2c5082834b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.1653 - categorical_accuracy: 0.2192 - val_loss: 2.1321 - val_categorical_accuracy: 0.2390\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.9952 - categorical_accuracy: 0.2704 - val_loss: 2.0991 - val_categorical_accuracy: 0.2169\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.9373 - categorical_accuracy: 0.3002 - val_loss: 2.1141 - val_categorical_accuracy: 0.2197\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8860 - categorical_accuracy: 0.3019 - val_loss: 2.0813 - val_categorical_accuracy: 0.2371\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.21      0.18       190\n",
            "         1.0       0.13      0.47      0.20       173\n",
            "         2.0       0.01      0.01      0.01       135\n",
            "         3.0       0.14      0.14      0.14       216\n",
            "         4.0       0.70      0.22      0.34      1036\n",
            "         5.0       0.10      0.47      0.17        76\n",
            "         6.0       0.76      0.72      0.74       195\n",
            "         7.0       0.21      0.02      0.04       290\n",
            "         8.0       0.09      0.22      0.13       139\n",
            "         9.0       0.23      0.23      0.23       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.25      0.27      0.22      2708\n",
            "weighted avg       0.40      0.24      0.26      2708\n",
            "\n",
            "0.27348924409011494\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 201s 305ms/step - loss: 1.8114 - categorical_accuracy: 0.3343 - val_loss: 2.1019 - val_categorical_accuracy: 0.2243\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6854 - categorical_accuracy: 0.3645 - val_loss: 2.0400 - val_categorical_accuracy: 0.2518\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.5842 - categorical_accuracy: 0.3850 - val_loss: 1.9871 - val_categorical_accuracy: 0.2730\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.4992 - categorical_accuracy: 0.4056 - val_loss: 1.9411 - val_categorical_accuracy: 0.2950\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.4189 - categorical_accuracy: 0.4220 - val_loss: 1.9245 - val_categorical_accuracy: 0.2904\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.3299 - categorical_accuracy: 0.4457 - val_loss: 2.0824 - val_categorical_accuracy: 0.2472\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.35      0.22       190\n",
            "         1.0       0.17      0.51      0.25       173\n",
            "         2.0       0.06      0.05      0.05       135\n",
            "         3.0       0.17      0.20      0.18       216\n",
            "         4.0       0.75      0.20      0.31      1036\n",
            "         5.0       0.14      0.62      0.23        76\n",
            "         6.0       0.74      0.80      0.77       195\n",
            "         7.0       0.27      0.02      0.04       290\n",
            "         8.0       0.12      0.20      0.15       139\n",
            "         9.0       0.30      0.38      0.34       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.29      0.33      0.26      2708\n",
            "weighted avg       0.45      0.27      0.27      2708\n",
            "\n",
            "0.33314381178094327\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 95s 136ms/step - loss: 2.1763 - categorical_accuracy: 0.2279 - val_loss: 2.1583 - val_categorical_accuracy: 0.2335\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9870 - categorical_accuracy: 0.2943 - val_loss: 2.0687 - val_categorical_accuracy: 0.2619\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9127 - categorical_accuracy: 0.2982 - val_loss: 2.0945 - val_categorical_accuracy: 0.2601\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8885 - categorical_accuracy: 0.3024 - val_loss: 2.0560 - val_categorical_accuracy: 0.2546\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8350 - categorical_accuracy: 0.3045 - val_loss: 2.0325 - val_categorical_accuracy: 0.2564\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.24      0.15       190\n",
            "         1.0       0.17      0.58      0.26       173\n",
            "         2.0       0.09      0.13      0.11       135\n",
            "         3.0       0.13      0.20      0.16       216\n",
            "         4.0       0.68      0.27      0.39      1036\n",
            "         5.0       0.15      0.42      0.22        76\n",
            "         6.0       0.75      0.69      0.72       195\n",
            "         7.0       0.10      0.01      0.01       290\n",
            "         8.0       0.09      0.08      0.08       139\n",
            "         9.0       0.25      0.22      0.24       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.25      0.29      0.24      2708\n",
            "weighted avg       0.39      0.27      0.28      2708\n",
            "\n",
            "0.28564621162103326\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 202s 306ms/step - loss: 1.7766 - categorical_accuracy: 0.3312 - val_loss: 2.0072 - val_categorical_accuracy: 0.2748\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.7497 - categorical_accuracy: 0.3372 - val_loss: 2.0068 - val_categorical_accuracy: 0.2757\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 184s 302ms/step - loss: 1.7262 - categorical_accuracy: 0.3367 - val_loss: 2.0083 - val_categorical_accuracy: 0.2831\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6925 - categorical_accuracy: 0.3444 - val_loss: 1.9792 - val_categorical_accuracy: 0.2904\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6830 - categorical_accuracy: 0.3463 - val_loss: 1.9964 - val_categorical_accuracy: 0.2868\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6483 - categorical_accuracy: 0.3580 - val_loss: 1.9886 - val_categorical_accuracy: 0.2923\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.28      0.17       190\n",
            "         1.0       0.19      0.56      0.29       173\n",
            "         2.0       0.08      0.12      0.10       135\n",
            "         3.0       0.15      0.18      0.16       216\n",
            "         4.0       0.70      0.29      0.41      1036\n",
            "         5.0       0.14      0.57      0.22        76\n",
            "         6.0       0.77      0.74      0.75       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.09      0.07      0.08       139\n",
            "         9.0       0.25      0.25      0.25       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.25      0.31      0.24      2708\n",
            "weighted avg       0.39      0.28      0.29      2708\n",
            "\n",
            "0.3051248873716309\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.5364 - categorical_accuracy: 0.1238 - val_loss: 2.2467 - val_categorical_accuracy: 0.1452\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.2420 - categorical_accuracy: 0.1767 - val_loss: 2.2205 - val_categorical_accuracy: 0.1645\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.1359 - categorical_accuracy: 0.2172 - val_loss: 2.2164 - val_categorical_accuracy: 0.1691\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.0751 - categorical_accuracy: 0.2328 - val_loss: 2.1977 - val_categorical_accuracy: 0.1921\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0337 - categorical_accuracy: 0.2496 - val_loss: 2.1751 - val_categorical_accuracy: 0.1921\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.0032 - categorical_accuracy: 0.2621 - val_loss: 2.1710 - val_categorical_accuracy: 0.1884\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.15      0.12       190\n",
            "         1.0       0.15      0.32      0.20       173\n",
            "         2.0       0.03      0.03      0.03       135\n",
            "         3.0       0.11      0.12      0.11       216\n",
            "         4.0       0.75      0.12      0.21      1036\n",
            "         5.0       0.08      0.58      0.13        76\n",
            "         6.0       0.70      0.65      0.68       195\n",
            "         7.0       0.14      0.12      0.13       290\n",
            "         8.0       0.05      0.10      0.07       139\n",
            "         9.0       0.25      0.21      0.22       258\n",
            "\n",
            "    accuracy                           0.19      2708\n",
            "   macro avg       0.23      0.24      0.19      2708\n",
            "weighted avg       0.41      0.19      0.20      2708\n",
            "\n",
            "0.24013837363714066\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 201s 305ms/step - loss: 1.9329 - categorical_accuracy: 0.2825 - val_loss: 2.0349 - val_categorical_accuracy: 0.2270\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.8183 - categorical_accuracy: 0.3053 - val_loss: 2.0005 - val_categorical_accuracy: 0.2693\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.7409 - categorical_accuracy: 0.3212 - val_loss: 1.8667 - val_categorical_accuracy: 0.3180\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6407 - categorical_accuracy: 0.3551 - val_loss: 2.1285 - val_categorical_accuracy: 0.2445\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.5492 - categorical_accuracy: 0.3797 - val_loss: 1.7971 - val_categorical_accuracy: 0.3483\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.4567 - categorical_accuracy: 0.4156 - val_loss: 1.9002 - val_categorical_accuracy: 0.3217\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.18      0.19       190\n",
            "         1.0       0.18      0.61      0.28       173\n",
            "         2.0       0.07      0.10      0.08       135\n",
            "         3.0       0.14      0.17      0.15       216\n",
            "         4.0       0.74      0.31      0.44      1036\n",
            "         5.0       0.21      0.42      0.28        76\n",
            "         6.0       0.68      0.83      0.75       195\n",
            "         7.0       0.16      0.13      0.14       290\n",
            "         8.0       0.14      0.12      0.13       139\n",
            "         9.0       0.34      0.38      0.35       258\n",
            "\n",
            "    accuracy                           0.32      2708\n",
            "   macro avg       0.28      0.33      0.28      2708\n",
            "weighted avg       0.43      0.32      0.33      2708\n",
            "\n",
            "0.3258683443164677\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.4423 - categorical_accuracy: 0.1418 - val_loss: 2.3235 - val_categorical_accuracy: 0.1498\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.2354 - categorical_accuracy: 0.2040 - val_loss: 2.2644 - val_categorical_accuracy: 0.1737\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1509 - categorical_accuracy: 0.2303 - val_loss: 2.2459 - val_categorical_accuracy: 0.1801\n",
            "Epoch 4/6\n",
            "123/609 [=====>........................] - ETA: 57s - loss: 2.1069 - categorical_accuracy: 0.2388"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resume from the last cell"
      ],
      "metadata": {
        "id": "sErIpS6Ed4-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.3\n",
        "learning_rate_transfer_learnings = [ 1e-4]\n",
        "learning_rate_fine_tunings = [1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    #model2.summary()\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d272c4ca403b4a47b1ece3efc81b4c60",
            "1e504b3e620e44a5b2524210523370b9",
            "fa78b894e25c444db500eb6f586219e7",
            "4dce5494f1a544bfb236d816e815156c",
            "a6baa10cad3c4cf297400c2a6c26836c",
            "48bea4ef9e0b4ef7862cd2e3adedae03",
            "af6987c103ca420a906441fb26a6ae34",
            "7d826796faf64e0bae02f9f62cbdae0c",
            "b8dde7f29f7740c58477e18a3b9a3ca6",
            "3d265b0a6d7f46d98d37f5f00c9ac6e0",
            "3f6a1352f8dc4e6cb4d20628323e6d87"
          ]
        },
        "id": "vcEwHX6Rd6xi",
        "outputId": "f247b4a8-ccf6-42fe-fff9-fc100be48ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d272c4ca403b4a47b1ece3efc81b4c60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 95s 135ms/step - loss: 2.4495 - categorical_accuracy: 0.1297 - val_loss: 2.3345 - val_categorical_accuracy: 0.1406\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.2148 - categorical_accuracy: 0.1918 - val_loss: 2.2765 - val_categorical_accuracy: 0.1691\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1319 - categorical_accuracy: 0.2072 - val_loss: 2.2452 - val_categorical_accuracy: 0.1765\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0613 - categorical_accuracy: 0.2320 - val_loss: 2.2178 - val_categorical_accuracy: 0.1921\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 80s 132ms/step - loss: 2.0293 - categorical_accuracy: 0.2409 - val_loss: 2.1922 - val_categorical_accuracy: 0.2022\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.9828 - categorical_accuracy: 0.2560 - val_loss: 2.1917 - val_categorical_accuracy: 0.2040\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.31      0.17       190\n",
            "         1.0       0.13      0.25      0.17       173\n",
            "         2.0       0.05      0.09      0.06       135\n",
            "         3.0       0.11      0.13      0.12       216\n",
            "         4.0       0.74      0.11      0.19      1036\n",
            "         5.0       0.10      0.39      0.15        76\n",
            "         6.0       0.68      0.70      0.69       195\n",
            "         7.0       0.08      0.03      0.04       290\n",
            "         8.0       0.10      0.21      0.13       139\n",
            "         9.0       0.24      0.31      0.27       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.23      0.25      0.20      2708\n",
            "weighted avg       0.40      0.20      0.20      2708\n",
            "\n",
            "0.25284298650124826\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 204s 309ms/step - loss: 1.9627 - categorical_accuracy: 0.2607 - val_loss: 2.1839 - val_categorical_accuracy: 0.1893\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 186s 305ms/step - loss: 1.9341 - categorical_accuracy: 0.2688 - val_loss: 2.1393 - val_categorical_accuracy: 0.2123\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 186s 305ms/step - loss: 1.9075 - categorical_accuracy: 0.2677 - val_loss: 2.1315 - val_categorical_accuracy: 0.2123\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.8853 - categorical_accuracy: 0.2781 - val_loss: 2.1393 - val_categorical_accuracy: 0.2086\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.8665 - categorical_accuracy: 0.2827 - val_loss: 2.1286 - val_categorical_accuracy: 0.2178\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 186s 305ms/step - loss: 1.8527 - categorical_accuracy: 0.2840 - val_loss: 2.1103 - val_categorical_accuracy: 0.2178\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.29      0.18       190\n",
            "         1.0       0.16      0.33      0.22       173\n",
            "         2.0       0.05      0.07      0.05       135\n",
            "         3.0       0.14      0.12      0.13       216\n",
            "         4.0       0.76      0.12      0.21      1036\n",
            "         5.0       0.11      0.53      0.19        76\n",
            "         6.0       0.71      0.77      0.74       195\n",
            "         7.0       0.09      0.04      0.05       290\n",
            "         8.0       0.12      0.24      0.16       139\n",
            "         9.0       0.24      0.40      0.30       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.25      0.29      0.22      2708\n",
            "weighted avg       0.42      0.23      0.22      2708\n",
            "\n",
            "0.29133796886832763\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameter = []#(drop_out_rate, initial_rate, fine_tune_learning_rate)"
      ],
      "metadata": {
        "id": "UWwkO5pxTANW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar={}\n",
        "balanced_accuracies_transfer_learning=[]\n",
        "balanced_accuracies_fine_tuning = []"
      ],
      "metadata": {
        "id": "V1ErLQ5mTANW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.4\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    #model2.summary()\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "494f3523b997428a8e07e2ff9f777278",
            "b7cc9f333c2b43c984854bf2a05c216b",
            "799f47064001473b9e2926d8b9f2a1c3",
            "60f03dcd1f494937924689fbabcb165c",
            "ab592251173e4fdeb9db0ac8037abf05",
            "069364167ee44547b1d841e3d488898c",
            "7c4eabafda57425980d8b661c5c4d4ef",
            "6bb505313711439c87d7ffe87c59b58b",
            "70a006728ee3429aa61eb3763bd2d601",
            "dd77628f26774bf4a5c03d5d92e6919b",
            "eb67aaba5d62417d94b683b2f8254d31"
          ]
        },
        "id": "uPIxk3ck0FPH",
        "outputId": "427dc0cf-3efd-444e-fa7d-4efca8bd7828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "494f3523b997428a8e07e2ff9f777278"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 134ms/step - loss: 2.2317 - categorical_accuracy: 0.1972 - val_loss: 2.1380 - val_categorical_accuracy: 0.1912\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 2.0176 - categorical_accuracy: 0.2512 - val_loss: 2.1589 - val_categorical_accuracy: 0.2086\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9597 - categorical_accuracy: 0.2723 - val_loss: 2.1580 - val_categorical_accuracy: 0.1930\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.9069 - categorical_accuracy: 0.2855 - val_loss: 2.1173 - val_categorical_accuracy: 0.2491\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 129ms/step - loss: 1.8727 - categorical_accuracy: 0.2930 - val_loss: 2.0645 - val_categorical_accuracy: 0.2408\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8497 - categorical_accuracy: 0.3043 - val_loss: 2.0751 - val_categorical_accuracy: 0.2261\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.27      0.17       190\n",
            "         1.0       0.13      0.50      0.21       173\n",
            "         2.0       0.07      0.04      0.05       135\n",
            "         3.0       0.09      0.19      0.13       216\n",
            "         4.0       0.73      0.13      0.22      1036\n",
            "         5.0       0.13      0.42      0.20        76\n",
            "         6.0       0.75      0.71      0.73       195\n",
            "         7.0       0.12      0.02      0.04       290\n",
            "         8.0       0.12      0.04      0.06       139\n",
            "         9.0       0.21      0.32      0.25       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.25      0.26      0.20      2708\n",
            "weighted avg       0.40      0.22      0.21      2708\n",
            "\n",
            "0.26467282256848795\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 202s 305ms/step - loss: 1.8155 - categorical_accuracy: 0.2956 - val_loss: 2.0693 - val_categorical_accuracy: 0.2417\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6760 - categorical_accuracy: 0.3289 - val_loss: 2.0994 - val_categorical_accuracy: 0.2463\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.5883 - categorical_accuracy: 0.3566 - val_loss: 1.9835 - val_categorical_accuracy: 0.2840\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.5029 - categorical_accuracy: 0.3783 - val_loss: 1.9055 - val_categorical_accuracy: 0.2987\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.4270 - categorical_accuracy: 0.4063 - val_loss: 1.9359 - val_categorical_accuracy: 0.3107\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.3398 - categorical_accuracy: 0.4276 - val_loss: 1.8814 - val_categorical_accuracy: 0.3254\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.44      0.22       190\n",
            "         1.0       0.19      0.60      0.29       173\n",
            "         2.0       0.10      0.09      0.10       135\n",
            "         3.0       0.19      0.13      0.15       216\n",
            "         4.0       0.74      0.28      0.41      1036\n",
            "         5.0       0.23      0.39      0.29        76\n",
            "         6.0       0.84      0.77      0.81       195\n",
            "         7.0       0.20      0.03      0.06       290\n",
            "         8.0       0.16      0.05      0.08       139\n",
            "         9.0       0.26      0.53      0.35       258\n",
            "\n",
            "    accuracy                           0.31      2708\n",
            "   macro avg       0.31      0.33      0.27      2708\n",
            "weighted avg       0.45      0.31      0.32      2708\n",
            "\n",
            "0.33237379521894855\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.2068 - categorical_accuracy: 0.2057 - val_loss: 2.2205 - val_categorical_accuracy: 0.1461\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0150 - categorical_accuracy: 0.2399 - val_loss: 2.1568 - val_categorical_accuracy: 0.1930\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9432 - categorical_accuracy: 0.2668 - val_loss: 2.1433 - val_categorical_accuracy: 0.2123\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9005 - categorical_accuracy: 0.2740 - val_loss: 2.0847 - val_categorical_accuracy: 0.2132\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.8612 - categorical_accuracy: 0.2830 - val_loss: 2.1234 - val_categorical_accuracy: 0.2123\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.8466 - categorical_accuracy: 0.2885 - val_loss: 2.1262 - val_categorical_accuracy: 0.2096\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.18      0.13       190\n",
            "         1.0       0.13      0.53      0.20       173\n",
            "         2.0       0.05      0.06      0.05       135\n",
            "         3.0       0.13      0.20      0.16       216\n",
            "         4.0       0.75      0.14      0.24      1036\n",
            "         5.0       0.10      0.58      0.17        76\n",
            "         6.0       0.78      0.68      0.73       195\n",
            "         7.0       0.11      0.01      0.01       290\n",
            "         8.0       0.06      0.04      0.04       139\n",
            "         9.0       0.26      0.28      0.27       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.25      0.27      0.20      2708\n",
            "weighted avg       0.42      0.21      0.22      2708\n",
            "\n",
            "0.26917697605329705\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 202s 306ms/step - loss: 1.7734 - categorical_accuracy: 0.3100 - val_loss: 2.1188 - val_categorical_accuracy: 0.2142\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.7511 - categorical_accuracy: 0.3136 - val_loss: 2.0763 - val_categorical_accuracy: 0.2371\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.7396 - categorical_accuracy: 0.3172 - val_loss: 2.0898 - val_categorical_accuracy: 0.2233\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.7041 - categorical_accuracy: 0.3252 - val_loss: 2.0878 - val_categorical_accuracy: 0.2353\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.6946 - categorical_accuracy: 0.3273 - val_loss: 2.0737 - val_categorical_accuracy: 0.2261\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.21      0.15       190\n",
            "         1.0       0.15      0.58      0.24       173\n",
            "         2.0       0.05      0.05      0.05       135\n",
            "         3.0       0.12      0.15      0.13       216\n",
            "         4.0       0.77      0.16      0.26      1036\n",
            "         5.0       0.10      0.58      0.17        76\n",
            "         6.0       0.75      0.77      0.76       195\n",
            "         7.0       0.08      0.00      0.01       290\n",
            "         8.0       0.04      0.02      0.03       139\n",
            "         9.0       0.27      0.35      0.30       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.25      0.29      0.21      2708\n",
            "weighted avg       0.42      0.23      0.23      2708\n",
            "\n",
            "0.28817625318114837\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.4721 - categorical_accuracy: 0.1269 - val_loss: 2.3431 - val_categorical_accuracy: 0.1369\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.2818 - categorical_accuracy: 0.1688 - val_loss: 2.2817 - val_categorical_accuracy: 0.1452\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1810 - categorical_accuracy: 0.1978 - val_loss: 2.2541 - val_categorical_accuracy: 0.1535\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1360 - categorical_accuracy: 0.2097 - val_loss: 2.2206 - val_categorical_accuracy: 0.1645\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0921 - categorical_accuracy: 0.2238 - val_loss: 2.1995 - val_categorical_accuracy: 0.1728\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0520 - categorical_accuracy: 0.2474 - val_loss: 2.1727 - val_categorical_accuracy: 0.1820\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.25      0.17       190\n",
            "         1.0       0.11      0.39      0.17       173\n",
            "         2.0       0.06      0.09      0.07       135\n",
            "         3.0       0.11      0.11      0.11       216\n",
            "         4.0       0.66      0.13      0.21      1036\n",
            "         5.0       0.09      0.62      0.16        76\n",
            "         6.0       0.67      0.76      0.71       195\n",
            "         7.0       0.09      0.02      0.03       290\n",
            "         8.0       0.07      0.05      0.06       139\n",
            "         9.0       0.21      0.18      0.19       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.22      0.26      0.19      2708\n",
            "weighted avg       0.37      0.20      0.20      2708\n",
            "\n",
            "0.25899548553031365\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 202s 305ms/step - loss: 1.9919 - categorical_accuracy: 0.2618 - val_loss: 1.9537 - val_categorical_accuracy: 0.2895\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 183s 301ms/step - loss: 1.8824 - categorical_accuracy: 0.2885 - val_loss: 2.0117 - val_categorical_accuracy: 0.2675\n",
            "Epoch 3/6\n",
            "392/609 [==================>...........] - ETA: 1:02 - loss: 1.7924 - categorical_accuracy: 0.3181"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resume from the last"
      ],
      "metadata": {
        "id": "2i6AHbv-xvWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.4\n",
        "learning_rate_transfer_learnings = [1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    #model2.summary()\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "05ce66e4bd7045e5bfca4025886d219d",
            "909c9d4b575543879765d871847f2f6a",
            "7e7090853d2d444b8f011659f2147ac3",
            "fdf96e564ee4446caec4471bef691679",
            "30bbac742239451b9f17c52b98695ec6",
            "763420132a35401c8865005eb4c3eb09",
            "c3ae1df16fd9472696aedb4a64485167",
            "8329ae8f3efe4931b1ae3690e1127319",
            "7dda33ea712045baba20dff1f1f99512",
            "e2671f8891a04b6aa692330f01d994f7",
            "0ffd1a44c92544988c0a299b379ebbc8"
          ]
        },
        "id": "7SHRahRtxxRf",
        "outputId": "9e7e90f6-610b-4466-a483-56512f259544"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05ce66e4bd7045e5bfca4025886d219d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 96s 136ms/step - loss: 2.5474 - categorical_accuracy: 0.1922 - val_loss: 2.2609 - val_categorical_accuracy: 0.1507\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.2904 - categorical_accuracy: 0.1937 - val_loss: 2.2255 - val_categorical_accuracy: 0.1627\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.1950 - categorical_accuracy: 0.2088 - val_loss: 2.2120 - val_categorical_accuracy: 0.1756\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.1501 - categorical_accuracy: 0.2247 - val_loss: 2.1856 - val_categorical_accuracy: 0.1710\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.0989 - categorical_accuracy: 0.2344 - val_loss: 2.1620 - val_categorical_accuracy: 0.1838\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.0665 - categorical_accuracy: 0.2503 - val_loss: 2.1514 - val_categorical_accuracy: 0.1921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.28      0.17       190\n",
            "         1.0       0.14      0.20      0.17       173\n",
            "         2.0       0.04      0.03      0.03       135\n",
            "         3.0       0.13      0.27      0.17       216\n",
            "         4.0       0.67      0.10      0.17      1036\n",
            "         5.0       0.11      0.29      0.16        76\n",
            "         6.0       0.68      0.72      0.70       195\n",
            "         7.0       0.12      0.10      0.11       290\n",
            "         8.0       0.09      0.20      0.13       139\n",
            "         9.0       0.17      0.25      0.20       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.23      0.24      0.20      2708\n",
            "weighted avg       0.37      0.20      0.20      2708\n",
            "\n",
            "0.24355273227399327\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "609/609 [==============================] - 205s 308ms/step - loss: 2.0187 - categorical_accuracy: 0.2574 - val_loss: 2.1205 - val_categorical_accuracy: 0.2096\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.9338 - categorical_accuracy: 0.2912 - val_loss: 2.0420 - val_categorical_accuracy: 0.2537\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.8401 - categorical_accuracy: 0.3116 - val_loss: 2.1483 - val_categorical_accuracy: 0.2233\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.7726 - categorical_accuracy: 0.3328 - val_loss: 2.0875 - val_categorical_accuracy: 0.2482\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.6934 - categorical_accuracy: 0.3549 - val_loss: 2.0820 - val_categorical_accuracy: 0.2472\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.28      0.19       190\n",
            "         1.0       0.17      0.44      0.24       173\n",
            "         2.0       0.11      0.07      0.08       135\n",
            "         3.0       0.14      0.19      0.16       216\n",
            "         4.0       0.77      0.17      0.28      1036\n",
            "         5.0       0.15      0.49      0.23        76\n",
            "         6.0       0.65      0.86      0.74       195\n",
            "         7.0       0.10      0.05      0.07       290\n",
            "         8.0       0.13      0.18      0.15       139\n",
            "         9.0       0.25      0.41      0.31       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.26      0.31      0.25      2708\n",
            "weighted avg       0.42      0.26      0.26      2708\n",
            "\n",
            "0.3130289740927619\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.4859 - categorical_accuracy: 0.1369 - val_loss: 2.2595 - val_categorical_accuracy: 0.1664\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.2612 - categorical_accuracy: 0.1911 - val_loss: 2.2091 - val_categorical_accuracy: 0.1783\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.1590 - categorical_accuracy: 0.2080 - val_loss: 2.1692 - val_categorical_accuracy: 0.1912\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.1282 - categorical_accuracy: 0.2221 - val_loss: 2.1616 - val_categorical_accuracy: 0.1875\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.0859 - categorical_accuracy: 0.2359 - val_loss: 2.1383 - val_categorical_accuracy: 0.1958\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.0407 - categorical_accuracy: 0.2432 - val_loss: 2.1390 - val_categorical_accuracy: 0.2068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.05      0.06       190\n",
            "         1.0       0.13      0.43      0.20       173\n",
            "         2.0       0.04      0.13      0.06       135\n",
            "         3.0       0.12      0.16      0.14       216\n",
            "         4.0       0.64      0.10      0.18      1036\n",
            "         5.0       0.08      0.42      0.14        76\n",
            "         6.0       0.64      0.75      0.69       195\n",
            "         7.0       0.11      0.04      0.06       290\n",
            "         8.0       0.07      0.09      0.08       139\n",
            "         9.0       0.19      0.16      0.17       258\n",
            "\n",
            "    accuracy                           0.18      2708\n",
            "   macro avg       0.21      0.23      0.18      2708\n",
            "weighted avg       0.35      0.18      0.18      2708\n",
            "\n",
            "0.23448652349259164\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "609/609 [==============================] - 205s 308ms/step - loss: 2.0157 - categorical_accuracy: 0.2485 - val_loss: 2.1258 - val_categorical_accuracy: 0.2151\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9896 - categorical_accuracy: 0.2572 - val_loss: 2.1042 - val_categorical_accuracy: 0.2096\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9563 - categorical_accuracy: 0.2642 - val_loss: 2.0781 - val_categorical_accuracy: 0.2233\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9456 - categorical_accuracy: 0.2640 - val_loss: 2.1164 - val_categorical_accuracy: 0.2224\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9211 - categorical_accuracy: 0.2731 - val_loss: 2.0909 - val_categorical_accuracy: 0.2381\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9165 - categorical_accuracy: 0.2787 - val_loss: 2.0890 - val_categorical_accuracy: 0.2353\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.06      0.08       190\n",
            "         1.0       0.15      0.53      0.23       173\n",
            "         2.0       0.04      0.12      0.06       135\n",
            "         3.0       0.14      0.14      0.14       216\n",
            "         4.0       0.70      0.16      0.26      1036\n",
            "         5.0       0.11      0.63      0.19        76\n",
            "         6.0       0.65      0.79      0.71       195\n",
            "         7.0       0.10      0.04      0.06       290\n",
            "         8.0       0.07      0.05      0.06       139\n",
            "         9.0       0.23      0.24      0.24       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.23      0.28      0.20      2708\n",
            "weighted avg       0.39      0.22      0.22      2708\n",
            "\n",
            "0.2776146034984809\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "#for drop_out_rate in drop_out_rates:\n",
        "\n",
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = bert_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    #model2.summary()\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccg_gvURl_qJ",
        "outputId": "b50b164a-5662-4c06-f141-c15f49b200be"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.2785 - categorical_accuracy: 0.1874 - val_loss: 2.1913 - val_categorical_accuracy: 0.1756\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.0369 - categorical_accuracy: 0.2328 - val_loss: 2.1467 - val_categorical_accuracy: 0.2013\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9804 - categorical_accuracy: 0.2607 - val_loss: 2.0973 - val_categorical_accuracy: 0.2243\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9389 - categorical_accuracy: 0.2745 - val_loss: 2.0932 - val_categorical_accuracy: 0.2472\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9070 - categorical_accuracy: 0.2903 - val_loss: 2.0543 - val_categorical_accuracy: 0.2482\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.8789 - categorical_accuracy: 0.2850 - val_loss: 2.0647 - val_categorical_accuracy: 0.2270\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.28      0.18       190\n",
            "         1.0       0.13      0.58      0.21       173\n",
            "         2.0       0.05      0.03      0.04       135\n",
            "         3.0       0.11      0.12      0.11       216\n",
            "         4.0       0.72      0.18      0.29      1036\n",
            "         5.0       0.13      0.49      0.20        76\n",
            "         6.0       0.72      0.77      0.75       195\n",
            "         7.0       0.09      0.02      0.03       290\n",
            "         8.0       0.07      0.07      0.07       139\n",
            "         9.0       0.28      0.27      0.27       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.24      0.28      0.22      2708\n",
            "weighted avg       0.40      0.24      0.24      2708\n",
            "\n",
            "0.2813021595195978\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 205s 308ms/step - loss: 1.8338 - categorical_accuracy: 0.3029 - val_loss: 1.9680 - val_categorical_accuracy: 0.2619\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.7193 - categorical_accuracy: 0.3211 - val_loss: 1.9922 - val_categorical_accuracy: 0.2656\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.6199 - categorical_accuracy: 0.3390 - val_loss: 1.9621 - val_categorical_accuracy: 0.2574\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.5442 - categorical_accuracy: 0.3506 - val_loss: 1.9326 - val_categorical_accuracy: 0.2739\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.4593 - categorical_accuracy: 0.3778 - val_loss: 1.9253 - val_categorical_accuracy: 0.3015\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.3994 - categorical_accuracy: 0.3975 - val_loss: 1.8392 - val_categorical_accuracy: 0.3235\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.42      0.23       190\n",
            "         1.0       0.19      0.56      0.28       173\n",
            "         2.0       0.10      0.09      0.09       135\n",
            "         3.0       0.18      0.14      0.16       216\n",
            "         4.0       0.72      0.32      0.44      1036\n",
            "         5.0       0.22      0.50      0.30        76\n",
            "         6.0       0.82      0.77      0.79       195\n",
            "         7.0       0.12      0.03      0.05       290\n",
            "         8.0       0.13      0.08      0.10       139\n",
            "         9.0       0.29      0.49      0.36       258\n",
            "\n",
            "    accuracy                           0.33      2708\n",
            "   macro avg       0.29      0.34      0.28      2708\n",
            "weighted avg       0.43      0.33      0.33      2708\n",
            "\n",
            "0.3395749899869377\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 95s 135ms/step - loss: 2.2802 - categorical_accuracy: 0.1978 - val_loss: 2.1871 - val_categorical_accuracy: 0.1710\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0456 - categorical_accuracy: 0.2475 - val_loss: 2.1839 - val_categorical_accuracy: 0.1700\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9930 - categorical_accuracy: 0.2526 - val_loss: 2.1838 - val_categorical_accuracy: 0.1857\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9502 - categorical_accuracy: 0.2663 - val_loss: 2.1174 - val_categorical_accuracy: 0.1903\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9132 - categorical_accuracy: 0.2797 - val_loss: 2.0839 - val_categorical_accuracy: 0.2188\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9079 - categorical_accuracy: 0.2763 - val_loss: 2.1154 - val_categorical_accuracy: 0.2132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.07      0.05      0.06       190\n",
            "         1.0       0.12      0.24      0.16       173\n",
            "         2.0       0.06      0.04      0.04       135\n",
            "         3.0       0.10      0.06      0.08       216\n",
            "         4.0       0.73      0.14      0.24      1036\n",
            "         5.0       0.10      0.33      0.15        76\n",
            "         6.0       0.71      0.69      0.70       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.08      0.59      0.14       139\n",
            "         9.0       0.26      0.33      0.29       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.22      0.25      0.19      2708\n",
            "weighted avg       0.39      0.20      0.20      2708\n",
            "\n",
            "0.24759405268985804\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 205s 308ms/step - loss: 1.8427 - categorical_accuracy: 0.2944 - val_loss: 2.0906 - val_categorical_accuracy: 0.2188\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.8244 - categorical_accuracy: 0.2971 - val_loss: 2.0959 - val_categorical_accuracy: 0.2132\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.8051 - categorical_accuracy: 0.3015 - val_loss: 2.0840 - val_categorical_accuracy: 0.2243\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.7809 - categorical_accuracy: 0.3086 - val_loss: 2.0792 - val_categorical_accuracy: 0.2252\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.7633 - categorical_accuracy: 0.3132 - val_loss: 2.0558 - val_categorical_accuracy: 0.2335\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.7394 - categorical_accuracy: 0.3190 - val_loss: 2.0807 - val_categorical_accuracy: 0.2307\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.12      0.12       190\n",
            "         1.0       0.17      0.31      0.22       173\n",
            "         2.0       0.03      0.01      0.02       135\n",
            "         3.0       0.08      0.04      0.05       216\n",
            "         4.0       0.76      0.18      0.29      1036\n",
            "         5.0       0.11      0.63      0.19        76\n",
            "         6.0       0.72      0.77      0.74       195\n",
            "         7.0       0.08      0.00      0.01       290\n",
            "         8.0       0.09      0.50      0.15       139\n",
            "         9.0       0.27      0.38      0.32       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.24      0.29      0.21      2708\n",
            "weighted avg       0.41      0.23      0.23      2708\n",
            "\n",
            "0.2944448546129229\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.5205 - categorical_accuracy: 0.1425 - val_loss: 2.3374 - val_categorical_accuracy: 0.1480\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.3057 - categorical_accuracy: 0.1819 - val_loss: 2.2816 - val_categorical_accuracy: 0.1664\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.2312 - categorical_accuracy: 0.2128 - val_loss: 2.2311 - val_categorical_accuracy: 0.1811\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1599 - categorical_accuracy: 0.2236 - val_loss: 2.2317 - val_categorical_accuracy: 0.1866\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1126 - categorical_accuracy: 0.2339 - val_loss: 2.2113 - val_categorical_accuracy: 0.1847\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0773 - categorical_accuracy: 0.2416 - val_loss: 2.1986 - val_categorical_accuracy: 0.1884\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.06      0.09      0.08       190\n",
            "         1.0       0.12      0.33      0.18       173\n",
            "         2.0       0.10      0.03      0.05       135\n",
            "         3.0       0.13      0.22      0.16       216\n",
            "         4.0       0.70      0.16      0.26      1036\n",
            "         5.0       0.09      0.55      0.15        76\n",
            "         6.0       0.61      0.73      0.67       195\n",
            "         7.0       0.07      0.01      0.02       290\n",
            "         8.0       0.09      0.14      0.11       139\n",
            "         9.0       0.21      0.25      0.22       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.22      0.25      0.19      2708\n",
            "weighted avg       0.37      0.21      0.21      2708\n",
            "\n",
            "0.2522822893698141\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 204s 308ms/step - loss: 2.0316 - categorical_accuracy: 0.2578 - val_loss: 2.2454 - val_categorical_accuracy: 0.1811\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.9390 - categorical_accuracy: 0.2811 - val_loss: 1.9728 - val_categorical_accuracy: 0.2969\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.8722 - categorical_accuracy: 0.3072 - val_loss: 2.1670 - val_categorical_accuracy: 0.2289\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.8112 - categorical_accuracy: 0.3215 - val_loss: 2.1646 - val_categorical_accuracy: 0.2335\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.7418 - categorical_accuracy: 0.3276 - val_loss: 2.0594 - val_categorical_accuracy: 0.2757\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.19      0.16       190\n",
            "         1.0       0.19      0.50      0.28       173\n",
            "         2.0       0.17      0.02      0.04       135\n",
            "         3.0       0.16      0.32      0.21       216\n",
            "         4.0       0.72      0.28      0.40      1036\n",
            "         5.0       0.10      0.68      0.18        76\n",
            "         6.0       0.71      0.82      0.76       195\n",
            "         7.0       0.10      0.00      0.01       290\n",
            "         8.0       0.18      0.10      0.13       139\n",
            "         9.0       0.27      0.34      0.30       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.27      0.33      0.25      2708\n",
            "weighted avg       0.42      0.30      0.30      2708\n",
            "\n",
            "0.3266763703144977\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 94s 135ms/step - loss: 2.5813 - categorical_accuracy: 0.1196 - val_loss: 2.2888 - val_categorical_accuracy: 0.1287\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 131ms/step - loss: 2.3399 - categorical_accuracy: 0.1607 - val_loss: 2.2221 - val_categorical_accuracy: 0.1535\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.2385 - categorical_accuracy: 0.1825 - val_loss: 2.1884 - val_categorical_accuracy: 0.1700\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.1680 - categorical_accuracy: 0.2026 - val_loss: 2.1762 - val_categorical_accuracy: 0.1765\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1307 - categorical_accuracy: 0.2115 - val_loss: 2.1658 - val_categorical_accuracy: 0.1829\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.1001 - categorical_accuracy: 0.2184 - val_loss: 2.1603 - val_categorical_accuracy: 0.1884\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.18      0.16       190\n",
            "         1.0       0.10      0.13      0.12       173\n",
            "         2.0       0.04      0.03      0.03       135\n",
            "         3.0       0.08      0.15      0.10       216\n",
            "         4.0       0.72      0.07      0.13      1036\n",
            "         5.0       0.10      0.42      0.16        76\n",
            "         6.0       0.64      0.68      0.66       195\n",
            "         7.0       0.07      0.01      0.02       290\n",
            "         8.0       0.10      0.38      0.16       139\n",
            "         9.0       0.18      0.35      0.24       258\n",
            "\n",
            "    accuracy                           0.18      2708\n",
            "   macro avg       0.22      0.24      0.18      2708\n",
            "weighted avg       0.38      0.18      0.16      2708\n",
            "\n",
            "0.2411930216346533\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 205s 308ms/step - loss: 2.0619 - categorical_accuracy: 0.2253 - val_loss: 2.1327 - val_categorical_accuracy: 0.1939\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0486 - categorical_accuracy: 0.2334 - val_loss: 2.1031 - val_categorical_accuracy: 0.1967\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0223 - categorical_accuracy: 0.2395 - val_loss: 2.1161 - val_categorical_accuracy: 0.1903\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0064 - categorical_accuracy: 0.2426 - val_loss: 2.0986 - val_categorical_accuracy: 0.2013\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.9984 - categorical_accuracy: 0.2461 - val_loss: 2.1002 - val_categorical_accuracy: 0.1994\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.9790 - categorical_accuracy: 0.2593 - val_loss: 2.0882 - val_categorical_accuracy: 0.2105\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.13      0.13       190\n",
            "         1.0       0.12      0.16      0.13       173\n",
            "         2.0       0.13      0.07      0.09       135\n",
            "         3.0       0.09      0.13      0.11       216\n",
            "         4.0       0.76      0.12      0.21      1036\n",
            "         5.0       0.11      0.51      0.18        76\n",
            "         6.0       0.65      0.79      0.71       195\n",
            "         7.0       0.02      0.00      0.01       290\n",
            "         8.0       0.11      0.41      0.17       139\n",
            "         9.0       0.18      0.39      0.25       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.23      0.27      0.20      2708\n",
            "weighted avg       0.39      0.21      0.20      2708\n",
            "\n",
            "0.27124955494885356\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76PuGBfmdQQc",
        "outputId": "884d4b07-754d-4fcf-89c0-c64d3fa61707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([(False, 0.4, 0.0001, 1e-05), (True, 0.4, 0.0001, 1e-05), (False, 0.4, 0.0001, 1e-06), (True, 0.4, 0.0001, 1e-06), (False, 0.5, 0.001, 1e-05), (True, 0.5, 0.001, 1e-05), (False, 0.5, 0.001, 1e-06), (True, 0.5, 0.001, 1e-06), (False, 0.5, 0.0001, 1e-05), (True, 0.5, 0.0001, 1e-05), (False, 0.5, 0.0001, 1e-06), (True, 0.5, 0.0001, 1e-06)])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_McNemar_BERT_split0_fine_tune = pd.DataFrame(data=McNemar[(True,0.5, 1e-3, 1e-5)])\n",
        "df_McNemar_BERT_split0_fine_tune.to_csv(DIR + 'McNemar_BERT_split0_fine_tune.csv')"
      ],
      "metadata": {
        "id": "7nr0UnKZLe1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_McNemar_BERT_split0_transfer_learning = pd.DataFrame(data=McNemar[(False,0.5, 1e-3, 1e-5)])\n",
        "df_McNemar_BERT_split0_transfer_learning.to_csv(DIR + 'McNemar_BERT_split0_transfer_learning.csv')"
      ],
      "metadata": {
        "id": "atoiZaZmdYuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzJC6ZwWom0p",
        "outputId": "aedb6da4-a92d-4eec-d7cd-26313df67bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3545180413326312,\n",
              " 0.32561995928565546,\n",
              " 0.3198687138125366,\n",
              " 0.2922621302487614]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSg4e4zOQhb6",
        "outputId": "0943eba2-a421-4cd5-f3f5-b90fd45bc57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3545180413326312,\n",
              " 0.32561995928565546,\n",
              " 0.3198687138125366,\n",
              " 0.2922621302487614,\n",
              " 0.35156416694413817,\n",
              " 0.3320729042652105,\n",
              " 0.3001390737921044]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7bOgI9tlF9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best parameter is: drop out rate= 0.5, initial learn rate= 1e-3 , fine tune rate= 1e-5"
      ],
      "metadata": {
        "id": "-0ZyPSRTmH3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KFold test"
      ],
      "metadata": {
        "id": "M150mwbAM6j0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best parameter set is: initial learning rate=1e-3, fine tuning learning rate=1e-5, drop out rate=0.2 "
      ],
      "metadata": {
        "id": "YYykbCsOMvbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(dataset_train)\n",
        "del(dataset_test)\n",
        "del(train)\n",
        "del(val)\n",
        "del(test)"
      ],
      "metadata": {
        "id": "nXI5kNu300m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fold1: intentionally separate cells for check point purpose."
      ],
      "metadata": {
        "id": "UL1HA0eCNFuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[1]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fdf238-6ce7-43ae-cdfd-7137d811aafd",
        "id": "LT8x-u6d00m3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learning =1e-3\n",
        "learning_rate_fine_tuning = 1e-5"
      ],
      "metadata": {
        "id": "zZFY4Qxs00m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if len(balanced_accuracy_transfer_learning)==0:\n",
        "balanced_accuracy_transfer_learning = []\n",
        "#if len(balanced_accuracy_fine_tuning)==0:\n",
        "balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "Jd3ZQYIIOK78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOZQ4tlkOh_u",
        "outputId": "4efcc723-63c3-4095-dba6-e26061f43935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([(False, 0.4, 0.0001, 1e-05), (True, 0.4, 0.0001, 1e-05), (False, 0.4, 0.0001, 1e-06), (True, 0.4, 0.0001, 1e-06), (False, 0.5, 0.001, 1e-05), (True, 0.5, 0.001, 1e-05), (False, 0.5, 0.001, 1e-06), (True, 0.5, 0.001, 1e-06), (False, 0.5, 0.0001, 1e-05), (True, 0.5, 0.0001, 1e-05), (False, 0.5, 0.0001, 1e-06), (True, 0.5, 0.0001, 1e-06)])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "roberta_base = TFAutoModel.from_pretrained('roberta-base')\n",
        "SEQ_LEN2=256\n",
        "#step1\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = roberta_base(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "print(model2.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "print(model2.summary() )#Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_transfer_learning.append(balanced_acc)\n",
        "\n",
        "\n",
        "#step5: fine tune\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_fine_tune.append(balanced_acc)\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bdac008971504c069f4e240f10a049cf",
            "f9fd1f6cb1994cdabfe96fe68484eb1a",
            "ad5d86b91fd14e8bab8b3f3e15f22da6",
            "8ec6453bad714888a56fd909440bd398",
            "63eb27215ab847f2aebad7d6e5ea35e8",
            "fde394d01b264e07ae7c07ccafdae6c4",
            "2d202fd6d45e440a9953fe80c8fd476d",
            "34efba7726b640889575959261f0cfe7",
            "8dbf1ef7980e452aaca49b5447f7ae6b",
            "2b4f71e00d4c4c63b6b84f2a7e525559",
            "81088231ee7b4f6893e136a8d12941fd",
            "07ac6dc4628a4f048a7fb7180611185c",
            "5a19a51846344a5ebc0abcc9cce0e2c6",
            "9a446421b64c428d87a64133977e3bf9",
            "ba956548e2ea4ec5b7988597ee642ddf",
            "7ef3942ee94e47e385bd4bb25a34ca13",
            "a10d50a4cede4ee9b7d1c3d991bc5394",
            "14000dc3c37e499daf2e19e7e7c564ff",
            "5d62baa87c2043348e835705ccabc772",
            "3b2e7832be724026a13c77b92b67e324",
            "7529487daaa247c08bb6004957c46c6c",
            "89cf43d486284b5388e298ceb06997d2"
          ]
        },
        "id": "zqoBAnlt00m3",
        "outputId": "ee05dfac-5ead-4a47-9716-ad56a40519b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdac008971504c069f4e240f10a049cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/627M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07ac6dc4628a4f048a7fb7180611185c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " el)                            thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_6 (Global  (None, 768)         0           ['tf_roberta_model[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 128)          98432       ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_265 (Dropout)          (None, 128)          0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 32)           4128        ['dropout_265[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 124,647,168\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " el)                            thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_6 (Global  (None, 768)         0           ['tf_roberta_model[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 128)          98432       ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_265 (Dropout)          (None, 128)          0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 32)           4128        ['dropout_265[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 124,647,168\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 96s 135ms/step - loss: 2.3820 - categorical_accuracy: 0.1554 - val_loss: 2.4944 - val_categorical_accuracy: 0.0616\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 131ms/step - loss: 2.1882 - categorical_accuracy: 0.1785 - val_loss: 2.5053 - val_categorical_accuracy: 0.0469\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1424 - categorical_accuracy: 0.2048 - val_loss: 2.4579 - val_categorical_accuracy: 0.0506\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.1187 - categorical_accuracy: 0.2169 - val_loss: 2.3708 - val_categorical_accuracy: 0.0781\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0964 - categorical_accuracy: 0.2571 - val_loss: 2.4036 - val_categorical_accuracy: 0.0855\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0981 - categorical_accuracy: 0.2457 - val_loss: 2.2375 - val_categorical_accuracy: 0.1636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.01      0.02       191\n",
            "         1.0       0.11      0.36      0.16       173\n",
            "         2.0       0.09      0.06      0.07       134\n",
            "         3.0       0.08      0.10      0.09       216\n",
            "         4.0       0.70      0.11      0.20      1036\n",
            "         5.0       0.06      0.49      0.10        76\n",
            "         6.0       0.38      0.80      0.52       196\n",
            "         7.0       0.07      0.02      0.03       289\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.17      0.29      0.22       258\n",
            "\n",
            "    accuracy                           0.18      2708\n",
            "   macro avg       0.18      0.22      0.14      2708\n",
            "weighted avg       0.34      0.18      0.16      2708\n",
            "\n",
            "0.22379344792522313\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 206s 313ms/step - loss: 2.0690 - categorical_accuracy: 0.2652 - val_loss: 3.2000 - val_categorical_accuracy: 0.0928\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 187s 307ms/step - loss: 2.0267 - categorical_accuracy: 0.2713 - val_loss: 5.2302 - val_categorical_accuracy: 0.0744\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 187s 307ms/step - loss: 1.9901 - categorical_accuracy: 0.2755 - val_loss: 4.3445 - val_categorical_accuracy: 0.1131\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 187s 307ms/step - loss: 1.9398 - categorical_accuracy: 0.2888 - val_loss: 5.0156 - val_categorical_accuracy: 0.0873\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 187s 307ms/step - loss: 1.8871 - categorical_accuracy: 0.2925 - val_loss: 3.3289 - val_categorical_accuracy: 0.1094\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 187s 307ms/step - loss: 1.8355 - categorical_accuracy: 0.3091 - val_loss: 2.8144 - val_categorical_accuracy: 0.1535\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.06      0.10       191\n",
            "         1.0       0.10      0.66      0.18       173\n",
            "         2.0       0.07      0.02      0.03       134\n",
            "         3.0       0.12      0.08      0.10       216\n",
            "         4.0       0.50      0.00      0.00      1036\n",
            "         5.0       0.08      0.54      0.14        76\n",
            "         6.0       0.85      0.79      0.82       196\n",
            "         7.0       0.00      0.00      0.00       289\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.20      0.51      0.29       258\n",
            "\n",
            "    accuracy                           0.18      2708\n",
            "   macro avg       0.21      0.27      0.17      2708\n",
            "weighted avg       0.31      0.18      0.12      2708\n",
            "\n",
            "0.26625640318037086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fold2: intentionally separate cells for check point purpose."
      ],
      "metadata": {
        "id": "qWLHwgPUO8eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[2]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148,
          "referenced_widgets": [
            "94f8bc87fd694827852a213f8a17527a",
            "eca728284a8f411db009b4b5894fcb5c",
            "5eaf5a66f0464462ac9443ad26abb68e",
            "4f7349751768430da050b45340f9ccbc",
            "9b0ccabb7e09493eaf7a31c19073e571",
            "34fe24a3f4a5468f9c07cec48ef1e497",
            "bddc8f8bb31b4ab4a124a85894c7f7b2",
            "98db0bea40fd4ea39815fcea8670de20",
            "b4b5fc21d8dc464c9923c329898d4384",
            "f8091b889eb94ee3bff5518b80edecb4",
            "1a587c4a581c4aa4b0996a488a182ff7",
            "ddb863956ab74dfc868afc62d4788820",
            "5cdc29dab405471a9a022ab6a284abb8",
            "df7462404d174fa3bbec01523fe8bea3",
            "a176217c38724f1788dc7566114b4d58",
            "49ce689060c34a81959c9392d6e3a732",
            "d97c42458a2a407d8e576dda48af216a",
            "f641ac563f964c62808aceaf809e61e8",
            "75d01b9e34dc462197387e93cca13b16",
            "b2180b2c9eba440f90a79c4eefc647fa",
            "d273b47d794c45f8afdf919e34dc54f5",
            "de21ee87818b4848827fd2b44eb6ffbd",
            "2f18cc3dd56d41aea970045fb788bcac",
            "330de2a0937345a2b90e2bcb03e26bfc",
            "6f2529a23bc642a99be3aed410acdf9e",
            "0a2b658646034eb39a8d07620feec854",
            "5b9985e281b6498aa5de094d632b213b",
            "14331b2af930420dab782757a5842855",
            "ffa9703c1dcf496d93e06739d05d9d90",
            "22640fa49fde4c4fb4c25cb22093c8c5",
            "6beb071303fe41ed9ba2c480d6e6d907",
            "0fe4b232c97d485cba64472dfd57fdc5",
            "be668a74359d48d09c93c9586cbb30e8"
          ]
        },
        "outputId": "aeaf8b2d-b8f1-4e4d-bcc4-e2288ba3de4a",
        "id": "d5c_5sLxO8eY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94f8bc87fd694827852a213f8a17527a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddb863956ab74dfc868afc62d4788820"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f18cc3dd56d41aea970045fb788bcac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learning =1e-3\n",
        "learning_rate_fine_tuning = 1e-5"
      ],
      "metadata": {
        "id": "TrvcQkbpO8eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(balanced_accuracy_transfer_learning)==0:\n",
        "  balanced_accuracy_transfer_learning = []\n",
        "if len(balanced_accuracy_fine_tune)==0:\n",
        "  balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "trBFNA5aO8eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d981be-b3bb-49af-9a27-b6d72b1f5e57",
        "id": "R7Ys1B6nO8eY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([(False, 0.4, 0.0001, 1e-06), (True, 0.4, 0.0001, 1e-06), (False, 0.5, 0.001, 1e-05), (True, 0.5, 0.001, 1e-05), (False, 0.5, 0.001, 1e-06), (True, 0.5, 0.001, 1e-06), (False, 0.5, 0.0001, 1e-05), (True, 0.5, 0.0001, 1e-05), (False, 0.5, 0.0001, 1e-06), (True, 0.5, 0.0001, 1e-06), (False, 0.2, 0.001, 1e-05), (True, 0.2, 0.001, 1e-05)])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "roberta_base = TFAutoModel.from_pretrained('roberta-base')\n",
        "SEQ_LEN2=256\n",
        "#step1\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = roberta_base(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "print(model2.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "print(model2.summary() )#Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_transfer_learning.append(balanced_acc)\n",
        "\n",
        "\n",
        "#step5: fine tune\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_fine_tune.append(balanced_acc)\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193ddd46-55a7-4c8a-d4a0-aba8440e44d6",
        "id": "BS9lQpP9O8eZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_7 (Global  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_7[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 128)          98432       ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_303 (Dropout)          (None, 128)          0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 32)           4128        ['dropout_303[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 124,647,168\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_7 (Global  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_7[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 128)          98432       ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_303 (Dropout)          (None, 128)          0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 32)           4128        ['dropout_303[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 124,647,168\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 95s 136ms/step - loss: 2.2631 - categorical_accuracy: 0.2047 - val_loss: 2.4520 - val_categorical_accuracy: 0.0892\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.0692 - categorical_accuracy: 0.2509 - val_loss: 2.3648 - val_categorical_accuracy: 0.0846\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 2.0087 - categorical_accuracy: 0.2628 - val_loss: 2.2105 - val_categorical_accuracy: 0.1783\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.9666 - categorical_accuracy: 0.2839 - val_loss: 2.2698 - val_categorical_accuracy: 0.1443\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9562 - categorical_accuracy: 0.2797 - val_loss: 2.3911 - val_categorical_accuracy: 0.0699\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.9246 - categorical_accuracy: 0.2820 - val_loss: 2.1405 - val_categorical_accuracy: 0.1820\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.38      0.19       191\n",
            "         1.0       0.22      0.03      0.06       172\n",
            "         2.0       0.10      0.05      0.07       134\n",
            "         3.0       0.17      0.04      0.07       216\n",
            "         4.0       0.73      0.18      0.29      1036\n",
            "         5.0       0.07      0.82      0.13        77\n",
            "         6.0       0.79      0.61      0.69       196\n",
            "         7.0       0.13      0.19      0.16       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.26      0.26      0.26       257\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.26      0.26      0.19      2708\n",
            "weighted avg       0.42      0.22      0.23      2708\n",
            "\n",
            "0.2576163405192071\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 208s 312ms/step - loss: 1.8701 - categorical_accuracy: 0.2817 - val_loss: 1.7959 - val_categorical_accuracy: 0.3143\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 187s 307ms/step - loss: 1.7823 - categorical_accuracy: 0.2990 - val_loss: 2.1377 - val_categorical_accuracy: 0.2344\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 187s 307ms/step - loss: 1.6984 - categorical_accuracy: 0.3192 - val_loss: 2.0663 - val_categorical_accuracy: 0.3033\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 187s 307ms/step - loss: 1.6316 - categorical_accuracy: 0.3428 - val_loss: 1.7964 - val_categorical_accuracy: 0.3088\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.23      0.17      0.20       191\n",
            "         1.0       0.26      0.32      0.29       172\n",
            "         2.0       0.13      0.07      0.09       134\n",
            "         3.0       0.29      0.13      0.18       216\n",
            "         4.0       0.68      0.26      0.37      1036\n",
            "         5.0       0.14      0.77      0.23        77\n",
            "         6.0       0.68      0.90      0.77       196\n",
            "         7.0       0.18      0.11      0.14       290\n",
            "         8.0       0.29      0.01      0.03       139\n",
            "         9.0       0.20      0.70      0.31       257\n",
            "\n",
            "    accuracy                           0.31      2708\n",
            "   macro avg       0.31      0.34      0.26      2708\n",
            "weighted avg       0.43      0.31      0.30      2708\n",
            "\n",
            "0.3447727236337791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fold3: intentionally separate cells for check point purpose."
      ],
      "metadata": {
        "id": "ivGPMia1TAUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[3]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dc78bb5-35b6-4b64-f81a-888b50733f62",
        "id": "RZ9AHi3gTAUv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learning =1e-3\n",
        "learning_rate_fine_tuning = 1e-5"
      ],
      "metadata": {
        "id": "q50zF8XwTAUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(balanced_accuracy_transfer_learning)==0:\n",
        "  balanced_accuracy_transfer_learning = []\n",
        "if len(balanced_accuracy_fine_tune)==0:\n",
        "  balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "5265WJBHTAUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac1b9d70-16d7-4d39-f9e3-321e7f19c68f",
        "id": "w3WaLIivTAUw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([(False, 0.4, 0.0001, 1e-06), (True, 0.4, 0.0001, 1e-06), (False, 0.5, 0.001, 1e-05), (True, 0.5, 0.001, 1e-05), (False, 0.5, 0.001, 1e-06), (True, 0.5, 0.001, 1e-06), (False, 0.5, 0.0001, 1e-05), (True, 0.5, 0.0001, 1e-05), (False, 0.5, 0.0001, 1e-06), (True, 0.5, 0.0001, 1e-06), (False, 0.2, 0.001, 1e-05), (True, 0.2, 0.001, 1e-05)])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "roberta_base = TFAutoModel.from_pretrained('roberta-base')\n",
        "SEQ_LEN2=256\n",
        "#step1\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = roberta_base(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "print(model2.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "print(model2.summary() )#Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_transfer_learning.append(balanced_acc)\n",
        "\n",
        "\n",
        "#step5: fine tune\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_fine_tune.append(balanced_acc)\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO0ech7zTAUw",
        "outputId": "8806fc4f-2822-423b-8dc5-9837eeafc765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_2 (TFRobertaM  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_8 (Global  (None, 768)         0           ['tf_roberta_model_2[0][0]']     \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_8[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 128)          98432       ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_341 (Dropout)          (None, 128)          0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 32)           4128        ['dropout_341[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 124,647,168\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_2 (TFRobertaM  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_8 (Global  (None, 768)         0           ['tf_roberta_model_2[0][0]']     \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_8[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 128)          98432       ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_341 (Dropout)          (None, 128)          0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 32)           4128        ['dropout_341[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 124,647,168\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 95s 135ms/step - loss: 2.2724 - categorical_accuracy: 0.1960 - val_loss: 2.5201 - val_categorical_accuracy: 0.0846\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0478 - categorical_accuracy: 0.2368 - val_loss: 2.2615 - val_categorical_accuracy: 0.1388\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.9879 - categorical_accuracy: 0.2535 - val_loss: 2.1521 - val_categorical_accuracy: 0.1627\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9695 - categorical_accuracy: 0.2669 - val_loss: 2.2613 - val_categorical_accuracy: 0.1581\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9394 - categorical_accuracy: 0.2833 - val_loss: 2.2879 - val_categorical_accuracy: 0.1489\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9306 - categorical_accuracy: 0.2825 - val_loss: 2.2174 - val_categorical_accuracy: 0.1728\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.04      0.02      0.02       191\n",
            "         1.0       0.24      0.07      0.11       172\n",
            "         2.0       0.03      0.04      0.03       134\n",
            "         3.0       0.08      0.10      0.09       216\n",
            "         4.0       0.77      0.05      0.09      1036\n",
            "         5.0       0.08      0.40      0.14        77\n",
            "         6.0       0.85      0.68      0.76       196\n",
            "         7.0       0.04      0.00      0.01       290\n",
            "         8.0       0.07      0.64      0.13       139\n",
            "         9.0       0.29      0.27      0.28       257\n",
            "\n",
            "    accuracy                           0.15      2708\n",
            "   macro avg       0.25      0.23      0.16      2708\n",
            "weighted avg       0.42      0.15      0.14      2708\n",
            "\n",
            "0.22633936952851022\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 207s 311ms/step - loss: 1.8725 - categorical_accuracy: 0.2869 - val_loss: 2.1187 - val_categorical_accuracy: 0.2445\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.8020 - categorical_accuracy: 0.2956 - val_loss: 1.8271 - val_categorical_accuracy: 0.3143\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.7419 - categorical_accuracy: 0.3117 - val_loss: 2.0408 - val_categorical_accuracy: 0.2748\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.6874 - categorical_accuracy: 0.3385 - val_loss: 1.8672 - val_categorical_accuracy: 0.3456\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.5979 - categorical_accuracy: 0.3556 - val_loss: 1.8225 - val_categorical_accuracy: 0.3180\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.5207 - categorical_accuracy: 0.3751 - val_loss: 2.6900 - val_categorical_accuracy: 0.2022\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.34      0.18       191\n",
            "         1.0       0.31      0.15      0.20       172\n",
            "         2.0       0.04      0.01      0.01       134\n",
            "         3.0       0.14      0.11      0.12       216\n",
            "         4.0       0.71      0.17      0.28      1036\n",
            "         5.0       0.05      0.87      0.10        77\n",
            "         6.0       0.89      0.76      0.82       196\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.16      0.23      0.19       139\n",
            "         9.0       0.53      0.14      0.23       257\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.30      0.28      0.21      2708\n",
            "weighted avg       0.44      0.21      0.24      2708\n",
            "\n",
            "0.27716701127652676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fold4: intentionally separate cells for check point purpose."
      ],
      "metadata": {
        "id": "6K_0Ui6OTMAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[4]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df39aae-adf1-4413-aa67-68aa533b5bad",
        "id": "JkyzsU7ITMAn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learning =1e-3\n",
        "learning_rate_fine_tuning = 1e-5"
      ],
      "metadata": {
        "id": "aYkmxONsTMAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(balanced_accuracy_transfer_learning)==0:\n",
        "  balanced_accuracy_transfer_learning = []\n",
        "if len(balanced_accuracy_fine_tune)==0:\n",
        "  balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "XC4TWeiFTMAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03bd8a7-dea8-4f81-e140-5d7baba716c9",
        "id": "DQuRTCzSTMAo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([(False, 0.4, 0.0001, 1e-06), (True, 0.4, 0.0001, 1e-06), (False, 0.5, 0.001, 1e-05), (True, 0.5, 0.001, 1e-05), (False, 0.5, 0.001, 1e-06), (True, 0.5, 0.001, 1e-06), (False, 0.5, 0.0001, 1e-05), (True, 0.5, 0.0001, 1e-05), (False, 0.5, 0.0001, 1e-06), (True, 0.5, 0.0001, 1e-06), (False, 0.2, 0.001, 1e-05), (True, 0.2, 0.001, 1e-05)])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "roberta_base = TFAutoModel.from_pretrained('roberta-base')\n",
        "SEQ_LEN2=256\n",
        "#step1\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = roberta_base(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "print(model2.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "print(model2.summary() )#Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_transfer_learning.append(balanced_acc)\n",
        "\n",
        "\n",
        "#step5: fine tune\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_fine_tune.append(balanced_acc)\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgCaNNP6TMAo",
        "outputId": "5b78847d-97d0-47a8-9977-146b1327346e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_3 (TFRobertaM  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_9 (Global  (None, 768)         0           ['tf_roberta_model_3[0][0]']     \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_9[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 128)          98432       ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_379 (Dropout)          (None, 128)          0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 32)           4128        ['dropout_379[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 124,647,168\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_roberta_model_3 (TFRobertaM  TFBaseModelOutputWi  124645632  ['input_ids[0][0]',              \n",
            " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_9 (Global  (None, 768)         0           ['tf_roberta_model_3[0][0]']     \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_9[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 128)          98432       ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_379 (Dropout)          (None, 128)          0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 32)           4128        ['dropout_379[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 124,751,594\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 124,647,168\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 95s 135ms/step - loss: 2.2387 - categorical_accuracy: 0.1984 - val_loss: 2.4949 - val_categorical_accuracy: 0.1140\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 79s 131ms/step - loss: 2.0422 - categorical_accuracy: 0.2540 - val_loss: 2.4613 - val_categorical_accuracy: 0.1296\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 2.0013 - categorical_accuracy: 0.2702 - val_loss: 2.3154 - val_categorical_accuracy: 0.1553\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9734 - categorical_accuracy: 0.2760 - val_loss: 2.2367 - val_categorical_accuracy: 0.1388\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 79s 130ms/step - loss: 1.9499 - categorical_accuracy: 0.2833 - val_loss: 2.1433 - val_categorical_accuracy: 0.2022\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 80s 131ms/step - loss: 1.9332 - categorical_accuracy: 0.2811 - val_loss: 2.0063 - val_categorical_accuracy: 0.3061\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.25      0.16       190\n",
            "         1.0       0.22      0.25      0.24       173\n",
            "         2.0       0.06      0.27      0.10       135\n",
            "         3.0       0.13      0.04      0.06       217\n",
            "         4.0       0.56      0.45      0.50      1035\n",
            "         5.0       0.18      0.42      0.26        76\n",
            "         6.0       0.74      0.77      0.75       195\n",
            "         7.0       0.67      0.01      0.01       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.26      0.20      0.23       258\n",
            "\n",
            "    accuracy                           0.31      2708\n",
            "   macro avg       0.29      0.27      0.23      2708\n",
            "weighted avg       0.41      0.31      0.31      2708\n",
            "\n",
            "0.2668156662794425\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_3/roberta/pooler/dense/kernel:0', 'tf_roberta_model_3/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_3/roberta/pooler/dense/kernel:0', 'tf_roberta_model_3/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 207s 311ms/step - loss: 1.8802 - categorical_accuracy: 0.2860 - val_loss: 1.8673 - val_categorical_accuracy: 0.3070\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 187s 306ms/step - loss: 1.7863 - categorical_accuracy: 0.3150 - val_loss: 1.9109 - val_categorical_accuracy: 0.3208\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 187s 306ms/step - loss: 1.7393 - categorical_accuracy: 0.3206 - val_loss: 1.9823 - val_categorical_accuracy: 0.2877\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.6536 - categorical_accuracy: 0.3501 - val_loss: 1.7699 - val_categorical_accuracy: 0.3153\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 186s 306ms/step - loss: 1.5818 - categorical_accuracy: 0.3625 - val_loss: 1.8261 - val_categorical_accuracy: 0.3189\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.36      0.27       190\n",
            "         1.0       0.22      0.55      0.32       173\n",
            "         2.0       0.17      0.16      0.16       135\n",
            "         3.0       0.20      0.12      0.15       217\n",
            "         4.0       0.67      0.26      0.38      1035\n",
            "         5.0       0.19      0.71      0.30        76\n",
            "         6.0       0.67      0.88      0.76       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.12      0.04      0.06       139\n",
            "         9.0       0.26      0.70      0.37       258\n",
            "\n",
            "    accuracy                           0.33      2708\n",
            "   macro avg       0.27      0.38      0.28      2708\n",
            "weighted avg       0.39      0.33      0.31      2708\n",
            "\n",
            "0.3789276338922123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take average"
      ],
      "metadata": {
        "id": "pe8-xF5cTaOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracy_fine_tune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_d4-AXfTbbm",
        "outputId": "5a863b05-647a-4627-fb85-7393afee0b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.26625640318037086,\n",
              " 0.3447727236337791,\n",
              " 0.27716701127652676,\n",
              " 0.3789276338922123]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracy_fine_tune.append(0.3560173405159383)"
      ],
      "metadata": {
        "id": "VigXG8PeTctM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(balanced_accuracy_fine_tune)/5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyLDOdzQTuIy",
        "outputId": "9b676af9-1381-48ff-fb24-2d04d7d77c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3503256162888067"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conduct McNemar testing with the best parameter"
      ],
      "metadata": {
        "id": "YlyEV7MauGPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.2\n",
        "learning_rate_transfer_learning = 1e-3\n",
        "learning_rate_fine_tuning = 1e-5\n",
        "McNemar = {}# (is_fine_tuning?, dropout_rate, learning_rate_transfer_learning, learning_rate_fine_tuning)"
      ],
      "metadata": {
        "id": "fPOHXTZ5uJtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "SEQ_LEN2=256\n",
        "\n",
        "drop_out_rate = 0.2\n",
        "learning_rate_transfer_learning = 1e-3\n",
        "learning_rate_fine_tuning = 1e-5\n",
        "\n",
        "\n",
        "print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        ", learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "#step1\n",
        "roberta = TFAutoModel.from_pretrained('roberta-base')\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = roberta(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "#model2.summary()\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "#model2.summary() #Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "#step5: fine tune\n",
        "print(\"Fine tuning---------------\")\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "print(\"----------------------------------------\")\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6crn297uKT5",
        "outputId": "b43e454b-24e1-46b7-e20d-aaee587f697a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 158s 234ms/step - loss: 2.1384 - categorical_accuracy: 0.2122 - val_loss: 2.8267 - val_categorical_accuracy: 0.0901\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 138s 227ms/step - loss: 1.9793 - categorical_accuracy: 0.2636 - val_loss: 2.3489 - val_categorical_accuracy: 0.1480\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 138s 227ms/step - loss: 1.9232 - categorical_accuracy: 0.2825 - val_loss: 2.4198 - val_categorical_accuracy: 0.1379\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 138s 227ms/step - loss: 1.8901 - categorical_accuracy: 0.2974 - val_loss: 2.3096 - val_categorical_accuracy: 0.1581\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 138s 227ms/step - loss: 1.8674 - categorical_accuracy: 0.2979 - val_loss: 2.2364 - val_categorical_accuracy: 0.1801\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 138s 227ms/step - loss: 1.8519 - categorical_accuracy: 0.3018 - val_loss: 2.2021 - val_categorical_accuracy: 0.1691\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.07      0.07       190\n",
            "         1.0       0.13      0.46      0.20       173\n",
            "         2.0       0.06      0.45      0.11       135\n",
            "         3.0       0.15      0.25      0.19       216\n",
            "         4.0       0.73      0.05      0.10      1036\n",
            "         5.0       0.13      0.16      0.14        76\n",
            "         6.0       0.76      0.53      0.62       195\n",
            "         7.0       0.12      0.02      0.03       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.27      0.18      0.21       258\n",
            "\n",
            "    accuracy                           0.16      2708\n",
            "   macro avg       0.24      0.22      0.17      2708\n",
            "weighted avg       0.41      0.16      0.15      2708\n",
            "\n",
            "0.21715377119415202\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 357s 553ms/step - loss: 1.7825 - categorical_accuracy: 0.3348 - val_loss: 1.8293 - val_categorical_accuracy: 0.2960\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 333s 547ms/step - loss: 1.6608 - categorical_accuracy: 0.3509 - val_loss: 1.8948 - val_categorical_accuracy: 0.2923\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 333s 547ms/step - loss: 1.5689 - categorical_accuracy: 0.3829 - val_loss: 2.0517 - val_categorical_accuracy: 0.2491\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 333s 547ms/step - loss: 1.4769 - categorical_accuracy: 0.4039 - val_loss: 1.9109 - val_categorical_accuracy: 0.2978\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 333s 547ms/step - loss: 1.3818 - categorical_accuracy: 0.4348 - val_loss: 1.7944 - val_categorical_accuracy: 0.3529\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 333s 547ms/step - loss: 1.2942 - categorical_accuracy: 0.4637 - val_loss: 1.7972 - val_categorical_accuracy: 0.3438\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.28      0.28      0.28       190\n",
            "         1.0       0.20      0.61      0.30       173\n",
            "         2.0       0.08      0.12      0.10       135\n",
            "         3.0       0.28      0.11      0.15       216\n",
            "         4.0       0.68      0.35      0.46      1036\n",
            "         5.0       0.31      0.34      0.32        76\n",
            "         6.0       0.55      0.90      0.69       195\n",
            "         7.0       0.10      0.01      0.01       290\n",
            "         8.0       0.18      0.14      0.16       139\n",
            "         9.0       0.25      0.63      0.36       258\n",
            "\n",
            "    accuracy                           0.35      2708\n",
            "   macro avg       0.29      0.35      0.28      2708\n",
            "weighted avg       0.41      0.35      0.33      2708\n",
            "\n",
            "0.34869950762677604\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar_RoBERTa_split0_transfer_learning = pd.DataFrame(data= McNemar[(False,0.2, 1e-3,1e-5)] )\n",
        "McNemar_RoBERTa_split0_transfer_learning.to_csv(DIR + 'McNemar_RoBERTa_split0_transfer_learning.csv')\n",
        "\n",
        "McNemar_RoBERTa_split0_fine_tuning = pd.DataFrame(data= McNemar[(True, 0.2, 1e-3,1e-5)] )\n",
        "McNemar_RoBERTa_split0_fine_tuning.to_csv(DIR + 'McNemar_RoBERTa_split0_fine_tuning.csv')"
      ],
      "metadata": {
        "id": "EYcXdx2XxsgG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DWL5DlwVTHgV",
        "hWxfNJqYBfjD",
        "nONmunMa_h7T",
        "tkFQndSlD2y6",
        "YlyEV7MauGPQ"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1sjQz5CZPapBWwW26v-fvn1bA1qAMtQ8G",
      "authorship_tag": "ABX9TyMJW5t2YZQXRPOEJdU060Y+",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f44f7989f4e42d1adb6fd3f10532d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec487b13a30d4ec4ab7ff778fdf71875",
              "IPY_MODEL_2ffc22a29ce1412dadc05f3d7b7a35ba",
              "IPY_MODEL_abd99e9aadef4d2f80f927075923ba58"
            ],
            "layout": "IPY_MODEL_84b8f1ac7cda4fe596dfbb924f55a632"
          }
        },
        "ec487b13a30d4ec4ab7ff778fdf71875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aafa4f5400b4d7f8be311c2881a2af2",
            "placeholder": "​",
            "style": "IPY_MODEL_765630ed0d6c47e5b41392db257591e0",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "2ffc22a29ce1412dadc05f3d7b7a35ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94747a85cb514f758c9b365d2b5dc48e",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e630d77e739c42e6a4a7399a891448f9",
            "value": 29
          }
        },
        "abd99e9aadef4d2f80f927075923ba58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab610be6ba4349c2adff62277659b4d3",
            "placeholder": "​",
            "style": "IPY_MODEL_09f31d6a4ba740dba521b97dd222c232",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.04kB/s]"
          }
        },
        "84b8f1ac7cda4fe596dfbb924f55a632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2aafa4f5400b4d7f8be311c2881a2af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "765630ed0d6c47e5b41392db257591e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94747a85cb514f758c9b365d2b5dc48e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e630d77e739c42e6a4a7399a891448f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab610be6ba4349c2adff62277659b4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09f31d6a4ba740dba521b97dd222c232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b7569539af4eaeb3f324e040856dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fdd2bef2722419cb005a6001ae7e19b",
              "IPY_MODEL_dd487e15d8fa421db7b5259f9d66a7a6",
              "IPY_MODEL_f5c8c8576b1c451a9b96f6d4e98a308b"
            ],
            "layout": "IPY_MODEL_8133599680514d82b24e0d2ee4744b8d"
          }
        },
        "4fdd2bef2722419cb005a6001ae7e19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fbd384a79c44145866b750154836bd9",
            "placeholder": "​",
            "style": "IPY_MODEL_b425723d5a77435fa8f5f4bb24dc3124",
            "value": "Downloading config.json: 100%"
          }
        },
        "dd487e15d8fa421db7b5259f9d66a7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d27039990f74964a14abb15c6416981",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1075e83342943d287d1cd64d53d12f6",
            "value": 570
          }
        },
        "f5c8c8576b1c451a9b96f6d4e98a308b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75a3d8554e79481cac916794c545b139",
            "placeholder": "​",
            "style": "IPY_MODEL_496ee739986f400f9cb251a13fd047dd",
            "value": " 570/570 [00:00&lt;00:00, 21.4kB/s]"
          }
        },
        "8133599680514d82b24e0d2ee4744b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fbd384a79c44145866b750154836bd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b425723d5a77435fa8f5f4bb24dc3124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d27039990f74964a14abb15c6416981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1075e83342943d287d1cd64d53d12f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75a3d8554e79481cac916794c545b139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496ee739986f400f9cb251a13fd047dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8696072b50614fe7a14e4a7ba4f16acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4b2326f603442c78268d0b0fce7a4c3",
              "IPY_MODEL_9fb4b98a430243c68a16dabe8331af1a",
              "IPY_MODEL_83183062ecc8488fadb4f87d924e79dd"
            ],
            "layout": "IPY_MODEL_0398c45910974acebc11aac48d99ba82"
          }
        },
        "a4b2326f603442c78268d0b0fce7a4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_043be71c3a624b89aad0bc6ef6c59ef3",
            "placeholder": "​",
            "style": "IPY_MODEL_d36299a1fd5b499ca3d3ee85be4e8681",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "9fb4b98a430243c68a16dabe8331af1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59be3300a46241c0bca72e5e75977ae5",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f7085aa03504d14850d29b92f2fa670",
            "value": 213450
          }
        },
        "83183062ecc8488fadb4f87d924e79dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5383aa711b49493fba17a6c53b5e3c6a",
            "placeholder": "​",
            "style": "IPY_MODEL_75bbcd3e5d38450093818c9f68d1c061",
            "value": " 208k/208k [00:00&lt;00:00, 457kB/s]"
          }
        },
        "0398c45910974acebc11aac48d99ba82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "043be71c3a624b89aad0bc6ef6c59ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36299a1fd5b499ca3d3ee85be4e8681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59be3300a46241c0bca72e5e75977ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7085aa03504d14850d29b92f2fa670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5383aa711b49493fba17a6c53b5e3c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75bbcd3e5d38450093818c9f68d1c061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33faf452d09340f99fc5444711e44b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae8283a15eea4f4bb7cef7b8e64fcb37",
              "IPY_MODEL_6f3b238dc6b94faeb3f3efe78b0e239c",
              "IPY_MODEL_09028592f4c4486da8434580b2ef37dd"
            ],
            "layout": "IPY_MODEL_8c4cc79788a6416ebdf65587eadb05a7"
          }
        },
        "ae8283a15eea4f4bb7cef7b8e64fcb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6eddbda476e44679a46acd357d20676",
            "placeholder": "​",
            "style": "IPY_MODEL_8eda9b1e0f0841d3a2f35c102f017021",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "6f3b238dc6b94faeb3f3efe78b0e239c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e8f4a2e94f43c3b79f5a06fc2507f4",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f8ba8f9293e4266a4c72fd9f6b96a56",
            "value": 435797
          }
        },
        "09028592f4c4486da8434580b2ef37dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1fdf93331b473fac1ae62ddb9af79c",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b979b56863404086279aae950e89e0",
            "value": " 426k/426k [00:00&lt;00:00, 608kB/s]"
          }
        },
        "8c4cc79788a6416ebdf65587eadb05a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6eddbda476e44679a46acd357d20676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eda9b1e0f0841d3a2f35c102f017021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e8f4a2e94f43c3b79f5a06fc2507f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f8ba8f9293e4266a4c72fd9f6b96a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d1fdf93331b473fac1ae62ddb9af79c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b979b56863404086279aae950e89e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf922c8f428444c08622abc048d16c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdf80bd13f334c5985032c1206d793af",
              "IPY_MODEL_0ba6cc9cf60e4e21ba2b097389544d3d",
              "IPY_MODEL_f6b01f0a84314988bdc219e3a6772ac5"
            ],
            "layout": "IPY_MODEL_de06093f8f35498cbb07ad8cfe599b45"
          }
        },
        "cdf80bd13f334c5985032c1206d793af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc9b821cb0e84ef2a7e6ced1acc4521b",
            "placeholder": "​",
            "style": "IPY_MODEL_09d2157428df45e69608ec3e66a9a082",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "0ba6cc9cf60e4e21ba2b097389544d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc46237759d248dfba9999388d2ea923",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca97ba6cd13044e5a43ee81bc98510be",
            "value": 526681800
          }
        },
        "f6b01f0a84314988bdc219e3a6772ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f69e3b9a164d1c91a3341490e88a03",
            "placeholder": "​",
            "style": "IPY_MODEL_b5d74376254e42da916bedc2615c74d4",
            "value": " 502M/502M [00:26&lt;00:00, 20.9MB/s]"
          }
        },
        "de06093f8f35498cbb07ad8cfe599b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc9b821cb0e84ef2a7e6ced1acc4521b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d2157428df45e69608ec3e66a9a082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc46237759d248dfba9999388d2ea923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca97ba6cd13044e5a43ee81bc98510be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03f69e3b9a164d1c91a3341490e88a03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d74376254e42da916bedc2615c74d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98d36cfd45f44e26bc7761ce59547224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81af9be098414483a2e849398b4452bc",
              "IPY_MODEL_24bf4b150cda4c6a9225b58a3dab4205",
              "IPY_MODEL_4ebdb75059d24ee0958be4681081a12d"
            ],
            "layout": "IPY_MODEL_70831f80e4664f5698feab1ae159677c"
          }
        },
        "81af9be098414483a2e849398b4452bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f610941746d4e3d8315daa1f4c1c7e6",
            "placeholder": "​",
            "style": "IPY_MODEL_f7e0775716c94358b7e2e77526a293c3",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "24bf4b150cda4c6a9225b58a3dab4205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa26e687eb3a484383c9533ade31c304",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_837e939a7d6540d6b77a96c842661f98",
            "value": 526681800
          }
        },
        "4ebdb75059d24ee0958be4681081a12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72d229c28fb145f7aa3cef7d7be72abb",
            "placeholder": "​",
            "style": "IPY_MODEL_5373dde9ca214785a80323cd11f48937",
            "value": " 502M/502M [00:09&lt;00:00, 47.7MB/s]"
          }
        },
        "70831f80e4664f5698feab1ae159677c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f610941746d4e3d8315daa1f4c1c7e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7e0775716c94358b7e2e77526a293c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa26e687eb3a484383c9533ade31c304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "837e939a7d6540d6b77a96c842661f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72d229c28fb145f7aa3cef7d7be72abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5373dde9ca214785a80323cd11f48937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d272c4ca403b4a47b1ece3efc81b4c60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e504b3e620e44a5b2524210523370b9",
              "IPY_MODEL_fa78b894e25c444db500eb6f586219e7",
              "IPY_MODEL_4dce5494f1a544bfb236d816e815156c"
            ],
            "layout": "IPY_MODEL_a6baa10cad3c4cf297400c2a6c26836c"
          }
        },
        "1e504b3e620e44a5b2524210523370b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48bea4ef9e0b4ef7862cd2e3adedae03",
            "placeholder": "​",
            "style": "IPY_MODEL_af6987c103ca420a906441fb26a6ae34",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "fa78b894e25c444db500eb6f586219e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d826796faf64e0bae02f9f62cbdae0c",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8dde7f29f7740c58477e18a3b9a3ca6",
            "value": 526681800
          }
        },
        "4dce5494f1a544bfb236d816e815156c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d265b0a6d7f46d98d37f5f00c9ac6e0",
            "placeholder": "​",
            "style": "IPY_MODEL_3f6a1352f8dc4e6cb4d20628323e6d87",
            "value": " 502M/502M [00:07&lt;00:00, 68.1MB/s]"
          }
        },
        "a6baa10cad3c4cf297400c2a6c26836c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48bea4ef9e0b4ef7862cd2e3adedae03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af6987c103ca420a906441fb26a6ae34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d826796faf64e0bae02f9f62cbdae0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8dde7f29f7740c58477e18a3b9a3ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d265b0a6d7f46d98d37f5f00c9ac6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6a1352f8dc4e6cb4d20628323e6d87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "494f3523b997428a8e07e2ff9f777278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7cc9f333c2b43c984854bf2a05c216b",
              "IPY_MODEL_799f47064001473b9e2926d8b9f2a1c3",
              "IPY_MODEL_60f03dcd1f494937924689fbabcb165c"
            ],
            "layout": "IPY_MODEL_ab592251173e4fdeb9db0ac8037abf05"
          }
        },
        "b7cc9f333c2b43c984854bf2a05c216b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_069364167ee44547b1d841e3d488898c",
            "placeholder": "​",
            "style": "IPY_MODEL_7c4eabafda57425980d8b661c5c4d4ef",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "799f47064001473b9e2926d8b9f2a1c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bb505313711439c87d7ffe87c59b58b",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70a006728ee3429aa61eb3763bd2d601",
            "value": 526681800
          }
        },
        "60f03dcd1f494937924689fbabcb165c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd77628f26774bf4a5c03d5d92e6919b",
            "placeholder": "​",
            "style": "IPY_MODEL_eb67aaba5d62417d94b683b2f8254d31",
            "value": " 502M/502M [00:08&lt;00:00, 65.9MB/s]"
          }
        },
        "ab592251173e4fdeb9db0ac8037abf05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069364167ee44547b1d841e3d488898c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c4eabafda57425980d8b661c5c4d4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bb505313711439c87d7ffe87c59b58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70a006728ee3429aa61eb3763bd2d601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd77628f26774bf4a5c03d5d92e6919b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb67aaba5d62417d94b683b2f8254d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05ce66e4bd7045e5bfca4025886d219d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_909c9d4b575543879765d871847f2f6a",
              "IPY_MODEL_7e7090853d2d444b8f011659f2147ac3",
              "IPY_MODEL_fdf96e564ee4446caec4471bef691679"
            ],
            "layout": "IPY_MODEL_30bbac742239451b9f17c52b98695ec6"
          }
        },
        "909c9d4b575543879765d871847f2f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_763420132a35401c8865005eb4c3eb09",
            "placeholder": "​",
            "style": "IPY_MODEL_c3ae1df16fd9472696aedb4a64485167",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "7e7090853d2d444b8f011659f2147ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8329ae8f3efe4931b1ae3690e1127319",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dda33ea712045baba20dff1f1f99512",
            "value": 526681800
          }
        },
        "fdf96e564ee4446caec4471bef691679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2671f8891a04b6aa692330f01d994f7",
            "placeholder": "​",
            "style": "IPY_MODEL_0ffd1a44c92544988c0a299b379ebbc8",
            "value": " 502M/502M [00:13&lt;00:00, 41.5MB/s]"
          }
        },
        "30bbac742239451b9f17c52b98695ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "763420132a35401c8865005eb4c3eb09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ae1df16fd9472696aedb4a64485167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8329ae8f3efe4931b1ae3690e1127319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dda33ea712045baba20dff1f1f99512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2671f8891a04b6aa692330f01d994f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ffd1a44c92544988c0a299b379ebbc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdac008971504c069f4e240f10a049cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9fd1f6cb1994cdabfe96fe68484eb1a",
              "IPY_MODEL_ad5d86b91fd14e8bab8b3f3e15f22da6",
              "IPY_MODEL_8ec6453bad714888a56fd909440bd398"
            ],
            "layout": "IPY_MODEL_63eb27215ab847f2aebad7d6e5ea35e8"
          }
        },
        "f9fd1f6cb1994cdabfe96fe68484eb1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fde394d01b264e07ae7c07ccafdae6c4",
            "placeholder": "​",
            "style": "IPY_MODEL_2d202fd6d45e440a9953fe80c8fd476d",
            "value": "Downloading config.json: 100%"
          }
        },
        "ad5d86b91fd14e8bab8b3f3e15f22da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34efba7726b640889575959261f0cfe7",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dbf1ef7980e452aaca49b5447f7ae6b",
            "value": 481
          }
        },
        "8ec6453bad714888a56fd909440bd398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b4f71e00d4c4c63b6b84f2a7e525559",
            "placeholder": "​",
            "style": "IPY_MODEL_81088231ee7b4f6893e136a8d12941fd",
            "value": " 481/481 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "63eb27215ab847f2aebad7d6e5ea35e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde394d01b264e07ae7c07ccafdae6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d202fd6d45e440a9953fe80c8fd476d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34efba7726b640889575959261f0cfe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbf1ef7980e452aaca49b5447f7ae6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b4f71e00d4c4c63b6b84f2a7e525559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81088231ee7b4f6893e136a8d12941fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07ac6dc4628a4f048a7fb7180611185c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a19a51846344a5ebc0abcc9cce0e2c6",
              "IPY_MODEL_9a446421b64c428d87a64133977e3bf9",
              "IPY_MODEL_ba956548e2ea4ec5b7988597ee642ddf"
            ],
            "layout": "IPY_MODEL_7ef3942ee94e47e385bd4bb25a34ca13"
          }
        },
        "5a19a51846344a5ebc0abcc9cce0e2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10d50a4cede4ee9b7d1c3d991bc5394",
            "placeholder": "​",
            "style": "IPY_MODEL_14000dc3c37e499daf2e19e7e7c564ff",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "9a446421b64c428d87a64133977e3bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d62baa87c2043348e835705ccabc772",
            "max": 657434796,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b2e7832be724026a13c77b92b67e324",
            "value": 657434796
          }
        },
        "ba956548e2ea4ec5b7988597ee642ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7529487daaa247c08bb6004957c46c6c",
            "placeholder": "​",
            "style": "IPY_MODEL_89cf43d486284b5388e298ceb06997d2",
            "value": " 627M/627M [00:10&lt;00:00, 64.4MB/s]"
          }
        },
        "7ef3942ee94e47e385bd4bb25a34ca13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a10d50a4cede4ee9b7d1c3d991bc5394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14000dc3c37e499daf2e19e7e7c564ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d62baa87c2043348e835705ccabc772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2e7832be724026a13c77b92b67e324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7529487daaa247c08bb6004957c46c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89cf43d486284b5388e298ceb06997d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94f8bc87fd694827852a213f8a17527a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eca728284a8f411db009b4b5894fcb5c",
              "IPY_MODEL_5eaf5a66f0464462ac9443ad26abb68e",
              "IPY_MODEL_4f7349751768430da050b45340f9ccbc"
            ],
            "layout": "IPY_MODEL_9b0ccabb7e09493eaf7a31c19073e571"
          }
        },
        "eca728284a8f411db009b4b5894fcb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34fe24a3f4a5468f9c07cec48ef1e497",
            "placeholder": "​",
            "style": "IPY_MODEL_bddc8f8bb31b4ab4a124a85894c7f7b2",
            "value": "Downloading vocab.json: 100%"
          }
        },
        "5eaf5a66f0464462ac9443ad26abb68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98db0bea40fd4ea39815fcea8670de20",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4b5fc21d8dc464c9923c329898d4384",
            "value": 898823
          }
        },
        "4f7349751768430da050b45340f9ccbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8091b889eb94ee3bff5518b80edecb4",
            "placeholder": "​",
            "style": "IPY_MODEL_1a587c4a581c4aa4b0996a488a182ff7",
            "value": " 878k/878k [00:00&lt;00:00, 2.02MB/s]"
          }
        },
        "9b0ccabb7e09493eaf7a31c19073e571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34fe24a3f4a5468f9c07cec48ef1e497": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bddc8f8bb31b4ab4a124a85894c7f7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98db0bea40fd4ea39815fcea8670de20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4b5fc21d8dc464c9923c329898d4384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8091b889eb94ee3bff5518b80edecb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a587c4a581c4aa4b0996a488a182ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddb863956ab74dfc868afc62d4788820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cdc29dab405471a9a022ab6a284abb8",
              "IPY_MODEL_df7462404d174fa3bbec01523fe8bea3",
              "IPY_MODEL_a176217c38724f1788dc7566114b4d58"
            ],
            "layout": "IPY_MODEL_49ce689060c34a81959c9392d6e3a732"
          }
        },
        "5cdc29dab405471a9a022ab6a284abb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d97c42458a2a407d8e576dda48af216a",
            "placeholder": "​",
            "style": "IPY_MODEL_f641ac563f964c62808aceaf809e61e8",
            "value": "Downloading merges.txt: 100%"
          }
        },
        "df7462404d174fa3bbec01523fe8bea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d01b9e34dc462197387e93cca13b16",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2180b2c9eba440f90a79c4eefc647fa",
            "value": 456318
          }
        },
        "a176217c38724f1788dc7566114b4d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d273b47d794c45f8afdf919e34dc54f5",
            "placeholder": "​",
            "style": "IPY_MODEL_de21ee87818b4848827fd2b44eb6ffbd",
            "value": " 446k/446k [00:00&lt;00:00, 628kB/s]"
          }
        },
        "49ce689060c34a81959c9392d6e3a732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97c42458a2a407d8e576dda48af216a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f641ac563f964c62808aceaf809e61e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75d01b9e34dc462197387e93cca13b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2180b2c9eba440f90a79c4eefc647fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d273b47d794c45f8afdf919e34dc54f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de21ee87818b4848827fd2b44eb6ffbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f18cc3dd56d41aea970045fb788bcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_330de2a0937345a2b90e2bcb03e26bfc",
              "IPY_MODEL_6f2529a23bc642a99be3aed410acdf9e",
              "IPY_MODEL_0a2b658646034eb39a8d07620feec854"
            ],
            "layout": "IPY_MODEL_5b9985e281b6498aa5de094d632b213b"
          }
        },
        "330de2a0937345a2b90e2bcb03e26bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14331b2af930420dab782757a5842855",
            "placeholder": "​",
            "style": "IPY_MODEL_ffa9703c1dcf496d93e06739d05d9d90",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "6f2529a23bc642a99be3aed410acdf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22640fa49fde4c4fb4c25cb22093c8c5",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6beb071303fe41ed9ba2c480d6e6d907",
            "value": 1355863
          }
        },
        "0a2b658646034eb39a8d07620feec854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fe4b232c97d485cba64472dfd57fdc5",
            "placeholder": "​",
            "style": "IPY_MODEL_be668a74359d48d09c93c9586cbb30e8",
            "value": " 1.29M/1.29M [00:00&lt;00:00, 1.73MB/s]"
          }
        },
        "5b9985e281b6498aa5de094d632b213b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14331b2af930420dab782757a5842855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa9703c1dcf496d93e06739d05d9d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22640fa49fde4c4fb4c25cb22093c8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6beb071303fe41ed9ba2c480d6e6d907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fe4b232c97d485cba64472dfd57fdc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be668a74359d48d09c93c9586cbb30e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
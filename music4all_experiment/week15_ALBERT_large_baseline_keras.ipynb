{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KenObata/TISMIR_notebooks/blob/main/week15_ALBERT_large_baseline_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS8WVxEoWZG0"
      },
      "source": [
        "## Week15: This notebook uses Pre-Trained word matrix-> SMOTE -> undersample by EDA -> append to word vectors. -> using Word2Vec. After that I apply SMOTE to balance out. \n",
        "Added task: Grid Search for best parameter in SVM.\n",
        "\n",
        "Situation: English only (=multi-class).\n",
        "Split: StratifiedKfold.\n",
        "Reference: https://github.com/jasonwei20/eda_nlp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWL5DlwVTHgV"
      },
      "source": [
        "### set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Fdw4QzS4FD",
        "outputId": "616f5096-adcd-4f51-c17b-ccbf8ab9653f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 2.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d5F3EmWPVWZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from collections import Counter\n",
        "\n",
        "from skmultilearn.model_selection import IterativeStratification   \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "def get_balanced_accuracy(model, McNemar, is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning):\n",
        "  test_y = test.map(map_func_only_y)\n",
        "  y_category=np.zeros((TEST_SIZE, ))\n",
        "  counter=0\n",
        "  for label_tensor in test_y.take(len(test_y)):\n",
        "    y_test = np.argmax(label_tensor, axis=1)\n",
        "    for label in y_test:\n",
        "      y_category[counter]=label\n",
        "      counter+=1\n",
        "\n",
        "  X_test, y_test = test.map(map_func_only_X), y_category\n",
        "  y_predict_test = np.asarray(model.predict(X_test))\n",
        "  y_predict_test = np.argmax(y_predict_test, axis=1)\n",
        "  print(classification_report(y_test, y_predict_test) )\n",
        "  print(balanced_accuracy_score(y_test, y_predict_test))\n",
        "\n",
        "  McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)] = []\n",
        "  for ground_truh, pred in zip(y_test, y_predict_test):\n",
        "        if ground_truh==pred:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(True)\n",
        "        else:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(False)\n",
        "  with open(DIR+ \"ALBERT_large_log.txt\", \"a\") as f:\n",
        "    print(\"======================================\", file=f)\n",
        "    print(\"is_fine_tuning?:\", is_fine_tuning, \"drop_out_rate: \", drop_out_rate, \"learning_rate_transfer_learning: \", learning_rate_transfer_learning,\n",
        "          \"learning_rate_fine_tuning: \", learning_rate_fine_tuning, file=f)\n",
        "    print(classification_report(y_test, y_predict_test) , file=f)\n",
        "    print(balanced_accuracy_score(y_test, y_predict_test), file=f)\n",
        "\n",
        "  return balanced_accuracy_score(y_test, y_predict_test), McNemar"
      ],
      "metadata": {
        "id": "K6VTlTxg8JVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWxfNJqYBfjD"
      },
      "source": [
        "### Data Preparation(Kfold split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbT7Qs4whnTX"
      },
      "source": [
        "Create dataframe for Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le3tiKjOOp19",
        "outputId": "c28ce282-4800-4b84-fe2e-0460618db459"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                id             genres lang  \\\n",
              "0               0  0009fFIM1eYThaPg                pop   en   \n",
              "1               1  00P2bHdWFkghmDqz               soul   en   \n",
              "2               2  00b6fV3nx5z2b8Ls                pop   en   \n",
              "3               3  013QDoTqbexEwkHr                pop   en   \n",
              "4               4  01EKNot8qVgZpKM7               rock   en   \n",
              "...           ...               ...                ...  ...   \n",
              "13535       13535  zzT504Z94j1IAuc3         indie rock   en   \n",
              "13536       13536  zzgS4ZqyswamEWNj                pop   en   \n",
              "13537       13537  zzx8CWdM7qkxKQpC         indie rock   en   \n",
              "13538       13538  zzz0n04uuTUA7fNh                pop   en   \n",
              "13539       13539  zzzj3LYaZtYtbzSr  singer-songwriter   en   \n",
              "\n",
              "                                                   lyric  number_of_line  \n",
              "0      a sunny day so I got nowhere to hide Not a clo...              91  \n",
              "1      Tell me a tale that always was Sing me a song ...              36  \n",
              "2      A buh A buh You went to school to learn girl T...              74  \n",
              "3      like a conversation where stops to breathe Is ...              20  \n",
              "4      Say the words I cannot say Say them on another...              31  \n",
              "...                                                  ...             ...  \n",
              "13535  think what afraid of come in you know been mad...              18  \n",
              "13536  Oh yeah yeah Last night I took a walk in the s...              75  \n",
              "13537  Innocence it come easy in a sense it never wil...              34  \n",
              "13538  Girl you know how I feel I really Since you be...              65  \n",
              "13539  wwI oh must go on standing You break that whic...              64  \n",
              "\n",
              "[13540 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ea1e6ce-98b0-40d3-aabd-fe481d5b94af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>genres</th>\n",
              "      <th>lang</th>\n",
              "      <th>lyric</th>\n",
              "      <th>number_of_line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0009fFIM1eYThaPg</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>a sunny day so I got nowhere to hide Not a clo...</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>00P2bHdWFkghmDqz</td>\n",
              "      <td>soul</td>\n",
              "      <td>en</td>\n",
              "      <td>Tell me a tale that always was Sing me a song ...</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>00b6fV3nx5z2b8Ls</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>A buh A buh You went to school to learn girl T...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>013QDoTqbexEwkHr</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>like a conversation where stops to breathe Is ...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>01EKNot8qVgZpKM7</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Say the words I cannot say Say them on another...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>13535</td>\n",
              "      <td>zzT504Z94j1IAuc3</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>think what afraid of come in you know been mad...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>13536</td>\n",
              "      <td>zzgS4ZqyswamEWNj</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Oh yeah yeah Last night I took a walk in the s...</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>13537</td>\n",
              "      <td>zzx8CWdM7qkxKQpC</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Innocence it come easy in a sense it never wil...</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>13538</td>\n",
              "      <td>zzz0n04uuTUA7fNh</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Girl you know how I feel I really Since you be...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>13539</td>\n",
              "      <td>zzzj3LYaZtYtbzSr</td>\n",
              "      <td>singer-songwriter</td>\n",
              "      <td>en</td>\n",
              "      <td>wwI oh must go on standing You break that whic...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ea1e6ce-98b0-40d3-aabd-fe481d5b94af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ea1e6ce-98b0-40d3-aabd-fe481d5b94af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ea1e6ce-98b0-40d3-aabd-fe481d5b94af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "df_genre_by_lang = pd.read_csv(DIR + 'df_genre_by_lang_full.csv')\n",
        "df_genre_by_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrRidTBHhmYp"
      },
      "outputs": [],
      "source": [
        "def load_data(df_col, y):\n",
        "    texts, labels = [], []\n",
        "    \n",
        "    for line in df_col:\n",
        "        # texts are already tokenized, just split on space\n",
        "        # in a real use-case we would put more effort in preprocessing\n",
        "        texts.append(line.split(' '))\n",
        "    return pd.DataFrame({'texts': texts, 'labels': y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5VJWiA6iJu2"
      },
      "outputs": [],
      "source": [
        "data = load_data(df_genre_by_lang[\"lyric\"], df_genre_by_lang[\"genres\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWI4V7oXiWw6",
        "outputId": "31041d2a-e883-4550-eb08-067a2d5f8ffe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   texts             labels\n",
              "0      [a, sunny, day, so, I, got, nowhere, to, hide,...                pop\n",
              "1      [Tell, me, a, tale, that, always, was, Sing, m...               soul\n",
              "2      [A, buh, A, buh, You, went, to, school, to, le...                pop\n",
              "3      [like, a, conversation, where, stops, to, brea...                pop\n",
              "4      [Say, the, words, I, cannot, say, Say, them, o...               rock\n",
              "...                                                  ...                ...\n",
              "13535  [think, what, afraid, of, come, in, you, know,...         indie rock\n",
              "13536  [Oh, yeah, yeah, Last, night, I, took, a, walk...                pop\n",
              "13537  [Innocence, it, come, easy, in, a, sense, it, ...         indie rock\n",
              "13538  [Girl, you, know, how, I, feel, I, really, Sin...                pop\n",
              "13539  [wwI, oh, must, go, on, standing, You, break, ...  singer-songwriter\n",
              "\n",
              "[13540 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c05ba6b7-3d56-4c92-a5e4-8e9b6b02bcf2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[a, sunny, day, so, I, got, nowhere, to, hide,...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Tell, me, a, tale, that, always, was, Sing, m...</td>\n",
              "      <td>soul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[A, buh, A, buh, You, went, to, school, to, le...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[like, a, conversation, where, stops, to, brea...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Say, the, words, I, cannot, say, Say, them, o...</td>\n",
              "      <td>rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>[think, what, afraid, of, come, in, you, know,...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>[Oh, yeah, yeah, Last, night, I, took, a, walk...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>[Innocence, it, come, easy, in, a, sense, it, ...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>[Girl, you, know, how, I, feel, I, really, Sin...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>[wwI, oh, must, go, on, standing, You, break, ...</td>\n",
              "      <td>singer-songwriter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c05ba6b7-3d56-4c92-a5e4-8e9b6b02bcf2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c05ba6b7-3d56-4c92-a5e4-8e9b6b02bcf2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c05ba6b7-3d56-4c92-a5e4-8e9b6b02bcf2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTROinyfjc6u"
      },
      "outputs": [],
      "source": [
        "data['labels'] = data['labels'].astype('category')\n",
        "label_mapping = data['labels'].cat.categories\n",
        "data['labels'] = data['labels'].cat.codes\n",
        "X = data['texts']\n",
        "y = data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32Ub0-kjoOj",
        "outputId": "68b50b43-1723-444b-ea42-22e01d5876cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnAEWk_Lza7f"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df_glove(df, feature_list, y_name):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  y = df[y_name]\n",
        "  skf.get_n_splits(df[ feature_list ], y)\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(df[ feature_list ], y):\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = df[ feature_list ].loc[train_index], df[ feature_list ].loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qOv6pF0BcrV"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df(X, y):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  #y = df[y_name]\n",
        "  skf.get_n_splits(X, y)#df[ feature_list ]\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(X, y):#df[ feature_list ]\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGZPLOeBg4R",
        "outputId": "a0aa1f21-4f16-4933-da7c-19b804d7bd4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [    0     1     3 ... 13537 13538 13539] TEST: [    2     4     5 ... 13526 13532 13535]\n",
            "TRAIN: [    0     2     4 ... 13535 13536 13539] TEST: [    1     3     7 ... 13530 13537 13538]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [    8    14    22 ... 13521 13531 13536]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [   10    12    15 ... 13523 13525 13534]\n",
            "TRAIN: [    1     2     3 ... 13536 13537 13538] TEST: [    0     6    11 ... 13529 13533 13539]\n"
          ]
        }
      ],
      "source": [
        "#feature_list = [\"texts\"] #this is BOW and TF-IDF\n",
        "#splits = StratifiedKFold_feature_and_df( data, feature_list, 'labels')\n",
        "splits = StratifiedKFold_feature_and_df( X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsQYbmVUWPU9",
        "outputId": "a95af708-691f-433e-9d79-d235b25bd446"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDMBs_gWCSLa",
        "outputId": "bc36f543-ff70-49aa-8cc3-f74e87db128c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,)\n",
            "(10832,)\n",
            "(2708,)\n",
            "(2708,)\n"
          ]
        }
      ],
      "source": [
        "split0=splits[0]\n",
        "print(split0['X_train'].shape)\n",
        "print(split0['y_train'].shape)\n",
        "print(split0['X_test'].shape)\n",
        "print(split0['y_test'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaMmpM44is_p",
        "outputId": "6c67c2b3-270d-45cd-89f8-df055f9ecb43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [a, sunny, day, so, I, got, nowhere, to, hide,...\n",
              "1        [Tell, me, a, tale, that, always, was, Sing, m...\n",
              "3        [like, a, conversation, where, stops, to, brea...\n",
              "6        [Locked, up, tight, Like, I, would, never, fee...\n",
              "7        [sittin, in, the, crib, dreamin, about, leer, ...\n",
              "                               ...                        \n",
              "13534    [grandma, cookies, nigga, Shout, out, to, fron...\n",
              "13536    [Oh, yeah, yeah, Last, night, I, took, a, walk...\n",
              "13537    [Innocence, it, come, easy, in, a, sense, it, ...\n",
              "13538    [Girl, you, know, how, I, feel, I, really, Sin...\n",
              "13539    [wwI, oh, must, go, on, standing, You, break, ...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "split0['X_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qTuHLEe8Aqg",
        "outputId": "bddc4e32-0153-463b-8725-a78d9861d010"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "split0['y_train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONmunMa_h7T"
      },
      "source": [
        "### Use my self programmed balanced accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot3KP7Dl_kdf",
        "outputId": "b39a20db-171b-4ef7-bd3a-e1a9522eb463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "339/339 [==============================] - 225s 645ms/step - loss: 0.5565 - categorical_accuracy: 0.3878 - val_loss: 1.9337 - val_categorical_accuracy: 0.3273\n",
            "Epoch 2/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5397 - categorical_accuracy: 0.3626 - val_loss: 2.0651 - val_categorical_accuracy: 0.2764\n",
            "Epoch 3/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5375 - categorical_accuracy: 0.3392 - val_loss: 2.0931 - val_categorical_accuracy: 0.2273\n",
            "Epoch 4/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5378 - categorical_accuracy: 0.3197 - val_loss: 2.0576 - val_categorical_accuracy: 0.2459\n",
            "Epoch 5/10\n",
            "339/339 [==============================] - 219s 645ms/step - loss: 0.5333 - categorical_accuracy: 0.3077 - val_loss: 2.0292 - val_categorical_accuracy: 0.2816\n",
            "Epoch 6/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5373 - categorical_accuracy: 0.2967 - val_loss: 2.1738 - val_categorical_accuracy: 0.1895\n",
            "Epoch 7/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5396 - categorical_accuracy: 0.2930 - val_loss: 2.1382 - val_categorical_accuracy: 0.2181\n",
            "Epoch 8/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5431 - categorical_accuracy: 0.2710 - val_loss: 2.1512 - val_categorical_accuracy: 0.1965\n",
            "Epoch 9/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5450 - categorical_accuracy: 0.2729 - val_loss: 2.1854 - val_categorical_accuracy: 0.1092\n",
            "Epoch 10/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5495 - categorical_accuracy: 0.2553 - val_loss: 2.1354 - val_categorical_accuracy: 0.1594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'balanced_accuracy': 0.09744849916749872},\n",
              " {'balanced_accuracy': 0.10420636932765996},\n",
              " {'balanced_accuracy': 0.10970405736872939},\n",
              " {'balanced_accuracy': 0.10356561320774078},\n",
              " {'balanced_accuracy': 0.10792864804613309},\n",
              " {'balanced_accuracy': 0.09168989857066105},\n",
              " {'balanced_accuracy': 0.09926135499834263},\n",
              " {'balanced_accuracy': 0.10014630125778516},\n",
              " {'balanced_accuracy': 0.09807505457274496},\n",
              " {'balanced_accuracy': 0.09881853716030842}]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics = Metrics()\n",
        "history = model.fit(train, validation_data=val, epochs=10, class_weight=my_weight ,callbacks=[metrics])\n",
        "metrics.get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzqLBSC6H175"
      },
      "source": [
        "## From here, separate X_train, X_test from KFOldSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb0KcNXhbUSN"
      },
      "source": [
        "### Preprocess my lyrics data (Official train and test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4lLLyF-bUSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6291d54c-eaf8-40a9-bfb3-3b6f0779f3b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 34.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "!pip3 install transformers\n",
        "SEQ_LEN = 256#512"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUA-ps2gyvt",
        "outputId": "17b29dbf-53c8-4d11-ddc2-d3feba12c514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2        [A, buh, A, buh, You, went, to, school, to, le...\n",
              "4        [Say, the, words, I, cannot, say, Say, them, o...\n",
              "5        [I, was, alone, I, was, made, of, stone, You, ...\n",
              "9        [Again, the, burden, of, losing, rests, upon, ...\n",
              "20       [only, been, three, weeks, And, a, bag, of, sp...\n",
              "                               ...                        \n",
              "13517    [Like, the, legend, of, the, Phoenix, All, end...\n",
              "13522    [Mr, Telephone, man, something, wrong, with, m...\n",
              "13526    [can, you, imagine, what, it, would, be, like,...\n",
              "13532    [Love, of, my, life, hurt, me, broken, my, hea...\n",
              "13535    [think, what, afraid, of, come, in, you, know,...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_lyrics(X_series):\n",
        "  for i, token_list in X_series.items():\n",
        "    if type(token_list) is list:\n",
        "      X_series.loc[i] = ' '.join(token_list)\n",
        "  return X_series"
      ],
      "metadata": {
        "id": "PqFwOGTIbhiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "split0['X_test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzTIRCW1cUwV",
        "outputId": "33e35718-6877-4e61-9897-e93998abccda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2        A buh A buh You went to school to learn girl T...\n",
              "4        Say the words I cannot say Say them on another...\n",
              "5        I was alone I was made of stone You took me ho...\n",
              "9        Again the burden of losing rests upon my shoul...\n",
              "20       only been three weeks And a bag of speed from ...\n",
              "                               ...                        \n",
              "13517    Like the legend of the Phoenix All ends with b...\n",
              "13522    Mr Telephone man something wrong with my line ...\n",
              "13526    can you imagine what it would be like we never...\n",
              "13532    Love of my life hurt me broken my heart and no...\n",
              "13535    think what afraid of come in you know been mad...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_train'] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxixg4yAcAfe",
        "outputId": "2fbc6572-9e0c-4c95-be34-031bda3f5bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        a sunny day so I got nowhere to hide Not a clo...\n",
              "1        Tell me a tale that always was Sing me a song ...\n",
              "3        like a conversation where stops to breathe Is ...\n",
              "6        Locked up tight Like I would never feel again ...\n",
              "7        sittin in the crib dreamin about leer jets and...\n",
              "                               ...                        \n",
              "13534    grandma cookies nigga Shout out to fronto leaf...\n",
              "13536    Oh yeah yeah Last night I took a walk in the s...\n",
              "13537    Innocence it come easy in a sense it never wil...\n",
              "13538    Girl you know how I feel I really Since you be...\n",
              "13539    wwI oh must go on standing You break that whic...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['y_train'] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9UxO1GAcfoI",
        "outputId": "72abce64-1a38-4d2e-c540-8f4b96ab0038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use ALBERT\n",
        "Be careful, you need sentencepiece library:https://stackoverflow.com/questions/65854722/huggingface-albert-tokenizer-nonetype-error-with-colab"
      ],
      "metadata": {
        "id": "9zWdtsKTSIjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QClJ2DWKVs0Q",
        "outputId": "f8fba33a-ba2d-4547-801f-14cb9fc3df51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "c7bbf41ebfd245dcbbaa47cfae1e325a",
            "a0d566968be248269790fd3ba5783915",
            "ddd856361c344f919ab1c8996f7da98d",
            "1394f3e609294612817b1707a4ad9364",
            "0eed20d3a16d40bfb9089a6f4720c714",
            "0328b3a4c3bf464eadca437316942d7e",
            "99c34b25a82e426fa05000b67d89839d",
            "e94ba8d1a16047d3b50a466ac93a5e8e",
            "bcb6ca0fd95a48ca9a2fa23f240dd63b",
            "bc83b47417b84c23aa649735e48e1095",
            "592361f890d048f78a2fc5f70f0d23c8",
            "4ff04f56385c4df6856f92080f45145a",
            "a53509d10690484aa6e678887d4261f6",
            "5efbd2459d334a02ae10d058a0afee00",
            "cd696eaa64384eada93dfa1a2660efda",
            "01a11a6af7254c8684d7fb75056a3df6",
            "7ccddde8a34941f890b2f8a14abbbd9a",
            "fb73f8dd28b745f2aaecd678e1e918ad",
            "e8907f5e76404386b0aecaf0cb2a05a7",
            "91c8a2cb92704c97ac1af4b4c2f6cf84",
            "0f9768e487ca49b3a6987fc179bb1bc2",
            "759e2c70eb6246c1b8446310f58cb733"
          ]
        },
        "id": "SV33Uvd7VYXJ",
        "outputId": "fe2df53d-6088-424c-fad1-7b281b96f553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/742k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7bbf41ebfd245dcbbaa47cfae1e325a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ff04f56385c4df6856f92080f45145a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "print(Xids_train.shape, Xids_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt_zTUp0SKST",
        "outputId": "2cb05275-0519-4193-a83d-79cd946f83d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4YypbKsbUSQ"
      },
      "source": [
        "Create y labels in transformer format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FESnc0UIbUSQ"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(threshold=np.inf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFYtD7rybUSQ"
      },
      "outputs": [],
      "source": [
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-FgpLfmjtZW",
        "outputId": "45ac7d34-b4f6-40e6-87bb-4cdc0bd2094c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10832"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7xk5236bUSR"
      },
      "outputs": [],
      "source": [
        "def map_func(input_ids, masks, labels):\n",
        "  return {'input_ids': input_ids, 'attention_mask':masks}, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXygicJBbUSR"
      },
      "outputs": [],
      "source": [
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cce947a-bbe9-43d9-c1d9-ade23ed45bf1",
        "id": "jqWHoZJebUSR"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "677"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "DS_LEN = len(list(dataset_train))\n",
        "DS_LEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVuShbZzbUSS"
      },
      "source": [
        "339 because 10800/32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c57f1bf-4365-4e83-c6d1-906b74c3c4b6",
        "id": "cg9c-e5jbUSS"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "609"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "SPLIT = 0.9\n",
        "round(DS_LEN*SPLIT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(split0['X_train'])-int(len(split0['X_train'])*0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-e9iZTaasAJ",
        "outputId": "1b7b407d-f2f7-4f03-c950-b5c023f3ca6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1084"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1VgA6bIbUSS"
      },
      "outputs": [],
      "source": [
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))#remainer is for val."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "id": "1GzPKw9sXgOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77foZE_rZc9E"
      },
      "outputs": [],
      "source": [
        "def map_func_only_X(val_dictionary, labels):\n",
        "  return {'input_ids': val_dictionary['input_ids'], 'attention_mask':val_dictionary['attention_mask']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n1WkoHFZc9H"
      },
      "outputs": [],
      "source": [
        "def map_func_only_y(val_dictionary, labels):\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE=1084"
      ],
      "metadata": {
        "id": "Q-VGMZy5bRfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5caf320-da12-4d53-e72e-cda454d031f1",
        "id": "wZDVrP0QYC_n"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10832"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "counter = Counter(split0['y_train'])\n",
        "SUM=0\n",
        "for item in list(counter.values()) :\n",
        "  SUM+=item\n",
        "#SUM = sum(counter.values())\n",
        "SUM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tutorial\n",
        "#weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "#weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "\n",
        "counter = Counter(split0['y_train'])\n",
        "my_weight2 = {}\n",
        "print(counter)\n",
        "\n",
        "for genre in counter:\n",
        "  #print(genre, counter[genre])\n",
        "  my_weight2[genre] = (1/counter[genre]) * (SUM/10)\n",
        "my_weight2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbDe9DVFAvjP",
        "outputId": "22fa6021-b176-46de-bb91-e44c885f9c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({4: 4143, 7: 1159, 9: 1030, 3: 865, 6: 783, 0: 763, 1: 690, 8: 556, 2: 537, 5: 306})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 0.2614530533429882,\n",
              " 9: 1.051650485436893,\n",
              " 6: 1.383397190293742,\n",
              " 2: 2.0171322160148977,\n",
              " 0: 1.4196592398427261,\n",
              " 7: 0.9345987920621226,\n",
              " 1: 1.569855072463768,\n",
              " 5: 3.539869281045752,\n",
              " 8: 1.948201438848921,\n",
              " 3: 1.2522543352601156}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE = split0[\"y_test\"].shape[0]\n",
        "TEST_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js6dH6oJAE25",
        "outputId": "48b453cd-cfe8-4123-a72d-48539ca0a7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2708"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oylD4vpEYC_m"
      },
      "source": [
        "### Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6c35bf-4117-450c-ee04-36aafb9f83cc",
        "id": "FSUwCq41YC_n"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4143"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "MAX = max(counter.values())\n",
        "MAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f05a11-a401-495b-ffe4-08e5d23df979",
        "id": "W43besBMYC_o"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5.4298820445609435,\n",
              " 1: 6.004347826086956,\n",
              " 2: 7.715083798882682,\n",
              " 3: 4.789595375722543,\n",
              " 4: 1.0,\n",
              " 5: 13.53921568627451,\n",
              " 6: 5.291187739463601,\n",
              " 7: 3.5746333045729077,\n",
              " 8: 7.451438848920863,\n",
              " 9: 4.022330097087378}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "my_weight={}\n",
        "\n",
        "for genre in range(10):\n",
        "  my_weight[genre]=MAX/counter[genre]\n",
        "#sum(weight)\n",
        "my_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850,
          "referenced_widgets": [
            "662d0f403d1e4dfeb6fc29be94f50198",
            "8f0af31782e5435581e80666c77478bd",
            "53abe4f95cf345869a3b6f44f96b1520",
            "6556acea07544f8c8f414265f2d87511",
            "69713da665c64ba8b168483309af40e8",
            "9d139056dee4493abaa1e2757840091b",
            "0803723664024e8b8e036b3886110483",
            "4c4aaf7d3d784d08973922bb7f50bf07",
            "b7d2fb18cb0748a69be07610ec5be7d3",
            "ecc37a448c8c48c1a5910f19a3c06730",
            "1acbc29d6f914422883ae875cad5fef5"
          ]
        },
        "outputId": "895c8af8-9ed8-4c04-dbaf-4d864ea941b9",
        "id": "3F3ZnDSzZc8_"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "662d0f403d1e4dfeb6fc29be94f50198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 512,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,416,234\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 108,311,808\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModel\n",
        "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN,), name='attention_mask')\n",
        "\n",
        "embeddings = bert(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(0.1)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model.layers[2].trainable = False\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeprUFLfZc9B"
      },
      "source": [
        "BERT is huge, so here we don't fine tune BERT. Simply use pre-trained base BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azlG0LBWZc9C"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model.compile(optimizer=optimizer, loss= loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lphE0vKbZc9C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c926cad6-0580-49eb-e154-c7e7e3fd7600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "339 305 34 85\n"
          ]
        }
      ],
      "source": [
        "print(DS_LEN, len(train), len(val), len(test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBQRA55rZc9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1958d5-7c26-4922-addc-4ddd05bd8f35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1088"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "VAL_SIZE = len(val)*32\n",
        "VAL_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8RRutv3Zc9E"
      },
      "outputs": [],
      "source": [
        "#print(len(val.take(len(val))))\n",
        "for item, label_batch in val.take(1):#len(val)\n",
        "  print(item['input_ids'])\n",
        "  #one_batch= item[0]['input_ids']\n",
        "  #for xids in one_batch:\n",
        "  #  print(xids.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f984a0cb-27f7-416e-8978-530eb9c0ed54",
        "id": "Pv5OpZRWZc9E"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        }
      ],
      "source": [
        "val_X = val.map(map_func_only_X)\n",
        "print(len(val_X))\n",
        "#for i in val_X.take(1):\n",
        "  #print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcQkXXWUZc9H"
      },
      "outputs": [],
      "source": [
        "val_y = val.map(map_func_only_y)\n",
        "print(len(val_y))\n",
        "y_category=np.zeros((VAL_SIZE, ))\n",
        "counter=0\n",
        "for label_tensor in val_y.take(1):\n",
        "  #print(label_tensor)\n",
        "  y_val = np.argmax(label_tensor, axis=1)\n",
        "  for label in y_val:\n",
        "    print(label) \n",
        "    y_category[counter]=label\n",
        "    counter+=1\n",
        "print('counter:',counter)\n",
        "print(y_category)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE=1072\n",
        "VAL_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlboX0e9aOOU",
        "outputId": "dd0ddbd7-a925-45a8-971e-d176463d010b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1072"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE=len(split0['X_train'])-int(len(split0['X_train'])*0.9)\n",
        "VAL_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TkIIrbvbGlZ",
        "outputId": "01b11abc-52ed-47d3-da2c-8b1cf82b91c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1084"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_y = val2.map(map_func_only_y)\n",
        "print(len(val_y))\n",
        "y_category=np.zeros((VAL_SIZE, ))\n",
        "counter=0\n",
        "for label_tensor in val_y.take(len(val2)):\n",
        "  #print(label_tensor)\n",
        "  y_val = np.argmax(label_tensor, axis=1)\n",
        "  for label in y_val:\n",
        "    print(label) \n",
        "    y_category[counter]=label\n",
        "    counter+=1\n",
        "print('counter:',counter)\n",
        "print(y_category)"
      ],
      "metadata": {
        "id": "ZbaDLzG0Z9rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch0PrqHiZc9I"
      },
      "source": [
        "Ref1: how to calculate genre as int instead of one hot vector from list of one hot vectors.\n",
        "https://www.sharpsightlabs.com/blog/numpy-argmax/\n",
        "\n",
        "Ref2: How to use self-programmed metrics: https://stackoverflow.com/questions/37657260/how-to-implement-custom-metric-in-keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MFJlAaBZc9I"
      },
      "outputs": [],
      "source": [
        "VAL_SIZE=1072"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuQBamEdZc9I"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self._data = []\n",
        "        self.validation_data = val2\n",
        "\n",
        "    def map_func_only_X(val_dictionary, labels):\n",
        "      return {'input_ids': val_dictionary['input_ids'], 'attention_mask':val_dictionary['attention_mask']}\n",
        "    def map_func_only_y(val_dictionary, labels):\n",
        "      return labels\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "      #Xid_list= np.zeros((VAL_SIZE, SEQ_LEN))\n",
        "      #y_onehot_list= np.zeros((VAL_SIZE, 10))\n",
        "      #counter=0\n",
        "      #for item in dataset.take(len(self.validation_data)):\n",
        "      #for item in val.take(len(val)):\n",
        "      \"\"\"\n",
        "      for item, batch_label in self.validation_data.take(len(val)):\n",
        "        for label in batch_label:\n",
        "          y_onehot_list[counter,:] = label\n",
        "          counter+=1\n",
        "        one_batch_xid = item['input_ids']\n",
        "        for xids in one_batch_xid:\n",
        "          Xid_list[counter, :] = xids\n",
        "        \n",
        "        #X_val, y_val = self.validation_data[0], self.validation_data[1]\n",
        "      \"\"\"\n",
        "      val_y = self.validation_data.map(map_func_only_y)\n",
        "      y_category=np.zeros((VAL_SIZE, ))\n",
        "      counter=0\n",
        "      for label_tensor in val_y.take(len(val_y)):\n",
        "        y_val = np.argmax(label_tensor, axis=1)\n",
        "        for label in y_val:\n",
        "          y_category[counter]=label\n",
        "          counter+=1\n",
        "      X_val, y_val =self.validation_data.map(map_func_only_X), y_category\n",
        "      y_predict = np.asarray(model2.predict(X_val))\n",
        "\n",
        "      #y_val = np.argmax(y_val, axis=1)#I have already done converting to category\n",
        "      y_predict = np.argmax(y_predict, axis=1)\n",
        "\n",
        "      self._data.append({\n",
        "          'balanced_accuracy': balanced_accuracy_score(y_val, y_predict),\n",
        "          #'val_rocauc': roc_auc_score(y_val, y_predict),\n",
        "      })\n",
        "      return\n",
        "\n",
        "    def get_data(self):\n",
        "        return self._data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer learning: try early stopping with SEQ_LEN=512"
      ],
      "metadata": {
        "id": "wr-sII815ZQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "\n",
        "metrics = Metrics()\n",
        "history = model.fit(train, validation_data=val, epochs=10, class_weight=my_weight ,callbacks=[metrics, early_stopping])\n",
        "metrics.get_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3xJUqUP5bhP",
        "outputId": "2ea8e267-26ee-467b-fd5f-05b16db30f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "305/305 [==============================] - 165s 541ms/step - loss: 7.4384 - categorical_accuracy: 0.2784 - val_loss: 2.1002 - val_categorical_accuracy: 0.2118\n",
            "Epoch 2/10\n",
            "305/305 [==============================] - 165s 541ms/step - loss: 7.0577 - categorical_accuracy: 0.3053 - val_loss: 2.0583 - val_categorical_accuracy: 0.2435\n",
            "Epoch 3/10\n",
            "305/305 [==============================] - 165s 542ms/step - loss: 6.7958 - categorical_accuracy: 0.3207 - val_loss: 1.9879 - val_categorical_accuracy: 0.2677\n",
            "Epoch 4/10\n",
            "305/305 [==============================] - 165s 542ms/step - loss: 6.5908 - categorical_accuracy: 0.3376 - val_loss: 2.0138 - val_categorical_accuracy: 0.2388\n",
            "Epoch 5/10\n",
            "305/305 [==============================] - 165s 542ms/step - loss: 6.4173 - categorical_accuracy: 0.3493 - val_loss: 2.0363 - val_categorical_accuracy: 0.2472\n",
            "Epoch 6/10\n",
            "305/305 [==============================] - 165s 542ms/step - loss: 6.2501 - categorical_accuracy: 0.3629 - val_loss: 2.0147 - val_categorical_accuracy: 0.2509\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'balanced_accuracy': 0.10064757124688836},\n",
              " {'balanced_accuracy': 0.1187677795399048},\n",
              " {'balanced_accuracy': 0.09990412917019217},\n",
              " {'balanced_accuracy': 0.08602748843296298},\n",
              " {'balanced_accuracy': 0.12293896335258817},\n",
              " {'balanced_accuracy': 0.08466265273217208}]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "test_y = test.map(map_func_only_y)\n",
        "y_category=np.zeros((TEST_SIZE, ))\n",
        "counter=0\n",
        "for label_tensor in test_y.take(len(test_y)):\n",
        "  y_test = np.argmax(label_tensor, axis=1)\n",
        "  for label in y_test:\n",
        "    y_category[counter]=label\n",
        "    counter+=1\n",
        "\n",
        "X_test, y_test = test.map(map_func_only_X), y_category\n",
        "y_predict_test = np.asarray(model.predict(X_test))\n",
        "y_predict_test = np.argmax(y_predict_test, axis=1)\n",
        "print(classification_report(y_test, y_predict_test) )\n",
        "print(balanced_accuracy_score(y_test, y_predict_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu5dCLm6noXw",
        "outputId": "a7b5a378-91e9-475d-b302-3c51cd515635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.42      0.21       190\n",
            "         1.0       0.16      0.28      0.20       173\n",
            "         2.0       0.10      0.14      0.12       135\n",
            "         3.0       0.13      0.17      0.15       216\n",
            "         4.0       0.74      0.19      0.31      1036\n",
            "         5.0       0.12      0.38      0.18        76\n",
            "         6.0       0.77      0.77      0.77       195\n",
            "         7.0       0.11      0.08      0.10       290\n",
            "         8.0       0.09      0.09      0.09       139\n",
            "         9.0       0.24      0.28      0.26       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.26      0.28      0.24      2708\n",
            "weighted avg       0.42      0.25      0.26      2708\n",
            "\n",
            "0.2825509565558356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning -> Fine tunine: unfreeze middle layers and train with smaller learning rate. using ALBERT base"
      ],
      "metadata": {
        "id": "L23dKb22nfQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter tuning"
      ],
      "metadata": {
        "id": "BOP8waA-flXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN2=256"
      ],
      "metadata": {
        "id": "0NyVM7_KZjox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "albert_base = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "\n",
        "drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "for drop_out_rate in drop_out_rates:\n",
        "  #step1\n",
        "  input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "  mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "  embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "  X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "  X = tf.keras.layers.BatchNormalization()(X)\n",
        "  X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "  X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "  X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "  y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "  model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "  model2.layers[2].trainable = False\n",
        "  #model2.summary()\n",
        "\n",
        "  #step2\n",
        "  optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "  metrics = []\n",
        "  metrics.append(\n",
        "      tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "  model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "  #model2.summary() #Check trainable params increased.\n",
        "\n",
        "  #step3: transfer learning\n",
        "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "  history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "  #step4: predict\n",
        "  balanced_acc=get_balanced_accuracy(model2)\n",
        "  balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "  #step5: fine tune\n",
        "  model2.layers[2].trainable = True\n",
        "\n",
        "  # It's important to recompile your model after you make any changes\n",
        "  optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "  loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "  metrics = []\n",
        "  metrics.append(\n",
        "      tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "  model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "  history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "  balanced_acc=get_balanced_accuracy(model2)\n",
        "  balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "  del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxbPCm_hU9iZ",
        "outputId": "6704ea91-703f-4908-b448-f70036247756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "609/609 [==============================] - 247s 369ms/step - loss: 2.0898 - categorical_accuracy: 0.2449 - val_loss: 1.9160 - val_categorical_accuracy: 0.2895\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 220s 361ms/step - loss: 1.6881 - categorical_accuracy: 0.3587 - val_loss: 1.8891 - val_categorical_accuracy: 0.3015\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 1.4174 - categorical_accuracy: 0.4352 - val_loss: 1.8973 - val_categorical_accuracy: 0.3153\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 1.1821 - categorical_accuracy: 0.4992 - val_loss: 2.0300 - val_categorical_accuracy: 0.2923\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 0.9610 - categorical_accuracy: 0.5565 - val_loss: 2.1120 - val_categorical_accuracy: 0.2996\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 0.8037 - categorical_accuracy: 0.6061 - val_loss: 2.1925 - val_categorical_accuracy: 0.3189\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.15      0.14       190\n",
            "         1.0       0.15      0.19      0.17       173\n",
            "         2.0       0.09      0.13      0.11       135\n",
            "         3.0       0.19      0.15      0.17       216\n",
            "         4.0       0.66      0.36      0.46      1036\n",
            "         5.0       0.20      0.25      0.22        76\n",
            "         6.0       0.68      0.72      0.70       195\n",
            "         7.0       0.16      0.19      0.17       290\n",
            "         8.0       0.10      0.22      0.14       139\n",
            "         9.0       0.23      0.35      0.28       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.26      0.27      0.26      2708\n",
            "weighted avg       0.39      0.30      0.33      2708\n",
            "\n",
            "0.2714461328340759\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 570s 892ms/step - loss: 2.0808 - categorical_accuracy: 0.3358 - val_loss: 2.3407 - val_categorical_accuracy: 0.2739\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 539s 884ms/step - loss: 2.2728 - categorical_accuracy: 0.2945 - val_loss: 2.5517 - val_categorical_accuracy: 0.3079\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 539s 885ms/step - loss: 2.0363 - categorical_accuracy: 0.3161 - val_loss: 2.5536 - val_categorical_accuracy: 0.2390\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 538s 884ms/step - loss: 1.7753 - categorical_accuracy: 0.3454 - val_loss: 2.4465 - val_categorical_accuracy: 0.2417\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 538s 884ms/step - loss: 1.5539 - categorical_accuracy: 0.3792 - val_loss: 2.3367 - val_categorical_accuracy: 0.2665\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.13      0.14       190\n",
            "         1.0       0.15      0.38      0.21       173\n",
            "         2.0       0.07      0.07      0.07       135\n",
            "         3.0       0.19      0.13      0.15       216\n",
            "         4.0       0.66      0.24      0.35      1036\n",
            "         5.0       0.15      0.30      0.20        76\n",
            "         6.0       0.64      0.77      0.70       195\n",
            "         7.0       0.14      0.12      0.13       290\n",
            "         8.0       0.09      0.18      0.12       139\n",
            "         9.0       0.20      0.40      0.26       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.24      0.27      0.23      2708\n",
            "weighted avg       0.38      0.26      0.28      2708\n",
            "\n",
            "0.27205025845354136\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 369ms/step - loss: 2.0334 - categorical_accuracy: 0.2658 - val_loss: 1.9282 - val_categorical_accuracy: 0.2969\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 220s 361ms/step - loss: 1.6390 - categorical_accuracy: 0.3753 - val_loss: 1.8546 - val_categorical_accuracy: 0.3346\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 220s 361ms/step - loss: 1.4180 - categorical_accuracy: 0.4187 - val_loss: 1.9456 - val_categorical_accuracy: 0.3051\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 1.2274 - categorical_accuracy: 0.4794 - val_loss: 1.9445 - val_categorical_accuracy: 0.3263\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 219s 360ms/step - loss: 1.0814 - categorical_accuracy: 0.5196 - val_loss: 2.0249 - val_categorical_accuracy: 0.3300\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.27      0.23       190\n",
            "         1.0       0.15      0.23      0.18       173\n",
            "         2.0       0.18      0.12      0.14       135\n",
            "         3.0       0.19      0.25      0.21       216\n",
            "         4.0       0.66      0.36      0.47      1036\n",
            "         5.0       0.21      0.14      0.17        76\n",
            "         6.0       0.70      0.77      0.73       195\n",
            "         7.0       0.15      0.13      0.14       290\n",
            "         8.0       0.09      0.17      0.12       139\n",
            "         9.0       0.23      0.40      0.29       258\n",
            "\n",
            "    accuracy                           0.32      2708\n",
            "   macro avg       0.27      0.28      0.27      2708\n",
            "weighted avg       0.40      0.32      0.34      2708\n",
            "\n",
            "0.2846293000154242\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 571s 891ms/step - loss: 2.3535 - categorical_accuracy: 0.2771 - val_loss: 4.3616 - val_categorical_accuracy: 0.0772\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.9284 - categorical_accuracy: 0.3013 - val_loss: 3.9277 - val_categorical_accuracy: 0.0993\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.8030 - categorical_accuracy: 0.3387 - val_loss: 3.6848 - val_categorical_accuracy: 0.1756\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 883ms/step - loss: 1.7356 - categorical_accuracy: 0.3471 - val_loss: 2.4950 - val_categorical_accuracy: 0.2886\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 1.9671 - categorical_accuracy: 0.3207 - val_loss: 5.9806 - val_categorical_accuracy: 0.0551\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 535s 879ms/step - loss: 2.1460 - categorical_accuracy: 0.2602 - val_loss: 7.0500 - val_categorical_accuracy: 0.0561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.01      0.01      0.01       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.03      0.64      0.05        76\n",
            "         6.0       0.00      0.00      0.00       195\n",
            "         7.0       0.11      0.25      0.15       290\n",
            "         8.0       0.03      0.02      0.02       139\n",
            "         9.0       0.00      0.00      0.00       258\n",
            "\n",
            "    accuracy                           0.05      2708\n",
            "   macro avg       0.02      0.09      0.02      2708\n",
            "weighted avg       0.01      0.05      0.02      2708\n",
            "\n",
            "0.09203757848079876\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 368ms/step - loss: 2.1277 - categorical_accuracy: 0.2306 - val_loss: 2.0056 - val_categorical_accuracy: 0.2500\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 2.0269 - categorical_accuracy: 0.2410 - val_loss: 1.9747 - val_categorical_accuracy: 0.2702\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 2.0083 - categorical_accuracy: 0.2414 - val_loss: 1.9780 - val_categorical_accuracy: 0.2684\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 2.0033 - categorical_accuracy: 0.2453 - val_loss: 1.9714 - val_categorical_accuracy: 0.2840\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.9938 - categorical_accuracy: 0.2513 - val_loss: 1.9551 - val_categorical_accuracy: 0.3373\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.9878 - categorical_accuracy: 0.2597 - val_loss: 1.9587 - val_categorical_accuracy: 0.3281\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.07      0.09       190\n",
            "         1.0       0.10      0.12      0.11       173\n",
            "         2.0       0.33      0.01      0.01       135\n",
            "         3.0       0.13      0.20      0.16       216\n",
            "         4.0       0.58      0.58      0.58      1036\n",
            "         5.0       0.07      0.34      0.11        76\n",
            "         6.0       0.54      0.86      0.66       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.07      0.10      0.08       139\n",
            "         9.0       0.25      0.12      0.17       258\n",
            "\n",
            "    accuracy                           0.34      2708\n",
            "   macro avg       0.22      0.24      0.20      2708\n",
            "weighted avg       0.34      0.34      0.32      2708\n",
            "\n",
            "0.24044978540726597\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 568s 892ms/step - loss: 2.0029 - categorical_accuracy: 0.3153 - val_loss: 5.8892 - val_categorical_accuracy: 0.1452\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 880ms/step - loss: 1.8961 - categorical_accuracy: 0.3041 - val_loss: 2.9597 - val_categorical_accuracy: 0.2472\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.8184 - categorical_accuracy: 0.3083 - val_loss: 2.1188 - val_categorical_accuracy: 0.2629\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.7148 - categorical_accuracy: 0.2889 - val_loss: 4.4864 - val_categorical_accuracy: 0.1011\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.6261 - categorical_accuracy: 0.2948 - val_loss: 2.2003 - val_categorical_accuracy: 0.2077\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.5460 - categorical_accuracy: 0.2943 - val_loss: 1.9049 - val_categorical_accuracy: 0.2546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.43      0.20       190\n",
            "         1.0       0.15      0.08      0.10       173\n",
            "         2.0       0.06      0.13      0.08       135\n",
            "         3.0       0.16      0.19      0.18       216\n",
            "         4.0       0.48      0.15      0.22      1036\n",
            "         5.0       0.23      0.24      0.23        76\n",
            "         6.0       0.84      0.72      0.78       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.19      0.65      0.29       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.22      0.26      0.21      2708\n",
            "weighted avg       0.30      0.23      0.21      2708\n",
            "\n",
            "0.2580569761133787\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 367ms/step - loss: 1.6436 - categorical_accuracy: 0.3229 - val_loss: 1.9396 - val_categorical_accuracy: 0.2785\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.4531 - categorical_accuracy: 0.3365 - val_loss: 2.0896 - val_categorical_accuracy: 0.2472\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.4436 - categorical_accuracy: 0.3503 - val_loss: 2.1367 - val_categorical_accuracy: 0.2721\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.4119 - categorical_accuracy: 0.3599 - val_loss: 2.0536 - val_categorical_accuracy: 0.2619\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.23      0.15      0.18       190\n",
            "         1.0       0.16      0.18      0.17       173\n",
            "         2.0       0.06      0.22      0.09       135\n",
            "         3.0       0.16      0.25      0.20       216\n",
            "         4.0       0.55      0.17      0.26      1036\n",
            "         5.0       0.42      0.07      0.11        76\n",
            "         6.0       0.81      0.74      0.77       195\n",
            "         7.0       0.21      0.02      0.04       290\n",
            "         8.0       0.10      0.25      0.15       139\n",
            "         9.0       0.19      0.51      0.28       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.29      0.26      0.23      2708\n",
            "weighted avg       0.37      0.24      0.24      2708\n",
            "\n",
            "0.2560964586279497\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 571s 891ms/step - loss: 1.4192 - categorical_accuracy: 0.3681 - val_loss: 2.9397 - val_categorical_accuracy: 0.2822\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.3136 - categorical_accuracy: 0.3799 - val_loss: 4.1014 - val_categorical_accuracy: 0.1756\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.2501 - categorical_accuracy: 0.3862 - val_loss: 3.1378 - val_categorical_accuracy: 0.1866\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.1917 - categorical_accuracy: 0.4078 - val_loss: 3.2733 - val_categorical_accuracy: 0.2197\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.73      0.18       190\n",
            "         1.0       0.17      0.06      0.09       173\n",
            "         2.0       0.05      0.13      0.07       135\n",
            "         3.0       0.16      0.07      0.10       216\n",
            "         4.0       0.61      0.12      0.21      1036\n",
            "         5.0       0.45      0.07      0.11        76\n",
            "         6.0       0.80      0.74      0.77       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.05      0.01      0.02       139\n",
            "         9.0       0.21      0.33      0.25       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.26      0.23      0.18      2708\n",
            "weighted avg       0.36      0.20      0.19      2708\n",
            "\n",
            "0.227055276787063\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 367ms/step - loss: 1.4062 - categorical_accuracy: 0.4185 - val_loss: 2.2085 - val_categorical_accuracy: 0.2886\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.1824 - categorical_accuracy: 0.4264 - val_loss: 2.3885 - val_categorical_accuracy: 0.2803\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.1450 - categorical_accuracy: 0.4421 - val_loss: 2.4581 - val_categorical_accuracy: 0.2858\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.1096 - categorical_accuracy: 0.4474 - val_loss: 2.4476 - val_categorical_accuracy: 0.2840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.07      0.11       190\n",
            "         1.0       0.15      0.07      0.10       173\n",
            "         2.0       0.04      0.14      0.06       135\n",
            "         3.0       0.20      0.16      0.18       216\n",
            "         4.0       0.61      0.21      0.31      1036\n",
            "         5.0       0.71      0.07      0.12        76\n",
            "         6.0       0.80      0.77      0.79       195\n",
            "         7.0       0.14      0.19      0.16       290\n",
            "         8.0       0.11      0.32      0.16       139\n",
            "         9.0       0.21      0.41      0.27       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.32      0.24      0.23      2708\n",
            "weighted avg       0.39      0.24      0.26      2708\n",
            "\n",
            "0.24175213805787257\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 567s 889ms/step - loss: 1.3344 - categorical_accuracy: 0.4152 - val_loss: 2.0446 - val_categorical_accuracy: 0.2748\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 1.2897 - categorical_accuracy: 0.4080 - val_loss: 2.5091 - val_categorical_accuracy: 0.2592\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 1.1043 - categorical_accuracy: 0.4618 - val_loss: 1.9240 - val_categorical_accuracy: 0.2702\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 1.0043 - categorical_accuracy: 0.4783 - val_loss: 2.7361 - val_categorical_accuracy: 0.2537\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.15      0.18       190\n",
            "         1.0       0.17      0.12      0.14       173\n",
            "         2.0       0.05      0.18      0.08       135\n",
            "         3.0       0.22      0.14      0.17       216\n",
            "         4.0       0.52      0.15      0.24      1036\n",
            "         5.0       0.40      0.11      0.17        76\n",
            "         6.0       0.83      0.70      0.76       195\n",
            "         7.0       0.13      0.13      0.13       290\n",
            "         8.0       0.10      0.20      0.14       139\n",
            "         9.0       0.20      0.57      0.29       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.28      0.25      0.23      2708\n",
            "weighted avg       0.35      0.23      0.24      2708\n",
            "\n",
            "0.24536153069686137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_transfer_learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673nstNCNBBZ",
        "outputId": "007dac37-8233-4786-b43b-cb34e8eb93c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2714461328340759,\n",
              " 0.2846293000154242,\n",
              " 0.24044978540726597,\n",
              " 0.2560964586279497,\n",
              " 0.24175213805787257]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdNc02xLM7j9",
        "outputId": "fba51e39-b5d8-4b1e-d9a3-3f2ff6793744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27205025845354136,\n",
              " 0.09203757848079876,\n",
              " 0.2580569761133787,\n",
              " 0.227055276787063,\n",
              " 0.24536153069686137]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameters = []\n",
        "drop_out_rates=[0.1,0.2,0.3,0.4,0.5]\n",
        "for dropout in drop_out_rates:\n",
        "  seen_parameters.append((1e-3, 1e-5, dropout))\n",
        "seen_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fho5_oVm5yhj",
        "outputId": "417d1b7f-ff7f-4d27-fd0b-361b7619dc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.001, 1e-05, 0.1),\n",
              " (0.001, 1e-05, 0.2),\n",
              " (0.001, 1e-05, 0.3),\n",
              " (0.001, 1e-05, 0.4),\n",
              " (0.001, 1e-05, 0.5)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.1]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "id": "HKOGrCtH5tl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.2]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUTlIsmH7QDl",
        "outputId": "cb22a7b8-2b53-408f-edf7-51a75945fbd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 366ms/step - loss: 0.9767 - categorical_accuracy: 0.5497 - val_loss: 3.1171 - val_categorical_accuracy: 0.2730\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.8618 - categorical_accuracy: 0.5754 - val_loss: 2.8146 - val_categorical_accuracy: 0.2941\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.8139 - categorical_accuracy: 0.5956 - val_loss: 2.7685 - val_categorical_accuracy: 0.3079\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.8014 - categorical_accuracy: 0.5962 - val_loss: 2.9234 - val_categorical_accuracy: 0.2950\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.7832 - categorical_accuracy: 0.5935 - val_loss: 2.9021 - val_categorical_accuracy: 0.3033\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.7746 - categorical_accuracy: 0.5939 - val_loss: 3.0508 - val_categorical_accuracy: 0.2886\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.26      0.11      0.15       190\n",
            "         1.0       0.14      0.06      0.09       173\n",
            "         2.0       0.06      0.13      0.09       135\n",
            "         3.0       0.21      0.19      0.20       216\n",
            "         4.0       0.56      0.30      0.39      1036\n",
            "         5.0       0.40      0.11      0.17        76\n",
            "         6.0       0.84      0.69      0.76       195\n",
            "         7.0       0.13      0.26      0.18       290\n",
            "         8.0       0.09      0.23      0.13       139\n",
            "         9.0       0.21      0.34      0.26       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.29      0.24      0.24      2708\n",
            "weighted avg       0.37      0.27      0.29      2708\n",
            "\n",
            "0.24114452614265702\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 570s 890ms/step - loss: 0.7486 - categorical_accuracy: 0.6236 - val_loss: 3.1019 - val_categorical_accuracy: 0.2996\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.6095 - categorical_accuracy: 0.6602 - val_loss: 3.2936 - val_categorical_accuracy: 0.2932\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.5196 - categorical_accuracy: 0.6862 - val_loss: 3.3856 - val_categorical_accuracy: 0.3033\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.4613 - categorical_accuracy: 0.7094 - val_loss: 3.5947 - val_categorical_accuracy: 0.2996\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.4068 - categorical_accuracy: 0.7328 - val_loss: 3.7525 - val_categorical_accuracy: 0.3051\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.3547 - categorical_accuracy: 0.7519 - val_loss: 3.9182 - val_categorical_accuracy: 0.3024\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.23      0.11      0.15       190\n",
            "         1.0       0.17      0.09      0.12       173\n",
            "         2.0       0.06      0.16      0.09       135\n",
            "         3.0       0.20      0.27      0.23       216\n",
            "         4.0       0.56      0.29      0.38      1036\n",
            "         5.0       0.50      0.09      0.16        76\n",
            "         6.0       0.82      0.74      0.78       195\n",
            "         7.0       0.15      0.23      0.18       290\n",
            "         8.0       0.11      0.23      0.15       139\n",
            "         9.0       0.22      0.38      0.28       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.30      0.26      0.25      2708\n",
            "weighted avg       0.38      0.28      0.30      2708\n",
            "\n",
            "0.2591786542521592\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 366ms/step - loss: 0.5864 - categorical_accuracy: 0.7268 - val_loss: 3.1348 - val_categorical_accuracy: 0.3428\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.3287 - categorical_accuracy: 0.7911 - val_loss: 3.3260 - val_categorical_accuracy: 0.3318\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.3042 - categorical_accuracy: 0.7972 - val_loss: 3.4778 - val_categorical_accuracy: 0.3401\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2960 - categorical_accuracy: 0.7960 - val_loss: 3.5928 - val_categorical_accuracy: 0.3346\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.23      0.10      0.14       190\n",
            "         1.0       0.18      0.09      0.12       173\n",
            "         2.0       0.08      0.12      0.10       135\n",
            "         3.0       0.19      0.13      0.16       216\n",
            "         4.0       0.55      0.44      0.49      1036\n",
            "         5.0       0.54      0.09      0.16        76\n",
            "         6.0       0.81      0.74      0.78       195\n",
            "         7.0       0.13      0.22      0.17       290\n",
            "         8.0       0.11      0.30      0.16       139\n",
            "         9.0       0.22      0.26      0.24       258\n",
            "\n",
            "    accuracy                           0.32      2708\n",
            "   macro avg       0.30      0.25      0.25      2708\n",
            "weighted avg       0.37      0.32      0.33      2708\n",
            "\n",
            "0.2493581581035141\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 568s 889ms/step - loss: 0.6903 - categorical_accuracy: 0.6650 - val_loss: 2.6388 - val_categorical_accuracy: 0.2454\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 880ms/step - loss: 0.8529 - categorical_accuracy: 0.6024 - val_loss: 2.5072 - val_categorical_accuracy: 0.3235\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.6334 - categorical_accuracy: 0.6818 - val_loss: 2.9687 - val_categorical_accuracy: 0.2675\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 536s 880ms/step - loss: 0.6259 - categorical_accuracy: 0.6781 - val_loss: 2.8853 - val_categorical_accuracy: 0.2886\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.6236 - categorical_accuracy: 0.6877 - val_loss: 2.8257 - val_categorical_accuracy: 0.1287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.27      0.13       190\n",
            "         1.0       0.18      0.13      0.15       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.17      0.45      0.25       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.43      0.12      0.19        76\n",
            "         6.0       0.94      0.52      0.67       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.05      0.46      0.09       139\n",
            "         9.0       0.00      0.00      0.00       258\n",
            "\n",
            "    accuracy                           0.13      2708\n",
            "   macro avg       0.18      0.20      0.15      2708\n",
            "weighted avg       0.11      0.13      0.10      2708\n",
            "\n",
            "0.1951356969544379\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 367ms/step - loss: 1.2159 - categorical_accuracy: 0.4541 - val_loss: 2.1646 - val_categorical_accuracy: 0.2638\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.0292 - categorical_accuracy: 0.4957 - val_loss: 2.2515 - val_categorical_accuracy: 0.2537\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.0081 - categorical_accuracy: 0.5090 - val_loss: 2.2440 - val_categorical_accuracy: 0.2684\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.9991 - categorical_accuracy: 0.5054 - val_loss: 2.3017 - val_categorical_accuracy: 0.2482\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 0.9822 - categorical_accuracy: 0.5109 - val_loss: 2.2757 - val_categorical_accuracy: 0.2555\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 0.9708 - categorical_accuracy: 0.5145 - val_loss: 2.2754 - val_categorical_accuracy: 0.2564\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.04      0.06       190\n",
            "         1.0       0.25      0.14      0.18       173\n",
            "         2.0       0.06      0.14      0.09       135\n",
            "         3.0       0.19      0.24      0.21       216\n",
            "         4.0       0.53      0.20      0.29      1036\n",
            "         5.0       0.42      0.11      0.17        76\n",
            "         6.0       0.78      0.71      0.74       195\n",
            "         7.0       0.12      0.21      0.16       290\n",
            "         8.0       0.09      0.23      0.13       139\n",
            "         9.0       0.20      0.45      0.27       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.28      0.25      0.23      2708\n",
            "weighted avg       0.35      0.25      0.26      2708\n",
            "\n",
            "0.24538399803019706\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 569s 893ms/step - loss: 0.7703 - categorical_accuracy: 0.5846 - val_loss: 2.5038 - val_categorical_accuracy: 0.2767\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.5538 - categorical_accuracy: 0.6744 - val_loss: 2.7458 - val_categorical_accuracy: 0.2858\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 0.4523 - categorical_accuracy: 0.7268 - val_loss: 2.7418 - val_categorical_accuracy: 0.2987\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 0.3836 - categorical_accuracy: 0.7657 - val_loss: 2.9142 - val_categorical_accuracy: 0.3015\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 537s 881ms/step - loss: 0.3323 - categorical_accuracy: 0.7907 - val_loss: 2.9112 - val_categorical_accuracy: 0.3153\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 536s 881ms/step - loss: 0.2907 - categorical_accuracy: 0.8165 - val_loss: 3.0451 - val_categorical_accuracy: 0.3254\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.07      0.11       190\n",
            "         1.0       0.15      0.06      0.08       173\n",
            "         2.0       0.07      0.12      0.09       135\n",
            "         3.0       0.20      0.23      0.21       216\n",
            "         4.0       0.58      0.41      0.48      1036\n",
            "         5.0       0.55      0.08      0.14        76\n",
            "         6.0       0.83      0.71      0.76       195\n",
            "         7.0       0.13      0.27      0.18       290\n",
            "         8.0       0.11      0.19      0.14       139\n",
            "         9.0       0.24      0.31      0.27       258\n",
            "\n",
            "    accuracy                           0.31      2708\n",
            "   macro avg       0.31      0.24      0.25      2708\n",
            "weighted avg       0.38      0.31      0.33      2708\n",
            "\n",
            "0.24465893332573913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_transfer_learning[5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cc8b3C-m1Gk",
        "outputId": "e7c9cb69-bb2a-4fc5-f3ee-eecf897ee839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.24114452614265702, 0.2493581581035141, 0.24538399803019706]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning[5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTmbyH72mzri",
        "outputId": "90cc55a3-e5a4-43b6-80f0-1c01ab1a253d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2591786542521592, 0.1951356969544379, 0.24465893332573913]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.3]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_base(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc=get_balanced_accuracy(model2)\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDd6MeYn7R9E",
        "outputId": "467601a2-efd8-4b8f-dce7-b1902fa82c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 366ms/step - loss: 0.3530 - categorical_accuracy: 0.8181 - val_loss: 4.6522 - val_categorical_accuracy: 0.3079\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2819 - categorical_accuracy: 0.8460 - val_loss: 4.7302 - val_categorical_accuracy: 0.3235\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2534 - categorical_accuracy: 0.8581 - val_loss: 5.0115 - val_categorical_accuracy: 0.3502\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2191 - categorical_accuracy: 0.8698 - val_loss: 4.8203 - val_categorical_accuracy: 0.3373\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2138 - categorical_accuracy: 0.8627 - val_loss: 4.8558 - val_categorical_accuracy: 0.3125\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 0.2100 - categorical_accuracy: 0.8683 - val_loss: 4.7053 - val_categorical_accuracy: 0.3281\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.08      0.10       190\n",
            "         1.0       0.17      0.06      0.09       173\n",
            "         2.0       0.06      0.10      0.08       135\n",
            "         3.0       0.19      0.20      0.19       216\n",
            "         4.0       0.56      0.39      0.46      1036\n",
            "         5.0       0.55      0.08      0.14        76\n",
            "         6.0       0.84      0.69      0.76       195\n",
            "         7.0       0.13      0.27      0.18       290\n",
            "         8.0       0.12      0.24      0.16       139\n",
            "         9.0       0.24      0.29      0.26       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.30      0.24      0.24      2708\n",
            "weighted avg       0.37      0.30      0.32      2708\n",
            "\n",
            "0.24068599126812157\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 571s 892ms/step - loss: 0.2203 - categorical_accuracy: 0.8519 - val_loss: 5.0364 - val_categorical_accuracy: 0.3125\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1989 - categorical_accuracy: 0.8660 - val_loss: 5.1490 - val_categorical_accuracy: 0.3254\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1790 - categorical_accuracy: 0.8784 - val_loss: 5.3023 - val_categorical_accuracy: 0.3364\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1582 - categorical_accuracy: 0.8874 - val_loss: 5.3419 - val_categorical_accuracy: 0.3272\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1584 - categorical_accuracy: 0.8960 - val_loss: 5.2012 - val_categorical_accuracy: 0.3566\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 0.1483 - categorical_accuracy: 0.9050 - val_loss: 4.9733 - val_categorical_accuracy: 0.3529\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.10      0.12       190\n",
            "         1.0       0.20      0.06      0.10       173\n",
            "         2.0       0.07      0.09      0.08       135\n",
            "         3.0       0.20      0.17      0.18       216\n",
            "         4.0       0.56      0.47      0.51      1036\n",
            "         5.0       0.55      0.08      0.14        76\n",
            "         6.0       0.83      0.70      0.76       195\n",
            "         7.0       0.14      0.24      0.17       290\n",
            "         8.0       0.11      0.22      0.15       139\n",
            "         9.0       0.23      0.28      0.25       258\n",
            "\n",
            "    accuracy                           0.33      2708\n",
            "   macro avg       0.30      0.24      0.25      2708\n",
            "weighted avg       0.37      0.33      0.34      2708\n",
            "\n",
            "0.24184874191585165\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.3\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 368ms/step - loss: 0.4913 - categorical_accuracy: 0.8213 - val_loss: 3.3338 - val_categorical_accuracy: 0.3557\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1803 - categorical_accuracy: 0.9095 - val_loss: 3.8188 - val_categorical_accuracy: 0.3548\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1569 - categorical_accuracy: 0.9206 - val_loss: 3.9239 - val_categorical_accuracy: 0.3686\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1406 - categorical_accuracy: 0.9256 - val_loss: 4.1161 - val_categorical_accuracy: 0.3667\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1359 - categorical_accuracy: 0.9300 - val_loss: 4.1055 - val_categorical_accuracy: 0.3750\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 0.1337 - categorical_accuracy: 0.9325 - val_loss: 4.2220 - val_categorical_accuracy: 0.3612\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.08      0.09       190\n",
            "         1.0       0.22      0.08      0.11       173\n",
            "         2.0       0.08      0.08      0.08       135\n",
            "         3.0       0.18      0.18      0.18       216\n",
            "         4.0       0.56      0.54      0.55      1036\n",
            "         5.0       0.60      0.08      0.14        76\n",
            "         6.0       0.85      0.70      0.77       195\n",
            "         7.0       0.14      0.22      0.17       290\n",
            "         8.0       0.11      0.24      0.15       139\n",
            "         9.0       0.25      0.21      0.23       258\n",
            "\n",
            "    accuracy                           0.35      2708\n",
            "   macro avg       0.31      0.24      0.25      2708\n",
            "weighted avg       0.38      0.35      0.35      2708\n",
            "\n",
            "0.24152452827204512\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 572s 892ms/step - loss: 0.4364 - categorical_accuracy: 0.7943 - val_loss: 3.5063 - val_categorical_accuracy: 0.3244\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 2.0401 - categorical_accuracy: 0.2666 - val_loss: 2.3408 - val_categorical_accuracy: 0.0947\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.9899 - categorical_accuracy: 0.2219 - val_loss: 2.0768 - val_categorical_accuracy: 0.1985\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 537s 882ms/step - loss: 1.7435 - categorical_accuracy: 0.2836 - val_loss: 2.0746 - val_categorical_accuracy: 0.2206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.15      0.28      0.20       173\n",
            "         2.0       0.05      0.01      0.02       135\n",
            "         3.0       0.11      0.23      0.15       216\n",
            "         4.0       0.39      0.13      0.20      1036\n",
            "         5.0       0.41      0.12      0.18        76\n",
            "         6.0       0.76      0.76      0.76       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.10      0.12      0.11       139\n",
            "         9.0       0.14      0.62      0.23       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.21      0.23      0.19      2708\n",
            "weighted avg       0.26      0.21      0.19      2708\n",
            "\n",
            "0.22925599574452962\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 246s 368ms/step - loss: 1.5823 - categorical_accuracy: 0.2958 - val_loss: 2.1996 - val_categorical_accuracy: 0.1921\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 1.4550 - categorical_accuracy: 0.3300 - val_loss: 2.2422 - val_categorical_accuracy: 0.1958\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 1.4314 - categorical_accuracy: 0.3341 - val_loss: 2.3209 - val_categorical_accuracy: 0.1847\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 219s 359ms/step - loss: 1.4306 - categorical_accuracy: 0.3300 - val_loss: 2.2992 - val_categorical_accuracy: 0.1737\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 359ms/step - loss: 1.4195 - categorical_accuracy: 0.3294 - val_loss: 2.2737 - val_categorical_accuracy: 0.1921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.07      0.10       190\n",
            "         1.0       0.17      0.20      0.18       173\n",
            "         2.0       0.06      0.21      0.10       135\n",
            "         3.0       0.12      0.14      0.13       216\n",
            "         4.0       0.51      0.07      0.12      1036\n",
            "         5.0       0.28      0.12      0.17        76\n",
            "         6.0       0.77      0.75      0.76       195\n",
            "         7.0       0.13      0.09      0.11       290\n",
            "         8.0       0.08      0.30      0.13       139\n",
            "         9.0       0.15      0.34      0.21       258\n",
            "\n",
            "    accuracy                           0.18      2708\n",
            "   macro avg       0.24      0.23      0.20      2708\n",
            "weighted avg       0.32      0.18      0.18      2708\n",
            "\n",
            "0.2303130166302793\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 571s 891ms/step - loss: 1.3501 - categorical_accuracy: 0.3499 - val_loss: 2.3684 - val_categorical_accuracy: 0.1967\n",
            "Epoch 2/6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Resume from the last checkpoint"
      ],
      "metadata": {
        "id": "IbueZKWW6sH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameters.append((1e-3, 1e-6, 0.3))\n",
        "seen_parameters.append((1e-4, 1e-5, 0.3))\n",
        "seen_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIekcZL46rjk",
        "outputId": "fe30704a-fb2a-4067-d11b-5bba9e85b706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.001, 1e-05, 0.1),\n",
              " (0.001, 1e-05, 0.2),\n",
              " (0.001, 1e-05, 0.3),\n",
              " (0.001, 1e-05, 0.4),\n",
              " (0.001, 1e-05, 0.5),\n",
              " (0.001, 1e-06, 0.3),\n",
              " (0.0001, 1e-05, 0.3)]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameters.remove((0.0001, 1e-06, 0.3))\n",
        "seen_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teTQtELP8TG3",
        "outputId": "535216c5-a65c-44bd-cd61-e5110b98f620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.001, 1e-05, 0.1),\n",
              " (0.001, 1e-05, 0.2),\n",
              " (0.001, 1e-05, 0.3),\n",
              " (0.001, 1e-05, 0.4),\n",
              " (0.001, 1e-05, 0.5),\n",
              " (0.001, 1e-06, 0.3),\n",
              " (0.0001, 1e-05, 0.3)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar = {}\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []"
      ],
      "metadata": {
        "id": "3HsY4Csi7U77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.3]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu4WBwkB7H0_",
        "outputId": "797094b6-69f4-4eba-e4a4-111f762879ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 418s 648ms/step - loss: 2.3861 - categorical_accuracy: 0.1485 - val_loss: 2.1801 - val_categorical_accuracy: 0.1912\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 390s 640ms/step - loss: 2.1133 - categorical_accuracy: 0.2192 - val_loss: 2.0884 - val_categorical_accuracy: 0.2270\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.9941 - categorical_accuracy: 0.2608 - val_loss: 2.0360 - val_categorical_accuracy: 0.2629\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 389s 640ms/step - loss: 1.9020 - categorical_accuracy: 0.2973 - val_loss: 1.9806 - val_categorical_accuracy: 0.2785\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.8229 - categorical_accuracy: 0.3197 - val_loss: 1.9525 - val_categorical_accuracy: 0.3024\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.7614 - categorical_accuracy: 0.3305 - val_loss: 1.9242 - val_categorical_accuracy: 0.3107\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.19      0.17       190\n",
            "         1.0       0.18      0.38      0.24       173\n",
            "         2.0       0.09      0.10      0.09       135\n",
            "         3.0       0.13      0.19      0.16       216\n",
            "         4.0       0.64      0.33      0.44      1036\n",
            "         5.0       0.18      0.38      0.25        76\n",
            "         6.0       0.54      0.81      0.65       195\n",
            "         7.0       0.16      0.07      0.09       290\n",
            "         8.0       0.10      0.12      0.10       139\n",
            "         9.0       0.24      0.37      0.29       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.24      0.29      0.25      2708\n",
            "weighted avg       0.37      0.30      0.31      2708\n",
            "\n",
            "0.29257651143912194\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 986s 2s/step - loss: 1.7809 - categorical_accuracy: 0.3281 - val_loss: 1.9469 - val_categorical_accuracy: 0.2978\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.7997 - categorical_accuracy: 0.3209 - val_loss: 1.9459 - val_categorical_accuracy: 0.2886\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.8179 - categorical_accuracy: 0.3180 - val_loss: 1.9257 - val_categorical_accuracy: 0.2969\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.7903 - categorical_accuracy: 0.3312 - val_loss: 1.9016 - val_categorical_accuracy: 0.3006\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.7939 - categorical_accuracy: 0.3264 - val_loss: 1.9550 - val_categorical_accuracy: 0.2932\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.7994 - categorical_accuracy: 0.3276 - val_loss: 1.9756 - val_categorical_accuracy: 0.2757\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.18      0.18       190\n",
            "         1.0       0.18      0.32      0.23       173\n",
            "         2.0       0.08      0.10      0.09       135\n",
            "         3.0       0.17      0.24      0.20       216\n",
            "         4.0       0.66      0.35      0.46      1036\n",
            "         5.0       0.14      0.36      0.20        76\n",
            "         6.0       0.55      0.82      0.66       195\n",
            "         7.0       0.12      0.04      0.07       290\n",
            "         8.0       0.11      0.12      0.11       139\n",
            "         9.0       0.20      0.34      0.25       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.24      0.29      0.24      2708\n",
            "weighted avg       0.37      0.30      0.31      2708\n",
            "\n",
            "0.2871389490893207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rndLTvgufxm-",
        "outputId": "14590f37-5a50-45a8-a146-629ad61d2bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2871389490893207]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.4]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z75mtdrI7Tmg",
        "outputId": "fbfa7391-d03d-4f1b-b55a-5e8ba6a91aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.4\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 418s 648ms/step - loss: 2.5535 - categorical_accuracy: 0.1344 - val_loss: 2.2163 - val_categorical_accuracy: 0.1912\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 2.2077 - categorical_accuracy: 0.1970 - val_loss: 2.1123 - val_categorical_accuracy: 0.2022\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 390s 640ms/step - loss: 2.0754 - categorical_accuracy: 0.2191 - val_loss: 2.0452 - val_categorical_accuracy: 0.2197\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 390s 640ms/step - loss: 1.9700 - categorical_accuracy: 0.2524 - val_loss: 2.0080 - val_categorical_accuracy: 0.2215\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.9136 - categorical_accuracy: 0.2634 - val_loss: 1.9795 - val_categorical_accuracy: 0.2307\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 389s 639ms/step - loss: 1.8342 - categorical_accuracy: 0.2964 - val_loss: 1.9442 - val_categorical_accuracy: 0.2518\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.33      0.23       190\n",
            "         1.0       0.17      0.31      0.22       173\n",
            "         2.0       0.08      0.10      0.09       135\n",
            "         3.0       0.14      0.07      0.10       216\n",
            "         4.0       0.64      0.21      0.32      1036\n",
            "         5.0       0.15      0.53      0.24        76\n",
            "         6.0       0.54      0.81      0.64       195\n",
            "         7.0       0.14      0.04      0.06       290\n",
            "         8.0       0.12      0.15      0.14       139\n",
            "         9.0       0.18      0.44      0.26       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.23      0.30      0.23      2708\n",
            "weighted avg       0.36      0.26      0.25      2708\n",
            "\n",
            "0.2986264741482065\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_5/albert/pooler/kernel:0', 'tf_albert_model_5/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_5/albert/pooler/kernel:0', 'tf_albert_model_5/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 988s 2s/step - loss: 1.8312 - categorical_accuracy: 0.2922 - val_loss: 1.9666 - val_categorical_accuracy: 0.2371\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.8744 - categorical_accuracy: 0.2819 - val_loss: 1.9689 - val_categorical_accuracy: 0.2426\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 957s 2s/step - loss: 1.8781 - categorical_accuracy: 0.2731 - val_loss: 1.9869 - val_categorical_accuracy: 0.2491\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.8775 - categorical_accuracy: 0.2720 - val_loss: 1.9427 - val_categorical_accuracy: 0.2702\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 956s 2s/step - loss: 1.8841 - categorical_accuracy: 0.2818 - val_loss: 1.9828 - val_categorical_accuracy: 0.2399\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 955s 2s/step - loss: 1.8930 - categorical_accuracy: 0.2762 - val_loss: 1.9521 - val_categorical_accuracy: 0.2693\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.30      0.23       190\n",
            "         1.0       0.16      0.31      0.21       173\n",
            "         2.0       0.10      0.11      0.10       135\n",
            "         3.0       0.17      0.09      0.11       216\n",
            "         4.0       0.65      0.20      0.31      1036\n",
            "         5.0       0.13      0.50      0.21        76\n",
            "         6.0       0.50      0.83      0.63       195\n",
            "         7.0       0.10      0.03      0.04       290\n",
            "         8.0       0.13      0.16      0.14       139\n",
            "         9.0       0.18      0.43      0.26       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.23      0.30      0.22      2708\n",
            "weighted avg       0.37      0.26      0.25      2708\n",
            "\n",
            "0.29546834261073013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seen_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNUMGcItnsZe",
        "outputId": "e0f50df0-5996-417c-cde7-01f56de68b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.001, 1e-05, 0.1),\n",
              " (0.001, 1e-05, 0.2),\n",
              " (0.001, 1e-05, 0.3),\n",
              " (0.001, 1e-05, 0.4),\n",
              " (0.001, 1e-05, 0.5),\n",
              " (0.001, 1e-06, 0.3),\n",
              " (0.0001, 1e-05, 0.3),\n",
              " (0.001, 1e-06, 0.5),\n",
              " (0.0001, 1e-05, 0.5),\n",
              " (0.0001, 1e-06, 0.5)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar={}\n",
        "balanced_accuracies_transfer_learning=[]\n",
        "balanced_accuracies_fine_tuning = []"
      ],
      "metadata": {
        "id": "kC7tbJ7xtm8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.5]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "if len(McNemar.keys()) == 0:\n",
        "  McNemar ={}\n",
        "if len(balanced_accuracies_fine_tuning) == 0:\n",
        "  balanced_accuracies_fine_tuning =[]\n",
        "  balanced_accuracies_transfer_learning=[]\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd1WOoaE7VCK",
        "outputId": "b7124931-1d71-4818-e588-7a477872d52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.5\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 366ms/step - loss: 2.5896 - categorical_accuracy: 0.1514 - val_loss: 2.2717 - val_categorical_accuracy: 0.1930\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 2.2829 - categorical_accuracy: 0.1995 - val_loss: 2.1596 - val_categorical_accuracy: 0.2142\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 217s 356ms/step - loss: 2.1393 - categorical_accuracy: 0.2254 - val_loss: 2.0961 - val_categorical_accuracy: 0.2399\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 2.0538 - categorical_accuracy: 0.2446 - val_loss: 2.0410 - val_categorical_accuracy: 0.2555\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 1.9761 - categorical_accuracy: 0.2625 - val_loss: 2.0155 - val_categorical_accuracy: 0.2537\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 1.9304 - categorical_accuracy: 0.2895 - val_loss: 1.9940 - val_categorical_accuracy: 0.2647\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.27      0.19       190\n",
            "         1.0       0.17      0.24      0.20       173\n",
            "         2.0       0.07      0.13      0.09       135\n",
            "         3.0       0.13      0.08      0.10       216\n",
            "         4.0       0.63      0.25      0.36      1036\n",
            "         5.0       0.12      0.45      0.19        76\n",
            "         6.0       0.52      0.81      0.64       195\n",
            "         7.0       0.20      0.06      0.09       290\n",
            "         8.0       0.07      0.05      0.06       139\n",
            "         9.0       0.22      0.47      0.30       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.23      0.28      0.22      2708\n",
            "weighted avg       0.36      0.27      0.27      2708\n",
            "\n",
            "0.2807043734688464\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_2/albert/pooler/kernel:0', 'tf_albert_model_2/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 564s 880ms/step - loss: 1.9347 - categorical_accuracy: 0.2822 - val_loss: 2.0095 - val_categorical_accuracy: 0.2711\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 530s 870ms/step - loss: 1.9516 - categorical_accuracy: 0.2778 - val_loss: 2.0077 - val_categorical_accuracy: 0.2564\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 530s 871ms/step - loss: 1.9537 - categorical_accuracy: 0.2792 - val_loss: 1.9977 - val_categorical_accuracy: 0.2592\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 530s 870ms/step - loss: 1.9814 - categorical_accuracy: 0.2707 - val_loss: 2.0206 - val_categorical_accuracy: 0.2463\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.33      0.22       190\n",
            "         1.0       0.18      0.25      0.21       173\n",
            "         2.0       0.06      0.09      0.07       135\n",
            "         3.0       0.13      0.08      0.10       216\n",
            "         4.0       0.66      0.30      0.41      1036\n",
            "         5.0       0.11      0.41      0.18        76\n",
            "         6.0       0.54      0.79      0.64       195\n",
            "         7.0       0.11      0.03      0.04       290\n",
            "         8.0       0.09      0.07      0.08       139\n",
            "         9.0       0.19      0.39      0.26       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.22      0.27      0.22      2708\n",
            "weighted avg       0.37      0.28      0.28      2708\n",
            "\n",
            "0.27426714207122804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (0.001, 1e-06, 0.5) in seen_parameters:\n",
        "  seen_parameters.remove((0.001, 1e-06, 0.5))\n",
        "if (0.0001, 1e-05, 0.5) in seen_parameters:\n",
        "  seen_parameters.remove((0.0001, 1e-05, 0.5))\n",
        "seen_parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XcymbgbEDec",
        "outputId": "e441aa64-1afa-452d-bed6-6982bec58434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.001, 1e-05, 0.1),\n",
              " (0.001, 1e-05, 0.2),\n",
              " (0.001, 1e-05, 0.3),\n",
              " (0.001, 1e-05, 0.4),\n",
              " (0.001, 1e-05, 0.5),\n",
              " (0.001, 1e-06, 0.3),\n",
              " (0.0001, 1e-05, 0.3),\n",
              " (0.0001, 1e-06, 0.5)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1de0q2GUEacI",
        "outputId": "5a4cc099-0ef7-467e-a847-f685a29abe2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27426714207122804]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rates = [0.5]#, 0.2, 0.3,0.4, 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "if len(McNemar.keys()) == 0:\n",
        "  McNemar ={}\n",
        "if len(balanced_accuracies_fine_tuning) == 0:\n",
        "  balanced_accuracies_fine_tuning =[]\n",
        "  balanced_accuracies_transfer_learning=[]\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    for drop_out_rate in drop_out_rates:\n",
        "      if (learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate) not in seen_parameters:\n",
        "        print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "        , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "\n",
        "        seen_parameters.append((learning_rate_transfer_learning, learning_rate_fine_tuning, drop_out_rate))\n",
        "\n",
        "        #step1\n",
        "        input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "        mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "        embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "        X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "        X = tf.keras.layers.BatchNormalization()(X)\n",
        "        X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "        X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "        model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "        model2.layers[2].trainable = False\n",
        "        #model2.summary()\n",
        "\n",
        "        #step2\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "        #model2.summary() #Check trainable params increased.\n",
        "\n",
        "        #step3: transfer learning\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "        #step4: predict\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "        #step5: fine tune\n",
        "        model2.layers[2].trainable = True\n",
        "\n",
        "        # It's important to recompile your model after you make any changes\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "        metrics = []\n",
        "        metrics.append(\n",
        "            tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "        model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "        history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "        balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "        balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "\n",
        "        del(model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ogI1Z5VEAYR",
        "outputId": "6b439172-de8e-41ea-c367-031a5bb2dcea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.5\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 365ms/step - loss: 2.2319 - categorical_accuracy: 0.2250 - val_loss: 2.0200 - val_categorical_accuracy: 0.2767\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.9344 - categorical_accuracy: 0.2908 - val_loss: 1.9183 - val_categorical_accuracy: 0.3024\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 1.8004 - categorical_accuracy: 0.3158 - val_loss: 1.8967 - val_categorical_accuracy: 0.2757\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 1.6771 - categorical_accuracy: 0.3434 - val_loss: 1.8694 - val_categorical_accuracy: 0.2923\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.6058 - categorical_accuracy: 0.3531 - val_loss: 1.8640 - val_categorical_accuracy: 0.2932\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.20      0.20       190\n",
            "         1.0       0.20      0.20      0.20       173\n",
            "         2.0       0.07      0.17      0.10       135\n",
            "         3.0       0.15      0.11      0.13       216\n",
            "         4.0       0.71      0.33      0.45      1036\n",
            "         5.0       0.18      0.33      0.23        76\n",
            "         6.0       0.64      0.80      0.71       195\n",
            "         7.0       0.20      0.06      0.09       290\n",
            "         8.0       0.11      0.37      0.17       139\n",
            "         9.0       0.24      0.40      0.30       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.27      0.30      0.26      2708\n",
            "weighted avg       0.41      0.30      0.32      2708\n",
            "\n",
            "0.2965663322361808\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_3/albert/pooler/kernel:0', 'tf_albert_model_3/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_3/albert/pooler/kernel:0', 'tf_albert_model_3/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 564s 879ms/step - loss: 1.5574 - categorical_accuracy: 0.3618 - val_loss: 1.8595 - val_categorical_accuracy: 0.3107\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 530s 870ms/step - loss: 1.5888 - categorical_accuracy: 0.3620 - val_loss: 1.8570 - val_categorical_accuracy: 0.3015\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 530s 870ms/step - loss: 1.5658 - categorical_accuracy: 0.3678 - val_loss: 1.8683 - val_categorical_accuracy: 0.3024\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 530s 870ms/step - loss: 1.5850 - categorical_accuracy: 0.3615 - val_loss: 1.8660 - val_categorical_accuracy: 0.3015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.19      0.18      0.19       190\n",
            "         1.0       0.20      0.21      0.20       173\n",
            "         2.0       0.09      0.20      0.12       135\n",
            "         3.0       0.18      0.14      0.16       216\n",
            "         4.0       0.67      0.32      0.43      1036\n",
            "         5.0       0.18      0.36      0.24        76\n",
            "         6.0       0.62      0.81      0.70       195\n",
            "         7.0       0.16      0.04      0.07       290\n",
            "         8.0       0.11      0.38      0.18       139\n",
            "         9.0       0.25      0.39      0.30       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.26      0.30      0.26      2708\n",
            "weighted avg       0.40      0.30      0.31      2708\n",
            "\n",
            "0.30378709045483726\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.5\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 366ms/step - loss: 2.5346 - categorical_accuracy: 0.1598 - val_loss: 2.1527 - val_categorical_accuracy: 0.2169\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 2.2175 - categorical_accuracy: 0.2092 - val_loss: 2.0932 - val_categorical_accuracy: 0.2270\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 2.0977 - categorical_accuracy: 0.2420 - val_loss: 2.0548 - val_categorical_accuracy: 0.2298\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 2.0177 - categorical_accuracy: 0.2526 - val_loss: 2.0265 - val_categorical_accuracy: 0.2482\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.9511 - categorical_accuracy: 0.2750 - val_loss: 1.9980 - val_categorical_accuracy: 0.2463\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 218s 358ms/step - loss: 1.9019 - categorical_accuracy: 0.2858 - val_loss: 1.9714 - val_categorical_accuracy: 0.2555\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.24      0.20       190\n",
            "         1.0       0.19      0.31      0.23       173\n",
            "         2.0       0.08      0.11      0.09       135\n",
            "         3.0       0.16      0.13      0.14       216\n",
            "         4.0       0.60      0.18      0.28      1036\n",
            "         5.0       0.15      0.43      0.22        76\n",
            "         6.0       0.57      0.79      0.67       195\n",
            "         7.0       0.23      0.06      0.10       290\n",
            "         8.0       0.08      0.10      0.09       139\n",
            "         9.0       0.18      0.49      0.26       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.24      0.29      0.23      2708\n",
            "weighted avg       0.36      0.25      0.25      2708\n",
            "\n",
            "0.2854462265645577\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_3/albert/pooler/kernel:0', 'tf_albert_model_3/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_3/albert/pooler/kernel:0', 'tf_albert_model_3/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 565s 879ms/step - loss: 2.2205 - categorical_accuracy: 0.2073 - val_loss: 4.7179 - val_categorical_accuracy: 0.0634\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 529s 868ms/step - loss: 2.1856 - categorical_accuracy: 0.1631 - val_loss: 2.1077 - val_categorical_accuracy: 0.1471\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 529s 868ms/step - loss: 2.0710 - categorical_accuracy: 0.1932 - val_loss: 2.9243 - val_categorical_accuracy: 0.2270\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 528s 867ms/step - loss: 2.0264 - categorical_accuracy: 0.2208 - val_loss: 1.9034 - val_categorical_accuracy: 0.3079\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 528s 867ms/step - loss: 1.9783 - categorical_accuracy: 0.2272 - val_loss: 2.1752 - val_categorical_accuracy: 0.1553\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 528s 867ms/step - loss: 1.9311 - categorical_accuracy: 0.2430 - val_loss: 2.6165 - val_categorical_accuracy: 0.1480\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.08      0.96      0.15       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.66      0.17      0.27      1036\n",
            "         5.0       0.03      0.01      0.02        76\n",
            "         6.0       0.93      0.39      0.55       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.01      0.03      0.02       139\n",
            "         9.0       0.25      0.00      0.01       258\n",
            "\n",
            "    accuracy                           0.16      2708\n",
            "   macro avg       0.20      0.16      0.10      2708\n",
            "weighted avg       0.35      0.16      0.16      2708\n",
            "\n",
            "0.15720348810871582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this result, ALBERT performs best at the dropout rate =0.5, initial learning rate=1e-3, fine tuning learning rate=1e-6."
      ],
      "metadata": {
        "id": "gaZxeBiu-l8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second Fold"
      ],
      "metadata": {
        "id": "tldC3z9k7eb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(dataset_train)\n",
        "del(dataset_test)\n",
        "del(train)\n",
        "del(val)\n",
        "del(test)"
      ],
      "metadata": {
        "id": "Ho4dl8W_f4Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[1]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c85a285-06fc-4416-a85e-5d854a05b18a",
        "id": "JkyzsU7ITMAn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learning =1e-3\n",
        "learning_rate_fine_tuning = 1e-6"
      ],
      "metadata": {
        "id": "aYkmxONsTMAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if len(balanced_accuracy_transfer_learning)==0:\n",
        "balanced_accuracy_transfer_learning = []\n",
        "#if len(balanced_accuracy_fine_tune)==0:\n",
        "balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "XC4TWeiFTMAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "McNemar={}"
      ],
      "metadata": {
        "id": "DQuRTCzSTMAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "SEQ_LEN2=256\n",
        "#step1\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "print(model2.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "print(model2.summary() )#Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_transfer_learning.append(balanced_acc)\n",
        "\n",
        "\n",
        "#step5: fine tune\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_fine_tune.append(balanced_acc)\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a1e74298aa14981aaffb0035b41dba9",
            "ba9f81a9049a484784a848d5bf2a261c",
            "1e31ebdba3bc4b9b960cd0ceb10ecddf",
            "67763a33ffd54fdaa72a4ad8cc441839",
            "ab86569ed0424abda503b45bd797e7fa",
            "ac71a72b67d54961b347eec24d654bcd",
            "0b1ad7af737d4f0c846098280cd2e272",
            "51f6c0c2d064478b98bc898c5f0860d4",
            "5ba90ff701574542a28518fada758d2e",
            "5527a6de1beb41769cd4c751eee8b786",
            "7ad457b748c84d58b3280ba5a2916f7e"
          ]
        },
        "id": "PgCaNNP6TMAo",
        "outputId": "48e15416-44f2-4f8f-f925-f54a42e3724e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/83.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a1e74298aa14981aaffb0035b41dba9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model (TFAlbertModel  TFBaseModelOutputWi  17683968   ['input_ids[0][0]',              \n",
            " )                              thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 1024),                                                          \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 1024)        0           ['tf_albert_model[0][0]']        \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 1024)        4096        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          131200      ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,823,722\n",
            "Trainable params: 137,706\n",
            "Non-trainable params: 17,686,016\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model (TFAlbertModel  TFBaseModelOutputWi  17683968   ['input_ids[0][0]',              \n",
            " )                              thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 1024),                                                          \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 1024)        0           ['tf_albert_model[0][0]']        \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 1024)        4096        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          131200      ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,823,722\n",
            "Trainable params: 137,706\n",
            "Non-trainable params: 17,686,016\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 245s 365ms/step - loss: 2.2230 - categorical_accuracy: 0.2022 - val_loss: 1.9923 - val_categorical_accuracy: 0.2206\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 217s 356ms/step - loss: 1.9045 - categorical_accuracy: 0.2834 - val_loss: 1.9217 - val_categorical_accuracy: 0.2675\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 218s 357ms/step - loss: 1.7995 - categorical_accuracy: 0.3011 - val_loss: 1.8969 - val_categorical_accuracy: 0.2592\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 1.6905 - categorical_accuracy: 0.3289 - val_loss: 1.8651 - val_categorical_accuracy: 0.2840\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 1.6260 - categorical_accuracy: 0.3487 - val_loss: 1.8815 - val_categorical_accuracy: 0.2877\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 1.5454 - categorical_accuracy: 0.3546 - val_loss: 1.8849 - val_categorical_accuracy: 0.2877\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.24      0.21       191\n",
            "         1.0       0.16      0.25      0.20       173\n",
            "         2.0       0.09      0.19      0.12       134\n",
            "         3.0       0.15      0.13      0.14       216\n",
            "         4.0       0.66      0.23      0.34      1036\n",
            "         5.0       0.18      0.25      0.21        76\n",
            "         6.0       0.64      0.86      0.73       196\n",
            "         7.0       0.22      0.03      0.05       289\n",
            "         8.0       0.10      0.32      0.15       139\n",
            "         9.0       0.25      0.49      0.33       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.26      0.30      0.25      2708\n",
            "weighted avg       0.39      0.27      0.28      2708\n",
            "\n",
            "0.29768744126078667\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 561s 880ms/step - loss: 1.5484 - categorical_accuracy: 0.3557 - val_loss: 1.8720 - val_categorical_accuracy: 0.2822\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 532s 874ms/step - loss: 1.5574 - categorical_accuracy: 0.3453 - val_loss: 1.8545 - val_categorical_accuracy: 0.2849\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 533s 875ms/step - loss: 1.6027 - categorical_accuracy: 0.3338 - val_loss: 1.8745 - val_categorical_accuracy: 0.2840\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 532s 874ms/step - loss: 1.6103 - categorical_accuracy: 0.3336 - val_loss: 1.8603 - val_categorical_accuracy: 0.2923\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 531s 872ms/step - loss: 1.5960 - categorical_accuracy: 0.3381 - val_loss: 1.8635 - val_categorical_accuracy: 0.2886\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 531s 873ms/step - loss: 1.5954 - categorical_accuracy: 0.3381 - val_loss: 1.8942 - val_categorical_accuracy: 0.2840\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.19      0.26      0.22       191\n",
            "         1.0       0.16      0.25      0.20       173\n",
            "         2.0       0.09      0.16      0.11       134\n",
            "         3.0       0.13      0.14      0.13       216\n",
            "         4.0       0.67      0.23      0.34      1036\n",
            "         5.0       0.18      0.21      0.20        76\n",
            "         6.0       0.63      0.88      0.74       196\n",
            "         7.0       0.19      0.02      0.04       289\n",
            "         8.0       0.09      0.31      0.14       139\n",
            "         9.0       0.25      0.47      0.33       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.26      0.29      0.24      2708\n",
            "weighted avg       0.40      0.27      0.28      2708\n",
            "\n",
            "0.2937908341627715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Third Fold"
      ],
      "metadata": {
        "id": "AYoa1akFgR7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(dataset_train)\n",
        "del(dataset_test)\n",
        "del(train)\n",
        "del(val)\n",
        "del(test)"
      ],
      "metadata": {
        "id": "trpyAeUagR7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[2]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b15c9eb-5a92-4020-f772-ed7f4e67d0a8",
        "id": "ZdtViU0lgR7M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learning =1e-3\n",
        "learning_rate_fine_tuning = 1e-6"
      ],
      "metadata": {
        "id": "roHzCUjzgR7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if len(balanced_accuracy_transfer_learning)==0:\n",
        "balanced_accuracy_transfer_learning = []\n",
        "#if len(balanced_accuracy_fine_tune)==0:\n",
        "balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "2yGSbndpgR7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if len(McNemar.keys())==0:\n",
        "McNemar={}"
      ],
      "metadata": {
        "id": "5nk4_T9vgR7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "SEQ_LEN2=256\n",
        "#step1\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "print(model2.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "print(model2.summary() )#Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_transfer_learning.append(balanced_acc)\n",
        "\n",
        "\n",
        "#step5: fine tune\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_fine_tune.append(balanced_acc)\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "56056ad00cb5469293bc4d07886b6377",
            "fa3bb0b7655744d491dfd2fc9e6c95c8",
            "931c03dafe6745edbfe4f9b580c5fd38",
            "9219b5b9b5364d6784a241cbae92a3a0",
            "e6c210ca1b664cf495b7377c7ce13a2d",
            "a31540359e5b470895d79ba9c82541f9",
            "a4e9f550e04c47ddb36098293f8149fa",
            "6b14562d96a045df8318f584929969a8",
            "be3f1cc199af48dd95f2b79feee05ae3",
            "644d3b32b6f9473fa56c53162d0b3aa5",
            "97653020e1f041129d3a2a6b5eaeb35b"
          ]
        },
        "outputId": "904d5c54-55a4-4ea7-e5e1-626ee072a8ac",
        "id": "FsUfSi7SgR7M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/83.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56056ad00cb5469293bc4d07886b6377"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model (TFAlbertModel  TFBaseModelOutputWi  17683968   ['input_ids[0][0]',              \n",
            " )                              thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 1024),                                                          \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 1024)        0           ['tf_albert_model[0][0]']        \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 1024)        4096        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          131200      ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,823,722\n",
            "Trainable params: 137,706\n",
            "Non-trainable params: 17,686,016\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model (TFAlbertModel  TFBaseModelOutputWi  17683968   ['input_ids[0][0]',              \n",
            " )                              thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 1024),                                                          \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 1024)        0           ['tf_albert_model[0][0]']        \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 1024)        4096        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          131200      ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,823,722\n",
            "Trainable params: 137,706\n",
            "Non-trainable params: 17,686,016\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 243s 362ms/step - loss: 2.2352 - categorical_accuracy: 0.2098 - val_loss: 1.9826 - val_categorical_accuracy: 0.2629\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 215s 354ms/step - loss: 1.9291 - categorical_accuracy: 0.2712 - val_loss: 1.9137 - val_categorical_accuracy: 0.2656\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 216s 355ms/step - loss: 1.8086 - categorical_accuracy: 0.3042 - val_loss: 1.9183 - val_categorical_accuracy: 0.2454\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 216s 355ms/step - loss: 1.7084 - categorical_accuracy: 0.3176 - val_loss: 1.8768 - val_categorical_accuracy: 0.2656\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 217s 357ms/step - loss: 1.6324 - categorical_accuracy: 0.3437 - val_loss: 1.8721 - val_categorical_accuracy: 0.2564\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.20      0.18       191\n",
            "         1.0       0.20      0.28      0.24       172\n",
            "         2.0       0.09      0.15      0.11       134\n",
            "         3.0       0.17      0.20      0.18       216\n",
            "         4.0       0.66      0.14      0.23      1036\n",
            "         5.0       0.19      0.39      0.25        77\n",
            "         6.0       0.65      0.86      0.74       196\n",
            "         7.0       0.16      0.05      0.08       290\n",
            "         8.0       0.10      0.16      0.12       139\n",
            "         9.0       0.20      0.61      0.30       257\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.26      0.30      0.24      2708\n",
            "weighted avg       0.39      0.25      0.24      2708\n",
            "\n",
            "0.3049863407146768\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 562s 877ms/step - loss: 1.5596 - categorical_accuracy: 0.3326 - val_loss: 1.8645 - val_categorical_accuracy: 0.2702\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 529s 868ms/step - loss: 1.5766 - categorical_accuracy: 0.3325 - val_loss: 1.8466 - val_categorical_accuracy: 0.2463\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 529s 868ms/step - loss: 1.6309 - categorical_accuracy: 0.3123 - val_loss: 1.8860 - val_categorical_accuracy: 0.2463\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 529s 868ms/step - loss: 1.6331 - categorical_accuracy: 0.3137 - val_loss: 1.8812 - val_categorical_accuracy: 0.2675\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.20      0.18       191\n",
            "         1.0       0.23      0.29      0.26       172\n",
            "         2.0       0.09      0.13      0.10       134\n",
            "         3.0       0.19      0.21      0.20       216\n",
            "         4.0       0.67      0.17      0.27      1036\n",
            "         5.0       0.16      0.39      0.23        77\n",
            "         6.0       0.60      0.88      0.71       196\n",
            "         7.0       0.14      0.05      0.07       290\n",
            "         8.0       0.11      0.14      0.13       139\n",
            "         9.0       0.18      0.57      0.28       257\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.25      0.30      0.24      2708\n",
            "weighted avg       0.39      0.26      0.25      2708\n",
            "\n",
            "0.3041683484458516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fourth Fold"
      ],
      "metadata": {
        "id": "DVdqNbDZ80Ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(dataset_train)\n",
        "del(dataset_test)\n",
        "del(train)\n",
        "del(val)\n",
        "del(test)"
      ],
      "metadata": {
        "id": "7TBgtXtd80E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if len(balanced_accuracy_transfer_learning)==0:\n",
        "balanced_accuracy_transfer_learning = []\n",
        "#if len(balanced_accuracy_fine_tune)==0:\n",
        "balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "-Fu1W3YATW65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if len(McNemar.keys())==0:\n",
        "McNemar={}"
      ],
      "metadata": {
        "id": "-5zZAABHTW65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[3]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6c66a1-8d5d-4aa5-fdd5-03234d149388",
        "id": "sFkkmSt780E0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learning =1e-3\n",
        "learning_rate_fine_tuning = 1e-6"
      ],
      "metadata": {
        "id": "q-8e3Yoz80E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(balanced_accuracy_transfer_learning)==0:\n",
        "  balanced_accuracy_transfer_learning = []\n",
        "if len(balanced_accuracy_fine_tune)==0:\n",
        "  balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "KxCamJQO80E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(McNemar.keys())==0:\n",
        "  McNemar={}"
      ],
      "metadata": {
        "id": "2bPgJ0tJ80E1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "SEQ_LEN2=256\n",
        "#step1\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "print(model2.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "print(model2.summary() )#Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_transfer_learning.append(balanced_acc)\n",
        "\n",
        "\n",
        "#step5: fine tune\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_fine_tune.append(balanced_acc)\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ffc57f3abaf94f93a08c67457d907dee",
            "a2fd47d1a9de45749a393d533a8552b6",
            "8fa763d244eb40718d7657734100c285",
            "420434132d534df98a9aca4922bbf624",
            "6a7bf583ef5e401d95d8b20fa3e4e7c8",
            "c9b3b907f20d4a40999f6a1e8ac98e17",
            "67bd96b8741e4bf58d7af67cf5d5d12c",
            "bfb97ff149694668b53a44e47b3bbeef",
            "b3da8ea56203494d92441b4213c18f9f",
            "f17724a585d64aad88c181e9c875db91",
            "dc6e0eade38e4f9dbc50d0adf9616d63"
          ]
        },
        "outputId": "b58de206-3d7e-44aa-f29e-0ddf310e79ad",
        "id": "-Xp6aLWV80E1"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffc57f3abaf94f93a08c67457d907dee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/83.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model (TFAlbertModel  TFBaseModelOutputWi  17683968   ['input_ids[0][0]',              \n",
            " )                              thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 1024),                                                          \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 1024)        0           ['tf_albert_model[0][0]']        \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 1024)        4096        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          131200      ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,823,722\n",
            "Trainable params: 137,706\n",
            "Non-trainable params: 17,686,016\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model (TFAlbertModel  TFBaseModelOutputWi  17683968   ['input_ids[0][0]',              \n",
            " )                              thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 1024),                                                          \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 1024)        0           ['tf_albert_model[0][0]']        \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 1024)        4096        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          131200      ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,823,722\n",
            "Trainable params: 137,706\n",
            "Non-trainable params: 17,686,016\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 431s 661ms/step - loss: 2.2359 - categorical_accuracy: 0.2048 - val_loss: 1.9714 - val_categorical_accuracy: 0.2528\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 397s 653ms/step - loss: 1.9263 - categorical_accuracy: 0.2887 - val_loss: 1.9004 - val_categorical_accuracy: 0.2638\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 397s 653ms/step - loss: 1.8065 - categorical_accuracy: 0.3057 - val_loss: 1.8915 - val_categorical_accuracy: 0.2638\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 397s 652ms/step - loss: 1.6893 - categorical_accuracy: 0.3233 - val_loss: 1.8537 - val_categorical_accuracy: 0.2831\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 397s 652ms/step - loss: 1.6117 - categorical_accuracy: 0.3507 - val_loss: 1.8608 - val_categorical_accuracy: 0.3006\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 397s 652ms/step - loss: 1.5199 - categorical_accuracy: 0.3706 - val_loss: 1.8583 - val_categorical_accuracy: 0.3107\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.19      0.28      0.22       191\n",
            "         1.0       0.16      0.16      0.16       172\n",
            "         2.0       0.08      0.19      0.12       134\n",
            "         3.0       0.23      0.26      0.25       216\n",
            "         4.0       0.67      0.19      0.30      1036\n",
            "         5.0       0.16      0.18      0.17        77\n",
            "         6.0       0.66      0.87      0.75       196\n",
            "         7.0       0.11      0.05      0.07       290\n",
            "         8.0       0.08      0.17      0.11       139\n",
            "         9.0       0.22      0.56      0.32       257\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.26      0.29      0.25      2708\n",
            "weighted avg       0.39      0.27      0.27      2708\n",
            "\n",
            "0.2905264583788094\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 1003s 2s/step - loss: 1.4983 - categorical_accuracy: 0.3686 - val_loss: 1.8687 - val_categorical_accuracy: 0.3051\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 965s 2s/step - loss: 1.5308 - categorical_accuracy: 0.3551 - val_loss: 1.8795 - val_categorical_accuracy: 0.2941\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 965s 2s/step - loss: 1.5535 - categorical_accuracy: 0.3573 - val_loss: 1.8469 - val_categorical_accuracy: 0.3162\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 965s 2s/step - loss: 1.5615 - categorical_accuracy: 0.3517 - val_loss: 1.8677 - val_categorical_accuracy: 0.2904\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 965s 2s/step - loss: 1.5541 - categorical_accuracy: 0.3443 - val_loss: 1.8695 - val_categorical_accuracy: 0.2886\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 965s 2s/step - loss: 1.5683 - categorical_accuracy: 0.3500 - val_loss: 1.8609 - val_categorical_accuracy: 0.2914\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.28      0.23       191\n",
            "         1.0       0.18      0.19      0.18       172\n",
            "         2.0       0.09      0.18      0.12       134\n",
            "         3.0       0.24      0.27      0.25       216\n",
            "         4.0       0.66      0.19      0.29      1036\n",
            "         5.0       0.15      0.26      0.19        77\n",
            "         6.0       0.67      0.83      0.74       196\n",
            "         7.0       0.09      0.04      0.05       290\n",
            "         8.0       0.10      0.19      0.13       139\n",
            "         9.0       0.20      0.54      0.29       257\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.26      0.30      0.25      2708\n",
            "weighted avg       0.39      0.27      0.26      2708\n",
            "\n",
            "0.2963777340680475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fifth Fold"
      ],
      "metadata": {
        "id": "gtw0FJoC84t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del(dataset_train)\n",
        "del(dataset_test)\n",
        "del(train)\n",
        "del(val)\n",
        "del(test)"
      ],
      "metadata": {
        "id": "FTrCnyB984t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if len(balanced_accuracy_transfer_learning)==0:\n",
        "balanced_accuracy_transfer_learning = []\n",
        "#if len(balanced_accuracy_fine_tune)==0:\n",
        "balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "czd-9hra84t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if len(McNemar.keys())==0:\n",
        "McNemar={}"
      ],
      "metadata": {
        "id": "EOptNKTR84t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AlbertTokenizer, TFAlbertModel\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[4]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "SEQ_LEN=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c6bb4d-f14b-4781-9a24-8dfebabdef61",
        "id": "oXziVzhj84t1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learning =1e-3\n",
        "learning_rate_fine_tuning = 1e-6"
      ],
      "metadata": {
        "id": "NLbFcv_Y84t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(balanced_accuracy_transfer_learning)==0:\n",
        "  balanced_accuracy_transfer_learning = []\n",
        "if len(balanced_accuracy_fine_tune)==0:\n",
        "  balanced_accuracy_fine_tune = []"
      ],
      "metadata": {
        "id": "oxqW2Yb-84t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(McNemar.keys())==0:\n",
        "  McNemar={}"
      ],
      "metadata": {
        "id": "ap5aB2hV84t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "albert_large = TFAlbertModel.from_pretrained('albert-large-v2')\n",
        "SEQ_LEN2=256\n",
        "#step1\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = albert_large(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model2 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model2.layers[2].trainable = False\n",
        "print(model2.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate= learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "print(model2.summary() )#Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_transfer_learning.append(balanced_acc)\n",
        "\n",
        "\n",
        "#step5: fine tune\n",
        "model2.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model2.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model2.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "#y_pred_transfer_learning=get_balanced_accuracy(model2)\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model2, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracy_fine_tune.append(balanced_acc)\n",
        "del(model2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4faea07b-6439-4981-cc74-f3ecd8f9601f",
        "id": "qoRA_8al84t1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model_1 (TFAlbertMod  TFBaseModelOutputWi  17683968   ['input_ids[0][0]',              \n",
            " el)                            thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 1024),                                                          \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 1024)        0           ['tf_albert_model_1[0][0]']      \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 1024)        4096        ['global_max_pooling1d_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          131200      ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           4128        ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,823,722\n",
            "Trainable params: 137,706\n",
            "Non-trainable params: 17,686,016\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_albert_model_1 (TFAlbertMod  TFBaseModelOutputWi  17683968   ['input_ids[0][0]',              \n",
            " el)                            thPooling(last_hidd               'attention_mask[0][0]']         \n",
            "                                en_state=(None, 256                                               \n",
            "                                , 1024),                                                          \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 1024)        0           ['tf_albert_model_1[0][0]']      \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 1024)        4096        ['global_max_pooling1d_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          131200      ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           4128        ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,823,722\n",
            "Trainable params: 137,706\n",
            "Non-trainable params: 17,686,016\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 431s 663ms/step - loss: 2.2458 - categorical_accuracy: 0.2086 - val_loss: 1.9954 - val_categorical_accuracy: 0.2840\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 397s 652ms/step - loss: 1.9546 - categorical_accuracy: 0.2777 - val_loss: 1.9366 - val_categorical_accuracy: 0.2730\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 397s 652ms/step - loss: 1.8142 - categorical_accuracy: 0.3047 - val_loss: 1.8961 - val_categorical_accuracy: 0.2904\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 397s 652ms/step - loss: 1.7170 - categorical_accuracy: 0.3389 - val_loss: 1.8791 - val_categorical_accuracy: 0.3006\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 397s 652ms/step - loss: 1.6145 - categorical_accuracy: 0.3611 - val_loss: 1.8648 - val_categorical_accuracy: 0.3199\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 397s 652ms/step - loss: 1.5249 - categorical_accuracy: 0.3884 - val_loss: 1.9108 - val_categorical_accuracy: 0.3015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.26      0.20       190\n",
            "         1.0       0.22      0.27      0.24       173\n",
            "         2.0       0.11      0.20      0.14       135\n",
            "         3.0       0.16      0.15      0.16       217\n",
            "         4.0       0.67      0.26      0.37      1035\n",
            "         5.0       0.20      0.32      0.24        76\n",
            "         6.0       0.60      0.86      0.71       195\n",
            "         7.0       0.14      0.08      0.10       290\n",
            "         8.0       0.08      0.12      0.10       139\n",
            "         9.0       0.22      0.52      0.31       258\n",
            "\n",
            "    accuracy                           0.29      2708\n",
            "   macro avg       0.26      0.30      0.26      2708\n",
            "weighted avg       0.39      0.29      0.29      2708\n",
            "\n",
            "0.30239952929166625\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_1/albert/pooler/kernel:0', 'tf_albert_model_1/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model_1/albert/pooler/kernel:0', 'tf_albert_model_1/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 1005s 2s/step - loss: 1.5295 - categorical_accuracy: 0.3772 - val_loss: 1.9275 - val_categorical_accuracy: 0.2932\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 965s 2s/step - loss: 1.6356 - categorical_accuracy: 0.3521 - val_loss: 1.9177 - val_categorical_accuracy: 0.2840\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 965s 2s/step - loss: 1.6112 - categorical_accuracy: 0.3597 - val_loss: 1.8921 - val_categorical_accuracy: 0.2776\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 965s 2s/step - loss: 1.6139 - categorical_accuracy: 0.3614 - val_loss: 1.9250 - val_categorical_accuracy: 0.2877\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.27      0.22       190\n",
            "         1.0       0.22      0.28      0.25       173\n",
            "         2.0       0.10      0.19      0.13       135\n",
            "         3.0       0.13      0.12      0.13       217\n",
            "         4.0       0.66      0.25      0.36      1035\n",
            "         5.0       0.20      0.34      0.25        76\n",
            "         6.0       0.62      0.85      0.72       195\n",
            "         7.0       0.16      0.08      0.11       290\n",
            "         8.0       0.09      0.13      0.11       139\n",
            "         9.0       0.23      0.53      0.32       258\n",
            "\n",
            "    accuracy                           0.29      2708\n",
            "   macro avg       0.26      0.30      0.26      2708\n",
            "weighted avg       0.39      0.29      0.29      2708\n",
            "\n",
            "0.30470751623170916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracy_fine_tune"
      ],
      "metadata": {
        "id": "O9bKH7VNeet7",
        "outputId": "f1068634-8dd1-4f0b-d662-50854cbb3d9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2963777340680475, 0.30470751623170916]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DWL5DlwVTHgV",
        "hWxfNJqYBfjD",
        "nONmunMa_h7T",
        "hb0KcNXhbUSN",
        "oylD4vpEYC_m",
        "wr-sII815ZQY",
        "tldC3z9k7eb3",
        "AYoa1akFgR7L",
        "DVdqNbDZ80Ez"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1GBA8Fqnm539nmtGxpqfHLZTiRfHsS80x",
      "authorship_tag": "ABX9TyPJz9H5tDDn47Y+9udlJhsb",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "662d0f403d1e4dfeb6fc29be94f50198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f0af31782e5435581e80666c77478bd",
              "IPY_MODEL_53abe4f95cf345869a3b6f44f96b1520",
              "IPY_MODEL_6556acea07544f8c8f414265f2d87511"
            ],
            "layout": "IPY_MODEL_69713da665c64ba8b168483309af40e8"
          }
        },
        "8f0af31782e5435581e80666c77478bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d139056dee4493abaa1e2757840091b",
            "placeholder": "​",
            "style": "IPY_MODEL_0803723664024e8b8e036b3886110483",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "53abe4f95cf345869a3b6f44f96b1520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4aaf7d3d784d08973922bb7f50bf07",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7d2fb18cb0748a69be07610ec5be7d3",
            "value": 526681800
          }
        },
        "6556acea07544f8c8f414265f2d87511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc37a448c8c48c1a5910f19a3c06730",
            "placeholder": "​",
            "style": "IPY_MODEL_1acbc29d6f914422883ae875cad5fef5",
            "value": " 502M/502M [00:08&lt;00:00, 64.3MB/s]"
          }
        },
        "69713da665c64ba8b168483309af40e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d139056dee4493abaa1e2757840091b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0803723664024e8b8e036b3886110483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c4aaf7d3d784d08973922bb7f50bf07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7d2fb18cb0748a69be07610ec5be7d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecc37a448c8c48c1a5910f19a3c06730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acbc29d6f914422883ae875cad5fef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7bbf41ebfd245dcbbaa47cfae1e325a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0d566968be248269790fd3ba5783915",
              "IPY_MODEL_ddd856361c344f919ab1c8996f7da98d",
              "IPY_MODEL_1394f3e609294612817b1707a4ad9364"
            ],
            "layout": "IPY_MODEL_0eed20d3a16d40bfb9089a6f4720c714"
          }
        },
        "a0d566968be248269790fd3ba5783915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0328b3a4c3bf464eadca437316942d7e",
            "placeholder": "​",
            "style": "IPY_MODEL_99c34b25a82e426fa05000b67d89839d",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "ddd856361c344f919ab1c8996f7da98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e94ba8d1a16047d3b50a466ac93a5e8e",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcb6ca0fd95a48ca9a2fa23f240dd63b",
            "value": 760289
          }
        },
        "1394f3e609294612817b1707a4ad9364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc83b47417b84c23aa649735e48e1095",
            "placeholder": "​",
            "style": "IPY_MODEL_592361f890d048f78a2fc5f70f0d23c8",
            "value": " 742k/742k [00:00&lt;00:00, 1.67MB/s]"
          }
        },
        "0eed20d3a16d40bfb9089a6f4720c714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0328b3a4c3bf464eadca437316942d7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99c34b25a82e426fa05000b67d89839d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e94ba8d1a16047d3b50a466ac93a5e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb6ca0fd95a48ca9a2fa23f240dd63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc83b47417b84c23aa649735e48e1095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592361f890d048f78a2fc5f70f0d23c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ff04f56385c4df6856f92080f45145a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a53509d10690484aa6e678887d4261f6",
              "IPY_MODEL_5efbd2459d334a02ae10d058a0afee00",
              "IPY_MODEL_cd696eaa64384eada93dfa1a2660efda"
            ],
            "layout": "IPY_MODEL_01a11a6af7254c8684d7fb75056a3df6"
          }
        },
        "a53509d10690484aa6e678887d4261f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ccddde8a34941f890b2f8a14abbbd9a",
            "placeholder": "​",
            "style": "IPY_MODEL_fb73f8dd28b745f2aaecd678e1e918ad",
            "value": "Downloading config.json: 100%"
          }
        },
        "5efbd2459d334a02ae10d058a0afee00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8907f5e76404386b0aecaf0cb2a05a7",
            "max": 685,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91c8a2cb92704c97ac1af4b4c2f6cf84",
            "value": 685
          }
        },
        "cd696eaa64384eada93dfa1a2660efda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9768e487ca49b3a6987fc179bb1bc2",
            "placeholder": "​",
            "style": "IPY_MODEL_759e2c70eb6246c1b8446310f58cb733",
            "value": " 685/685 [00:00&lt;00:00, 19.3kB/s]"
          }
        },
        "01a11a6af7254c8684d7fb75056a3df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ccddde8a34941f890b2f8a14abbbd9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb73f8dd28b745f2aaecd678e1e918ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8907f5e76404386b0aecaf0cb2a05a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c8a2cb92704c97ac1af4b4c2f6cf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f9768e487ca49b3a6987fc179bb1bc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "759e2c70eb6246c1b8446310f58cb733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a1e74298aa14981aaffb0035b41dba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba9f81a9049a484784a848d5bf2a261c",
              "IPY_MODEL_1e31ebdba3bc4b9b960cd0ceb10ecddf",
              "IPY_MODEL_67763a33ffd54fdaa72a4ad8cc441839"
            ],
            "layout": "IPY_MODEL_ab86569ed0424abda503b45bd797e7fa"
          }
        },
        "ba9f81a9049a484784a848d5bf2a261c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac71a72b67d54961b347eec24d654bcd",
            "placeholder": "​",
            "style": "IPY_MODEL_0b1ad7af737d4f0c846098280cd2e272",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "1e31ebdba3bc4b9b960cd0ceb10ecddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51f6c0c2d064478b98bc898c5f0860d4",
            "max": 87181048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5ba90ff701574542a28518fada758d2e",
            "value": 87181048
          }
        },
        "67763a33ffd54fdaa72a4ad8cc441839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5527a6de1beb41769cd4c751eee8b786",
            "placeholder": "​",
            "style": "IPY_MODEL_7ad457b748c84d58b3280ba5a2916f7e",
            "value": " 83.1M/83.1M [00:01&lt;00:00, 64.5MB/s]"
          }
        },
        "ab86569ed0424abda503b45bd797e7fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac71a72b67d54961b347eec24d654bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1ad7af737d4f0c846098280cd2e272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51f6c0c2d064478b98bc898c5f0860d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba90ff701574542a28518fada758d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5527a6de1beb41769cd4c751eee8b786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad457b748c84d58b3280ba5a2916f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56056ad00cb5469293bc4d07886b6377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa3bb0b7655744d491dfd2fc9e6c95c8",
              "IPY_MODEL_931c03dafe6745edbfe4f9b580c5fd38",
              "IPY_MODEL_9219b5b9b5364d6784a241cbae92a3a0"
            ],
            "layout": "IPY_MODEL_e6c210ca1b664cf495b7377c7ce13a2d"
          }
        },
        "fa3bb0b7655744d491dfd2fc9e6c95c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31540359e5b470895d79ba9c82541f9",
            "placeholder": "​",
            "style": "IPY_MODEL_a4e9f550e04c47ddb36098293f8149fa",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "931c03dafe6745edbfe4f9b580c5fd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b14562d96a045df8318f584929969a8",
            "max": 87181048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be3f1cc199af48dd95f2b79feee05ae3",
            "value": 87181048
          }
        },
        "9219b5b9b5364d6784a241cbae92a3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644d3b32b6f9473fa56c53162d0b3aa5",
            "placeholder": "​",
            "style": "IPY_MODEL_97653020e1f041129d3a2a6b5eaeb35b",
            "value": " 83.1M/83.1M [00:01&lt;00:00, 69.6MB/s]"
          }
        },
        "e6c210ca1b664cf495b7377c7ce13a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a31540359e5b470895d79ba9c82541f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e9f550e04c47ddb36098293f8149fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b14562d96a045df8318f584929969a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be3f1cc199af48dd95f2b79feee05ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "644d3b32b6f9473fa56c53162d0b3aa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97653020e1f041129d3a2a6b5eaeb35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffc57f3abaf94f93a08c67457d907dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2fd47d1a9de45749a393d533a8552b6",
              "IPY_MODEL_8fa763d244eb40718d7657734100c285",
              "IPY_MODEL_420434132d534df98a9aca4922bbf624"
            ],
            "layout": "IPY_MODEL_6a7bf583ef5e401d95d8b20fa3e4e7c8"
          }
        },
        "a2fd47d1a9de45749a393d533a8552b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9b3b907f20d4a40999f6a1e8ac98e17",
            "placeholder": "​",
            "style": "IPY_MODEL_67bd96b8741e4bf58d7af67cf5d5d12c",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "8fa763d244eb40718d7657734100c285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfb97ff149694668b53a44e47b3bbeef",
            "max": 87181048,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3da8ea56203494d92441b4213c18f9f",
            "value": 87181048
          }
        },
        "420434132d534df98a9aca4922bbf624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f17724a585d64aad88c181e9c875db91",
            "placeholder": "​",
            "style": "IPY_MODEL_dc6e0eade38e4f9dbc50d0adf9616d63",
            "value": " 83.1M/83.1M [00:02&lt;00:00, 42.5MB/s]"
          }
        },
        "6a7bf583ef5e401d95d8b20fa3e4e7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b3b907f20d4a40999f6a1e8ac98e17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67bd96b8741e4bf58d7af67cf5d5d12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfb97ff149694668b53a44e47b3bbeef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3da8ea56203494d92441b4213c18f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f17724a585d64aad88c181e9c875db91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6e0eade38e4f9dbc50d0adf9616d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KenObata/TISMIR_notebooks/blob/main/week15_XLnet_baseline_keras_768_batch_normaliza_every_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS8WVxEoWZG0"
      },
      "source": [
        "## Week15: This notebook uses Pre-Trained word matrix-> SMOTE -> undersample by EDA -> append to word vectors. -> using Word2Vec. After that I apply SMOTE to balance out. \n",
        "Added task: Grid Search for best parameter in SVM.\n",
        "\n",
        "Situation: English only (=multi-class).\n",
        "Split: StratifiedKfold.\n",
        "Reference: https://github.com/jasonwei20/eda_nlp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWL5DlwVTHgV"
      },
      "source": [
        "### set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Fdw4QzS4FD",
        "outputId": "574ac3ca-e1c5-4f3b-d836-be27fa29a2a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 5.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d5F3EmWPVWZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from collections import Counter\n",
        "\n",
        "from skmultilearn.model_selection import IterativeStratification   \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6VTlTxg8JVQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "def get_balanced_accuracy(model, McNemar, is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning):\n",
        "  test_y = test.map(map_func_only_y)\n",
        "  y_category=np.zeros((TEST_SIZE, ))\n",
        "  counter=0\n",
        "  for label_tensor in test_y.take(len(test_y)):\n",
        "    y_test = np.argmax(label_tensor, axis=1)\n",
        "    for label in y_test:\n",
        "      y_category[counter]=label\n",
        "      counter+=1\n",
        "\n",
        "  X_test, y_test = test.map(map_func_only_X), y_category\n",
        "  y_predict_test = np.asarray(model.predict(X_test))\n",
        "  y_predict_test = np.argmax(y_predict_test, axis=1)\n",
        "  print(classification_report(y_test, y_predict_test) )\n",
        "  print(balanced_accuracy_score(y_test, y_predict_test))\n",
        "\n",
        "  McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)] = []\n",
        "  for ground_truh, pred in zip(y_test, y_predict_test):\n",
        "        if ground_truh==pred:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(True)\n",
        "        else:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(False)\n",
        "  with open(DIR+ \"XLnet_1024_simple_dropout_and_batch_normalization_log.txt\", \"a\") as f:\n",
        "    print(\"======================================\", file=f)\n",
        "    print(\"is_fine_tuning?:\", is_fine_tuning, \"drop_out_rate: \", drop_out_rate, \"learning_rate_transfer_learning: \", learning_rate_transfer_learning,\n",
        "          \"learning_rate_fine_tuning: \", learning_rate_fine_tuning, file=f)\n",
        "    print(classification_report(y_test, y_predict_test) , file=f)\n",
        "    print(balanced_accuracy_score(y_test, y_predict_test), file=f)\n",
        "\n",
        "  return balanced_accuracy_score(y_test, y_predict_test), McNemar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWxfNJqYBfjD"
      },
      "source": [
        "### Data Preparation(Kfold split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbT7Qs4whnTX"
      },
      "source": [
        "Create dataframe for Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le3tiKjOOp19",
        "outputId": "e85cbaa5-bc40-4a37-993f-7aa1100ba5e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-41b4eafe-26d0-4d37-82b7-945224be75de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>genres</th>\n",
              "      <th>lang</th>\n",
              "      <th>lyric</th>\n",
              "      <th>number_of_line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0009fFIM1eYThaPg</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>a sunny day so I got nowhere to hide Not a clo...</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>00P2bHdWFkghmDqz</td>\n",
              "      <td>soul</td>\n",
              "      <td>en</td>\n",
              "      <td>Tell me a tale that always was Sing me a song ...</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>00b6fV3nx5z2b8Ls</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>A buh A buh You went to school to learn girl T...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>013QDoTqbexEwkHr</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>like a conversation where stops to breathe Is ...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>01EKNot8qVgZpKM7</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Say the words I cannot say Say them on another...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>13535</td>\n",
              "      <td>zzT504Z94j1IAuc3</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>think what afraid of come in you know been mad...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>13536</td>\n",
              "      <td>zzgS4ZqyswamEWNj</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Oh yeah yeah Last night I took a walk in the s...</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>13537</td>\n",
              "      <td>zzx8CWdM7qkxKQpC</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Innocence it come easy in a sense it never wil...</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>13538</td>\n",
              "      <td>zzz0n04uuTUA7fNh</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Girl you know how I feel I really Since you be...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>13539</td>\n",
              "      <td>zzzj3LYaZtYtbzSr</td>\n",
              "      <td>singer-songwriter</td>\n",
              "      <td>en</td>\n",
              "      <td>wwI oh must go on standing You break that whic...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41b4eafe-26d0-4d37-82b7-945224be75de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41b4eafe-26d0-4d37-82b7-945224be75de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41b4eafe-26d0-4d37-82b7-945224be75de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0                id             genres lang  \\\n",
              "0               0  0009fFIM1eYThaPg                pop   en   \n",
              "1               1  00P2bHdWFkghmDqz               soul   en   \n",
              "2               2  00b6fV3nx5z2b8Ls                pop   en   \n",
              "3               3  013QDoTqbexEwkHr                pop   en   \n",
              "4               4  01EKNot8qVgZpKM7               rock   en   \n",
              "...           ...               ...                ...  ...   \n",
              "13535       13535  zzT504Z94j1IAuc3         indie rock   en   \n",
              "13536       13536  zzgS4ZqyswamEWNj                pop   en   \n",
              "13537       13537  zzx8CWdM7qkxKQpC         indie rock   en   \n",
              "13538       13538  zzz0n04uuTUA7fNh                pop   en   \n",
              "13539       13539  zzzj3LYaZtYtbzSr  singer-songwriter   en   \n",
              "\n",
              "                                                   lyric  number_of_line  \n",
              "0      a sunny day so I got nowhere to hide Not a clo...              91  \n",
              "1      Tell me a tale that always was Sing me a song ...              36  \n",
              "2      A buh A buh You went to school to learn girl T...              74  \n",
              "3      like a conversation where stops to breathe Is ...              20  \n",
              "4      Say the words I cannot say Say them on another...              31  \n",
              "...                                                  ...             ...  \n",
              "13535  think what afraid of come in you know been mad...              18  \n",
              "13536  Oh yeah yeah Last night I took a walk in the s...              75  \n",
              "13537  Innocence it come easy in a sense it never wil...              34  \n",
              "13538  Girl you know how I feel I really Since you be...              65  \n",
              "13539  wwI oh must go on standing You break that whic...              64  \n",
              "\n",
              "[13540 rows x 6 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "df_genre_by_lang = pd.read_csv(DIR + 'df_genre_by_lang_full.csv')\n",
        "df_genre_by_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrRidTBHhmYp"
      },
      "outputs": [],
      "source": [
        "def load_data(df_col, y):\n",
        "    texts, labels = [], []\n",
        "    \n",
        "    for line in df_col:\n",
        "        # texts are already tokenized, just split on space\n",
        "        # in a real use-case we would put more effort in preprocessing\n",
        "        texts.append(line.split(' '))\n",
        "    return pd.DataFrame({'texts': texts, 'labels': y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5VJWiA6iJu2"
      },
      "outputs": [],
      "source": [
        "data = load_data(df_genre_by_lang[\"lyric\"], df_genre_by_lang[\"genres\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWI4V7oXiWw6",
        "outputId": "991d81fc-9f44-40ca-c0b1-ee7ea2b5c778"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-94178785-dd84-42f8-84d7-5f228db234f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[a, sunny, day, so, I, got, nowhere, to, hide,...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Tell, me, a, tale, that, always, was, Sing, m...</td>\n",
              "      <td>soul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[A, buh, A, buh, You, went, to, school, to, le...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[like, a, conversation, where, stops, to, brea...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Say, the, words, I, cannot, say, Say, them, o...</td>\n",
              "      <td>rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>[think, what, afraid, of, come, in, you, know,...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>[Oh, yeah, yeah, Last, night, I, took, a, walk...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>[Innocence, it, come, easy, in, a, sense, it, ...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>[Girl, you, know, how, I, feel, I, really, Sin...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>[wwI, oh, must, go, on, standing, You, break, ...</td>\n",
              "      <td>singer-songwriter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94178785-dd84-42f8-84d7-5f228db234f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94178785-dd84-42f8-84d7-5f228db234f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94178785-dd84-42f8-84d7-5f228db234f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   texts             labels\n",
              "0      [a, sunny, day, so, I, got, nowhere, to, hide,...                pop\n",
              "1      [Tell, me, a, tale, that, always, was, Sing, m...               soul\n",
              "2      [A, buh, A, buh, You, went, to, school, to, le...                pop\n",
              "3      [like, a, conversation, where, stops, to, brea...                pop\n",
              "4      [Say, the, words, I, cannot, say, Say, them, o...               rock\n",
              "...                                                  ...                ...\n",
              "13535  [think, what, afraid, of, come, in, you, know,...         indie rock\n",
              "13536  [Oh, yeah, yeah, Last, night, I, took, a, walk...                pop\n",
              "13537  [Innocence, it, come, easy, in, a, sense, it, ...         indie rock\n",
              "13538  [Girl, you, know, how, I, feel, I, really, Sin...                pop\n",
              "13539  [wwI, oh, must, go, on, standing, You, break, ...  singer-songwriter\n",
              "\n",
              "[13540 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTROinyfjc6u"
      },
      "outputs": [],
      "source": [
        "data['labels'] = data['labels'].astype('category')\n",
        "label_mapping = data['labels'].cat.categories\n",
        "data['labels'] = data['labels'].cat.codes\n",
        "X = data['texts']\n",
        "y = data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32Ub0-kjoOj",
        "outputId": "8c336c39-24d9-4e04-9cd2-92a0fdafe9a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnAEWk_Lza7f"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df_glove(df, feature_list, y_name):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  y = df[y_name]\n",
        "  skf.get_n_splits(df[ feature_list ], y)\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(df[ feature_list ], y):\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = df[ feature_list ].loc[train_index], df[ feature_list ].loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qOv6pF0BcrV"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df(X, y):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  #y = df[y_name]\n",
        "  skf.get_n_splits(X, y)#df[ feature_list ]\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(X, y):#df[ feature_list ]\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGZPLOeBg4R",
        "outputId": "75159890-b6c2-494b-eaa7-a61087cfdb00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN: [    0     1     3 ... 13537 13538 13539] TEST: [    2     4     5 ... 13526 13532 13535]\n",
            "TRAIN: [    0     2     4 ... 13535 13536 13539] TEST: [    1     3     7 ... 13530 13537 13538]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [    8    14    22 ... 13521 13531 13536]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [   10    12    15 ... 13523 13525 13534]\n",
            "TRAIN: [    1     2     3 ... 13536 13537 13538] TEST: [    0     6    11 ... 13529 13533 13539]\n"
          ]
        }
      ],
      "source": [
        "#feature_list = [\"texts\"] #this is BOW and TF-IDF\n",
        "#splits = StratifiedKFold_feature_and_df( data, feature_list, 'labels')\n",
        "splits = StratifiedKFold_feature_and_df( X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsQYbmVUWPU9",
        "outputId": "a076ec08-eb56-4506-a957-786c5dfe149b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDMBs_gWCSLa",
        "outputId": "223a0c48-f598-4847-8dcf-5e4b93d57de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10832,)\n",
            "(10832,)\n",
            "(2708,)\n",
            "(2708,)\n"
          ]
        }
      ],
      "source": [
        "split0=splits[0]\n",
        "print(split0['X_train'].shape)\n",
        "print(split0['y_train'].shape)\n",
        "print(split0['X_test'].shape)\n",
        "print(split0['y_test'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaMmpM44is_p",
        "outputId": "e27cc429-e27c-4d5d-e489-3c838602aee4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        [a, sunny, day, so, I, got, nowhere, to, hide,...\n",
              "1        [Tell, me, a, tale, that, always, was, Sing, m...\n",
              "3        [like, a, conversation, where, stops, to, brea...\n",
              "6        [Locked, up, tight, Like, I, would, never, fee...\n",
              "7        [sittin, in, the, crib, dreamin, about, leer, ...\n",
              "                               ...                        \n",
              "13534    [grandma, cookies, nigga, Shout, out, to, fron...\n",
              "13536    [Oh, yeah, yeah, Last, night, I, took, a, walk...\n",
              "13537    [Innocence, it, come, easy, in, a, sense, it, ...\n",
              "13538    [Girl, you, know, how, I, feel, I, really, Sin...\n",
              "13539    [wwI, oh, must, go, on, standing, You, break, ...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split0['X_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qTuHLEe8Aqg",
        "outputId": "3a7b7c62-1739-4085-991d-68d171d629cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split0['y_train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONmunMa_h7T"
      },
      "source": [
        "### Use my self programmed balanced accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot3KP7Dl_kdf",
        "outputId": "b39a20db-171b-4ef7-bd3a-e1a9522eb463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "339/339 [==============================] - 225s 645ms/step - loss: 0.5565 - categorical_accuracy: 0.3878 - val_loss: 1.9337 - val_categorical_accuracy: 0.3273\n",
            "Epoch 2/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5397 - categorical_accuracy: 0.3626 - val_loss: 2.0651 - val_categorical_accuracy: 0.2764\n",
            "Epoch 3/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5375 - categorical_accuracy: 0.3392 - val_loss: 2.0931 - val_categorical_accuracy: 0.2273\n",
            "Epoch 4/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5378 - categorical_accuracy: 0.3197 - val_loss: 2.0576 - val_categorical_accuracy: 0.2459\n",
            "Epoch 5/10\n",
            "339/339 [==============================] - 219s 645ms/step - loss: 0.5333 - categorical_accuracy: 0.3077 - val_loss: 2.0292 - val_categorical_accuracy: 0.2816\n",
            "Epoch 6/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5373 - categorical_accuracy: 0.2967 - val_loss: 2.1738 - val_categorical_accuracy: 0.1895\n",
            "Epoch 7/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5396 - categorical_accuracy: 0.2930 - val_loss: 2.1382 - val_categorical_accuracy: 0.2181\n",
            "Epoch 8/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5431 - categorical_accuracy: 0.2710 - val_loss: 2.1512 - val_categorical_accuracy: 0.1965\n",
            "Epoch 9/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5450 - categorical_accuracy: 0.2729 - val_loss: 2.1854 - val_categorical_accuracy: 0.1092\n",
            "Epoch 10/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5495 - categorical_accuracy: 0.2553 - val_loss: 2.1354 - val_categorical_accuracy: 0.1594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'balanced_accuracy': 0.09744849916749872},\n",
              " {'balanced_accuracy': 0.10420636932765996},\n",
              " {'balanced_accuracy': 0.10970405736872939},\n",
              " {'balanced_accuracy': 0.10356561320774078},\n",
              " {'balanced_accuracy': 0.10792864804613309},\n",
              " {'balanced_accuracy': 0.09168989857066105},\n",
              " {'balanced_accuracy': 0.09926135499834263},\n",
              " {'balanced_accuracy': 0.10014630125778516},\n",
              " {'balanced_accuracy': 0.09807505457274496},\n",
              " {'balanced_accuracy': 0.09881853716030842}]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics = Metrics()\n",
        "history = model.fit(train, validation_data=val, epochs=10, class_weight=my_weight ,callbacks=[metrics])\n",
        "metrics.get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzqLBSC6H175"
      },
      "source": [
        "## From here, separate X_train, X_test from KFoldSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb0KcNXhbUSN"
      },
      "source": [
        "### Preprocess my lyrics data (Official train and test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4lLLyF-bUSO",
        "outputId": "d2d25b5f-dd34-4c25-8793-e2c223e5377f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "!pip3 install transformers\n",
        "SEQ_LEN = 1024#256#512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUA-ps2gyvt",
        "outputId": "798742c9-8138-4ba3-937c-86d16af6c2c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2        [A, buh, A, buh, You, went, to, school, to, le...\n",
              "4        [Say, the, words, I, cannot, say, Say, them, o...\n",
              "5        [I, was, alone, I, was, made, of, stone, You, ...\n",
              "9        [Again, the, burden, of, losing, rests, upon, ...\n",
              "20       [only, been, three, weeks, And, a, bag, of, sp...\n",
              "                               ...                        \n",
              "13517    [Like, the, legend, of, the, Phoenix, All, end...\n",
              "13522    [Mr, Telephone, man, something, wrong, with, m...\n",
              "13526    [can, you, imagine, what, it, would, be, like,...\n",
              "13532    [Love, of, my, life, hurt, me, broken, my, hea...\n",
              "13535    [think, what, afraid, of, come, in, you, know,...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split0['X_test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqFwOGTIbhiZ"
      },
      "outputs": [],
      "source": [
        "def prepare_lyrics(X_series):\n",
        "  for i, token_list in X_series.items():\n",
        "    if type(token_list) is list:\n",
        "      X_series.loc[i] = ' '.join(token_list)\n",
        "  return X_series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzTIRCW1cUwV",
        "outputId": "cdee203d-74da-4f10-8570-be259fd06df2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2        A buh A buh You went to school to learn girl T...\n",
              "4        Say the words I cannot say Say them on another...\n",
              "5        I was alone I was made of stone You took me ho...\n",
              "9        Again the burden of losing rests upon my shoul...\n",
              "20       only been three weeks And a bag of speed from ...\n",
              "                               ...                        \n",
              "13517    Like the legend of the Phoenix All ends with b...\n",
              "13522    Mr Telephone man something wrong with my line ...\n",
              "13526    can you imagine what it would be like we never...\n",
              "13532    Love of my life hurt me broken my heart and no...\n",
              "13535    think what afraid of come in you know been mad...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "split0['X_test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxixg4yAcAfe",
        "outputId": "58355521-4569-415f-9d27-519c1f0d7e3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        a sunny day so I got nowhere to hide Not a clo...\n",
              "1        Tell me a tale that always was Sing me a song ...\n",
              "3        like a conversation where stops to breathe Is ...\n",
              "6        Locked up tight Like I would never feel again ...\n",
              "7        sittin in the crib dreamin about leer jets and...\n",
              "                               ...                        \n",
              "13534    grandma cookies nigga Shout out to fronto leaf...\n",
              "13536    Oh yeah yeah Last night I took a walk in the s...\n",
              "13537    Innocence it come easy in a sense it never wil...\n",
              "13538    Girl you know how I feel I really Since you be...\n",
              "13539    wwI oh must go on standing You break that whic...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_train'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9UxO1GAcfoI",
        "outputId": "407debb4-db0a-4830-dd0c-9b3e52076f44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split0['y_train'] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zWdtsKTSIjD"
      },
      "source": [
        "use ALBERT\n",
        "Be careful, you need sentencepiece library:https://stackoverflow.com/questions/65854722/huggingface-albert-tokenizer-nonetype-error-with-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QClJ2DWKVs0Q",
        "outputId": "6c89e738-d803-438b-e245-c97d2334c904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 11.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip3 install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7xk5236bUSR"
      },
      "outputs": [],
      "source": [
        "def map_func(input_ids, masks, labels):\n",
        "  return {'input_ids': input_ids, 'attention_mask':masks}, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVuShbZzbUSS"
      },
      "source": [
        "339 because 10800/32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cg9c-e5jbUSS"
      },
      "outputs": [],
      "source": [
        "SPLIT = 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-e9iZTaasAJ",
        "outputId": "fd2a5844-4f1e-45af-c06b-16a9fc7032a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1084"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(split0['X_train'])-int(len(split0['X_train'])*0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bHc8yy3Njni"
      },
      "outputs": [],
      "source": [
        "def map_func_only_X(val_dictionary, labels):\n",
        "  return {'input_ids': val_dictionary['input_ids'], 'attention_mask':val_dictionary['attention_mask']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n1WkoHFZc9H"
      },
      "outputs": [],
      "source": [
        "def map_func_only_y(val_dictionary, labels):\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-VGMZy5bRfN"
      },
      "outputs": [],
      "source": [
        "VAL_SIZE=1088"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZDVrP0QYC_n",
        "outputId": "6d254963-aca7-4b97-a33c-8689f2cdb4e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10832"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counter = Counter(split0['y_train'])\n",
        "SUM=0\n",
        "for item in list(counter.values()) :\n",
        "  SUM+=item\n",
        "#SUM = sum(counter.values())\n",
        "SUM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbDe9DVFAvjP",
        "outputId": "dcd74859-bb21-4d34-c2ac-b80606314df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({4: 4143, 7: 1159, 9: 1030, 3: 865, 6: 783, 0: 763, 1: 690, 8: 556, 2: 537, 5: 306})\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{4: 0.2614530533429882,\n",
              " 9: 1.051650485436893,\n",
              " 6: 1.383397190293742,\n",
              " 2: 2.0171322160148977,\n",
              " 0: 1.4196592398427261,\n",
              " 7: 0.9345987920621226,\n",
              " 1: 1.569855072463768,\n",
              " 5: 3.539869281045752,\n",
              " 8: 1.948201438848921,\n",
              " 3: 1.2522543352601156}"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Tutorial\n",
        "#weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "#weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "\n",
        "counter = Counter(split0['y_train'])\n",
        "my_weight2 = {}\n",
        "print(counter)\n",
        "\n",
        "for genre in counter:\n",
        "  #print(genre, counter[genre])\n",
        "  my_weight2[genre] = (1/counter[genre]) * (SUM/10)\n",
        "my_weight2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLARPbncyjEw"
      },
      "source": [
        "### Parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfijuZDLR0bc",
        "outputId": "bf64dca6-a495-4327-a0bf-9cab08ce878c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2708"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TEST_SIZE=len(split0['y_test'])\n",
        "TEST_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "165cdb4cb82044319ba7d11e095e1bb5",
            "c86eb452882d48b09ff9b0dbf3ccf7f4",
            "b0612c2880f14fd1a409489f5a9e27f6",
            "8df57050db29456a849bfba6f7176afa",
            "06bcef83f932418aa708baf469d9264d",
            "7d5720dce23c4f78b35d23695397498d",
            "92303b847b0c4c4f8e3982b0825006e2",
            "1305e76e3aba4dd6884f17d1eeac2521",
            "0aadba53b9344cf28420d825097d8706",
            "828d2b52949e4e91966e47c25932e99d",
            "b064c72cb7014010bc21b01f2aa233da",
            "bb9b977be1cd47228e59e249a3b7b1b0",
            "06b22f1dbcdc4e4598de8fbc481e62d6",
            "14bd8e6dfbaa4e8b8650f2fb82872485",
            "b03a52b26016434aad7fb5f20aab53eb",
            "bbc15d90748a43faa2a9e7d9246d3459",
            "d2da1ecf229d4816a9a62f123c6c656b",
            "5491d62ff68b4b5795642e8df264f3d8",
            "1b6fe1a0ecec414eafcb4080ae38de9d",
            "f7275c390c9c4c5fa8cf13ee3bf68dfc",
            "8ad2bc152e6e48628ceff2a83505818b",
            "eb724856fa854a6fb3c0cb77c09c79fb"
          ]
        },
        "id": "QKF0fs_C8g_k",
        "outputId": "a8e1a954-2956-47e4-d73f-114001145d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10832,) (2708,)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "165cdb4cb82044319ba7d11e095e1bb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/779k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb9b977be1cd47228e59e249a3b7b1b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xids_train.shape, Xids_test.shape:  (10832, 768) (2708, 768)\n"
          ]
        }
      ],
      "source": [
        "from transformers import XLNetLMHeadModel, XLNetTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[0]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "\n",
        "SEQ_LEN=768\n",
        "SEQ_LEN2=768\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(4)\n",
        "\n",
        "DS_LEN=len(dataset_train)\n",
        "SPLIT=0.9\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz7SP-mQXnnk"
      },
      "outputs": [],
      "source": [
        "McNemar={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c4a7d83637f9426eb59873faa506f0f5",
            "fed7359c01a242958f16286bb9265cd9",
            "5a3ca785b23b4902a9b131b35535fb6a",
            "af464a9ae30947d4a8433fd402e2338e",
            "699f1c785e2e440aa3da9187c78cd503",
            "4e2925be3236401a8734f0efe7aa4f49",
            "9b2f83b1bc7c4dcfa03b371c66523f1d",
            "65d704982ce1489d8b428f1f01953b9b",
            "af1de15c65c94c828999471f5c4f05cf",
            "8f4341b1229f4217806f24eb29726d29",
            "c65d75c08a4a401ebee0495a385d2c06"
          ]
        },
        "id": "bEMPSMEKym_P",
        "outputId": "e34516e3-eaf4-4128-aa38-06c3ef1f857f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4a7d83637f9426eb59873faa506f0f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/539M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model (TFXLNetModel)  TFXLNetModelOutput(  116718336   ['input_ids[0][0]',              \n",
            "                                last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tfxl_net_model[0][0]']         \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32)          128         ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 32)           0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 955s 387ms/step - loss: 2.3277 - categorical_accuracy: 0.1718 - val_loss: 2.3879 - val_categorical_accuracy: 0.1937\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 941s 386ms/step - loss: 2.1048 - categorical_accuracy: 0.2414 - val_loss: 2.4364 - val_categorical_accuracy: 0.1513\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 941s 386ms/step - loss: 2.0645 - categorical_accuracy: 0.2432 - val_loss: 3.5316 - val_categorical_accuracy: 0.1098\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 941s 386ms/step - loss: 2.0522 - categorical_accuracy: 0.2500 - val_loss: 2.5196 - val_categorical_accuracy: 0.1144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.08      0.11       190\n",
            "         1.0       0.21      0.09      0.13       173\n",
            "         2.0       0.10      0.01      0.01       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.61      0.05      0.09      1036\n",
            "         5.0       0.09      0.04      0.06        76\n",
            "         6.0       0.09      0.99      0.17       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       1.00      0.01      0.01       139\n",
            "         9.0       0.16      0.15      0.16       258\n",
            "\n",
            "    accuracy                           0.12      2708\n",
            "   macro avg       0.24      0.14      0.07      2708\n",
            "weighted avg       0.34      0.12      0.08      2708\n",
            "\n",
            "0.14231380435725033\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2437/2437 [==============================] - 2934s 1s/step - loss: 2.0440 - categorical_accuracy: 0.2421 - val_loss: 15.6274 - val_categorical_accuracy: 0.0710\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 2918s 1s/step - loss: 1.9965 - categorical_accuracy: 0.2548 - val_loss: 13.7981 - val_categorical_accuracy: 0.0683\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 2918s 1s/step - loss: 1.9685 - categorical_accuracy: 0.2563 - val_loss: 16.2683 - val_categorical_accuracy: 0.0867\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 2918s 1s/step - loss: 1.9111 - categorical_accuracy: 0.2735 - val_loss: 9.3672 - val_categorical_accuracy: 0.1476\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 2918s 1s/step - loss: 1.8826 - categorical_accuracy: 0.2658 - val_loss: 11.4877 - val_categorical_accuracy: 0.0729\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 2918s 1s/step - loss: 1.8912 - categorical_accuracy: 0.2638 - val_loss: 13.5491 - val_categorical_accuracy: 0.0812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.03      0.99      0.06        76\n",
            "         6.0       0.82      0.77      0.80       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.00      0.00      0.00       258\n",
            "\n",
            "    accuracy                           0.08      2708\n",
            "   macro avg       0.09      0.18      0.09      2708\n",
            "weighted avg       0.06      0.08      0.06      2708\n",
            "\n",
            "0.17560728744939272\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_1 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['tfxl_net_model_1[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          98432       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_76 (Dropout)           (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           4128        ['dropout_76[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32)          128         ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_77 (Dropout)           (None, 32)           0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_77[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 956s 388ms/step - loss: 2.3444 - categorical_accuracy: 0.1676 - val_loss: 2.8202 - val_categorical_accuracy: 0.1375\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 942s 386ms/step - loss: 2.1042 - categorical_accuracy: 0.2291 - val_loss: 3.0034 - val_categorical_accuracy: 0.1052\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 941s 386ms/step - loss: 2.0687 - categorical_accuracy: 0.2273 - val_loss: 3.7997 - val_categorical_accuracy: 0.1006\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 942s 387ms/step - loss: 2.0290 - categorical_accuracy: 0.2442 - val_loss: 2.9147 - val_categorical_accuracy: 0.1467\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 942s 386ms/step - loss: 2.0211 - categorical_accuracy: 0.2598 - val_loss: 2.2581 - val_categorical_accuracy: 0.2168\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 942s 387ms/step - loss: 2.0216 - categorical_accuracy: 0.2508 - val_loss: 3.9335 - val_categorical_accuracy: 0.0959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.07      0.09       190\n",
            "         1.0       0.33      0.03      0.05       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.25      0.00      0.01       216\n",
            "         4.0       0.62      0.07      0.13      1036\n",
            "         5.0       0.30      0.09      0.14        76\n",
            "         6.0       0.08      1.00      0.15       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.25      0.01      0.01       139\n",
            "         9.0       0.28      0.03      0.06       258\n",
            "\n",
            "    accuracy                           0.11      2708\n",
            "   macro avg       0.22      0.13      0.06      2708\n",
            "weighted avg       0.34      0.11      0.08      2708\n",
            "\n",
            "0.1302722996528771\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_1/transformer/mask_emb:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_1/transformer/mask_emb:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2437/2437 [==============================] - 2936s 1s/step - loss: 1.9956 - categorical_accuracy: 0.2699 - val_loss: 3.7042 - val_categorical_accuracy: 0.1172\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 2920s 1s/step - loss: 1.9796 - categorical_accuracy: 0.2707 - val_loss: 3.5604 - val_categorical_accuracy: 0.1227\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 2919s 1s/step - loss: 1.9726 - categorical_accuracy: 0.2717 - val_loss: 3.9591 - val_categorical_accuracy: 0.0923\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 2919s 1s/step - loss: 1.9550 - categorical_accuracy: 0.2748 - val_loss: 2.7125 - val_categorical_accuracy: 0.1577\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 2919s 1s/step - loss: 1.9615 - categorical_accuracy: 0.2664 - val_loss: 2.3468 - val_categorical_accuracy: 0.1900\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 2919s 1s/step - loss: 1.9516 - categorical_accuracy: 0.2705 - val_loss: 2.5830 - val_categorical_accuracy: 0.1587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.20      0.14       190\n",
            "         1.0       0.33      0.20      0.25       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.23      0.07      0.11       216\n",
            "         4.0       0.63      0.04      0.07      1036\n",
            "         5.0       0.07      0.30      0.11        76\n",
            "         6.0       0.14      0.97      0.24       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.19      0.17      0.18       139\n",
            "         9.0       0.24      0.26      0.25       258\n",
            "\n",
            "    accuracy                           0.16      2708\n",
            "   macro avg       0.19      0.22      0.14      2708\n",
            "weighted avg       0.33      0.16      0.11      2708\n",
            "\n",
            "0.22201906086712864\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_2 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 768)         0           ['tfxl_net_model_2[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          98432       ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128)         512         ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_115 (Dropout)          (None, 128)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 32)           4128        ['dropout_115[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32)          128         ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_116 (Dropout)          (None, 32)           0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_116[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 955s 387ms/step - loss: 2.7367 - categorical_accuracy: 0.1264 - val_loss: 2.6515 - val_categorical_accuracy: 0.2168\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 941s 386ms/step - loss: 2.4594 - categorical_accuracy: 0.1606 - val_loss: 2.9213 - val_categorical_accuracy: 0.1208\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 941s 386ms/step - loss: 2.3506 - categorical_accuracy: 0.1689 - val_loss: 2.5087 - val_categorical_accuracy: 0.1836\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 942s 386ms/step - loss: 2.2625 - categorical_accuracy: 0.1846 - val_loss: 2.5384 - val_categorical_accuracy: 0.1365\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.04      0.06       190\n",
            "         1.0       0.12      0.05      0.07       173\n",
            "         2.0       0.50      0.01      0.01       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.48      0.17      0.25      1036\n",
            "         5.0       0.33      0.01      0.03        76\n",
            "         6.0       0.09      0.99      0.17       195\n",
            "         7.0       0.24      0.02      0.03       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.09      0.03      0.05       258\n",
            "\n",
            "    accuracy                           0.15      2708\n",
            "   macro avg       0.20      0.13      0.07      2708\n",
            "weighted avg       0.28      0.15      0.13      2708\n",
            "\n",
            "0.13105618218847193\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000/2437 [=======================>......] - ETA: 8:28 - loss: 2.3144 - categorical_accuracy: 0.1700"
          ]
        }
      ],
      "source": [
        "from transformers import TFXLNetModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.2\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    checkpoint_filepath = DIR + 'checkpoints'\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True\n",
        "                                                  , monitor='val_categorical_accuracy', save_best_only=False)#, mode='max'\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping, model_checkpoint_callback])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6335406064ce4698a6bb0cc86c04fde0",
            "911bcfae1b0e4067a2e09c36b3580fb9",
            "8e7efdb0fc5742459dae1c35dd3af3a2",
            "05e4551b5c31404aa62bf864e9b64e79",
            "df6f4681101c420baa838f2f363c6df4",
            "bec54ae0c6224d8581a28e5bfaf75f44",
            "c352729952e64fe5b1e082fa7a1d1855",
            "700a9603018e45b18c9aa621cec44874",
            "12db1e83cf00483bb6790cf184bb3b7a",
            "7cf785ae86c04f6690b479b9b891ef98",
            "5988796af7964979b50aa7281a9b46b7"
          ]
        },
        "id": "nG8ttcLRYHb9",
        "outputId": "78a73e37-04d2-4ba2-a468-22b82280e6b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6335406064ce4698a6bb0cc86c04fde0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/539M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model (TFXLNetModel)  TFXLNetModelOutput(  116718336   ['input_ids[0][0]',              \n",
            "                                last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tfxl_net_model[0][0]']         \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 128)         512         ['dense[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 128)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32)          128         ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_38 (Dropout)           (None, 32)           0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_38[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 500s 200ms/step - loss: 2.4151 - categorical_accuracy: 0.1609 - val_loss: 3.3193 - val_categorical_accuracy: 0.0987\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 486s 199ms/step - loss: 2.1211 - categorical_accuracy: 0.2162 - val_loss: 2.7018 - val_categorical_accuracy: 0.1190\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 485s 199ms/step - loss: 2.0818 - categorical_accuracy: 0.2423 - val_loss: 2.7864 - val_categorical_accuracy: 0.1208\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 485s 199ms/step - loss: 2.0503 - categorical_accuracy: 0.2534 - val_loss: 2.1413 - val_categorical_accuracy: 0.1780\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 485s 199ms/step - loss: 2.0267 - categorical_accuracy: 0.2591 - val_loss: 2.3978 - val_categorical_accuracy: 0.1365\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 486s 199ms/step - loss: 2.0312 - categorical_accuracy: 0.2450 - val_loss: 2.0874 - val_categorical_accuracy: 0.2085\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.19      0.17       190\n",
            "         1.0       0.33      0.02      0.04       173\n",
            "         2.0       0.33      0.01      0.01       135\n",
            "         3.0       0.25      0.01      0.03       216\n",
            "         4.0       0.58      0.12      0.20      1036\n",
            "         5.0       0.28      0.11      0.15        76\n",
            "         6.0       0.22      0.96      0.35       195\n",
            "         7.0       0.15      0.01      0.03       290\n",
            "         8.0       0.10      0.08      0.09       139\n",
            "         9.0       0.13      0.58      0.21       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.25      0.21      0.13      2708\n",
            "weighted avg       0.35      0.20      0.15      2708\n",
            "\n",
            "0.21035017612714352\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2437/2437 [==============================] - 1726s 702ms/step - loss: 2.0378 - categorical_accuracy: 0.2391 - val_loss: 3.1614 - val_categorical_accuracy: 0.1577\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 1709s 701ms/step - loss: 1.9646 - categorical_accuracy: 0.2573 - val_loss: 16.1496 - val_categorical_accuracy: 0.0517\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 1710s 701ms/step - loss: 1.9279 - categorical_accuracy: 0.2680 - val_loss: 11.6222 - val_categorical_accuracy: 0.0701\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 1710s 702ms/step - loss: 1.9098 - categorical_accuracy: 0.2625 - val_loss: 16.3768 - val_categorical_accuracy: 0.0517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.60      0.07      0.12       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       1.00      0.01      0.03        76\n",
            "         6.0       0.00      0.00      0.00       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.05      1.00      0.10       139\n",
            "         9.0       0.00      0.00      0.00       258\n",
            "\n",
            "    accuracy                           0.06      2708\n",
            "   macro avg       0.17      0.11      0.02      2708\n",
            "weighted avg       0.07      0.06      0.01      2708\n",
            "\n",
            "0.1082522056586553\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_1 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['tfxl_net_model_1[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          98432       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_76 (Dropout)           (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           4128        ['dropout_76[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32)          128         ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_77 (Dropout)           (None, 32)           0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_77[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 498s 200ms/step - loss: 2.3729 - categorical_accuracy: 0.1664 - val_loss: 3.7199 - val_categorical_accuracy: 0.0830\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 486s 199ms/step - loss: 2.1279 - categorical_accuracy: 0.2234 - val_loss: 3.1554 - val_categorical_accuracy: 0.1744\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 486s 199ms/step - loss: 2.0719 - categorical_accuracy: 0.2320 - val_loss: 3.6307 - val_categorical_accuracy: 0.1125\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 486s 199ms/step - loss: 2.0582 - categorical_accuracy: 0.2358 - val_loss: 2.3574 - val_categorical_accuracy: 0.2177\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 485s 199ms/step - loss: 2.0360 - categorical_accuracy: 0.2487 - val_loss: 3.4279 - val_categorical_accuracy: 0.1070\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 485s 199ms/step - loss: 2.0271 - categorical_accuracy: 0.2497 - val_loss: 2.6924 - val_categorical_accuracy: 0.1596\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.14      0.14       190\n",
            "         1.0       0.30      0.06      0.10       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.56      0.18      0.27      1036\n",
            "         5.0       1.00      0.03      0.05        76\n",
            "         6.0       0.10      0.98      0.18       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.18      0.14      0.16       258\n",
            "\n",
            "    accuracy                           0.17      2708\n",
            "   macro avg       0.23      0.15      0.09      2708\n",
            "weighted avg       0.29      0.17      0.15      2708\n",
            "\n",
            "0.15328221867396633\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_1/transformer/mask_emb:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_1/transformer/mask_emb:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2437/2437 [==============================] - 1728s 703ms/step - loss: 1.9925 - categorical_accuracy: 0.2645 - val_loss: 3.2273 - val_categorical_accuracy: 0.1024\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 1712s 703ms/step - loss: 1.9688 - categorical_accuracy: 0.2696 - val_loss: 2.7007 - val_categorical_accuracy: 0.1227\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 1710s 702ms/step - loss: 1.9725 - categorical_accuracy: 0.2617 - val_loss: 3.2317 - val_categorical_accuracy: 0.0941\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 1710s 702ms/step - loss: 1.9549 - categorical_accuracy: 0.2704 - val_loss: 3.2687 - val_categorical_accuracy: 0.0959\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 1710s 702ms/step - loss: 1.9584 - categorical_accuracy: 0.2631 - val_loss: 3.2880 - val_categorical_accuracy: 0.0876\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.10      0.12       190\n",
            "         1.0       0.34      0.13      0.18       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.50      0.00      0.01       216\n",
            "         4.0       0.92      0.01      0.02      1036\n",
            "         5.0       0.75      0.04      0.07        76\n",
            "         6.0       0.08      1.00      0.15       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.26      0.08      0.12       258\n",
            "\n",
            "    accuracy                           0.10      2708\n",
            "   macro avg       0.30      0.14      0.07      2708\n",
            "weighted avg       0.48      0.10      0.05      2708\n",
            "\n",
            "0.13603733353259323\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_2 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 768)         0           ['tfxl_net_model_2[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          98432       ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128)         512         ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_115 (Dropout)          (None, 128)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 32)           4128        ['dropout_115[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32)          128         ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_116 (Dropout)          (None, 32)           0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_116[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 498s 200ms/step - loss: 2.8925 - categorical_accuracy: 0.1102 - val_loss: 3.8861 - val_categorical_accuracy: 0.1042\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 485s 199ms/step - loss: 2.5860 - categorical_accuracy: 0.1366 - val_loss: 3.2704 - val_categorical_accuracy: 0.1015\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 485s 199ms/step - loss: 2.4589 - categorical_accuracy: 0.1492 - val_loss: 3.2974 - val_categorical_accuracy: 0.0803\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 485s 199ms/step - loss: 2.3462 - categorical_accuracy: 0.1704 - val_loss: 3.9045 - val_categorical_accuracy: 0.0803\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.50      0.01      0.01       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.33      0.00      0.01       216\n",
            "         4.0       0.40      0.00      0.00      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.07      1.00      0.14       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.15      0.03      0.05       258\n",
            "\n",
            "    accuracy                           0.08      2708\n",
            "   macro avg       0.15      0.10      0.02      2708\n",
            "weighted avg       0.23      0.08      0.02      2708\n",
            "\n",
            "0.10433482303189254\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2437/2437 [==============================] - 1727s 702ms/step - loss: 2.4221 - categorical_accuracy: 0.1344 - val_loss: 35.1660 - val_categorical_accuracy: 0.0710\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 1710s 702ms/step - loss: 2.5697 - categorical_accuracy: 0.1016 - val_loss: 57.0783 - val_categorical_accuracy: 0.0710\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 1710s 702ms/step - loss: 2.5697 - categorical_accuracy: 0.1001 - val_loss: 40.9827 - val_categorical_accuracy: 0.0720\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 1710s 702ms/step - loss: 2.5500 - categorical_accuracy: 0.1000 - val_loss: 38.4891 - val_categorical_accuracy: 0.0701\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 1711s 702ms/step - loss: 2.5616 - categorical_accuracy: 0.1009 - val_loss: 32.6773 - val_categorical_accuracy: 0.0720\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 1713s 703ms/step - loss: 2.5461 - categorical_accuracy: 0.1036 - val_loss: 81.7926 - val_categorical_accuracy: 0.0701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.07      1.00      0.13       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.00      0.00      0.00       258\n",
            "\n",
            "    accuracy                           0.07      2708\n",
            "   macro avg       0.01      0.10      0.01      2708\n",
            "weighted avg       0.01      0.07      0.01      2708\n",
            "\n",
            "0.1\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_3 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Global  (None, 768)         0           ['tfxl_net_model_3[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          98432       ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 128)         512         ['dense_6[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_154 (Dropout)          (None, 128)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 32)           4128        ['dropout_154[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32)          128         ['dense_7[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_155 (Dropout)          (None, 32)           0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_155[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 507s 203ms/step - loss: 2.8274 - categorical_accuracy: 0.1109 - val_loss: 3.0457 - val_categorical_accuracy: 0.1052\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 494s 203ms/step - loss: 2.5642 - categorical_accuracy: 0.1319 - val_loss: 2.7108 - val_categorical_accuracy: 0.1661\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 495s 203ms/step - loss: 2.4220 - categorical_accuracy: 0.1465 - val_loss: 2.3558 - val_categorical_accuracy: 0.1836\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 499s 205ms/step - loss: 2.3249 - categorical_accuracy: 0.1579 - val_loss: 2.2117 - val_categorical_accuracy: 0.2251\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 497s 204ms/step - loss: 2.2521 - categorical_accuracy: 0.1759 - val_loss: 2.0787 - val_categorical_accuracy: 0.2721\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 497s 204ms/step - loss: 2.2081 - categorical_accuracy: 0.1912 - val_loss: 2.4185 - val_categorical_accuracy: 0.1550\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.41      0.19       190\n",
            "         1.0       0.19      0.13      0.15       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.60      0.10      0.17      1036\n",
            "         5.0       0.13      0.09      0.11        76\n",
            "         6.0       0.13      0.96      0.23       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.14      0.02      0.04       139\n",
            "         9.0       0.16      0.17      0.16       258\n",
            "\n",
            "    accuracy                           0.16      2708\n",
            "   macro avg       0.15      0.19      0.10      2708\n",
            "weighted avg       0.29      0.16      0.12      2708\n",
            "\n",
            "0.1878676270112449\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_3/transformer/mask_emb:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_3/transformer/mask_emb:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2437/2437 [==============================] - 1738s 707ms/step - loss: 2.1887 - categorical_accuracy: 0.1947 - val_loss: 2.4011 - val_categorical_accuracy: 0.1614\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 1720s 706ms/step - loss: 2.2143 - categorical_accuracy: 0.1808 - val_loss: 2.3591 - val_categorical_accuracy: 0.1485\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 1721s 706ms/step - loss: 2.1973 - categorical_accuracy: 0.1867 - val_loss: 2.4682 - val_categorical_accuracy: 0.1448\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 1722s 707ms/step - loss: 2.3465 - categorical_accuracy: 0.1444 - val_loss: 3.4109 - val_categorical_accuracy: 0.0895\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.07      0.82      0.14       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       1.00      0.00      0.01       216\n",
            "         4.0       0.37      0.02      0.04      1036\n",
            "         5.0       0.07      0.01      0.02        76\n",
            "         6.0       0.12      0.32      0.18       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.20      0.01      0.01       258\n",
            "\n",
            "    accuracy                           0.09      2708\n",
            "   macro avg       0.18      0.12      0.04      2708\n",
            "weighted avg       0.25      0.09      0.04      2708\n",
            "\n",
            "0.11857763331141544\n",
            "----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFXLNetModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.3\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    checkpoint_filepath = DIR + 'checkpoints'\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True\n",
        "                                                  , monitor='val_categorical_accuracy', save_best_only=False)#, mode='max'\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping, model_checkpoint_callback])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UlFJyHsDT2W",
        "outputId": "3c018e51-a032-483b-b3fc-8d01b70b378a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_4 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_4 (Global  (None, 768)         0           ['tfxl_net_model_4[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 768)         3072        ['global_max_pooling1d_4[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          98432       ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128)         512         ['dense_8[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_193 (Dropout)          (None, 128)          0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 32)           4128        ['dropout_193[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32)          128         ['dense_9[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_194 (Dropout)          (None, 32)           0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_194[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 511s 205ms/step - loss: 2.4376 - categorical_accuracy: 0.1524 - val_loss: 3.5878 - val_categorical_accuracy: 0.0738\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 497s 204ms/step - loss: 2.1629 - categorical_accuracy: 0.2130 - val_loss: 2.7578 - val_categorical_accuracy: 0.1245\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 498s 204ms/step - loss: 2.1030 - categorical_accuracy: 0.2382 - val_loss: 3.6020 - val_categorical_accuracy: 0.1006\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 497s 204ms/step - loss: 2.0764 - categorical_accuracy: 0.2461 - val_loss: 2.5967 - val_categorical_accuracy: 0.1236\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 497s 204ms/step - loss: 2.0602 - categorical_accuracy: 0.2357 - val_loss: 2.2398 - val_categorical_accuracy: 0.1605\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 496s 204ms/step - loss: 2.0709 - categorical_accuracy: 0.2389 - val_loss: 2.0603 - val_categorical_accuracy: 0.2168\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.44      0.23       190\n",
            "         1.0       0.40      0.02      0.04       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.07      0.02      0.03       216\n",
            "         4.0       0.59      0.15      0.23      1036\n",
            "         5.0       0.24      0.16      0.19        76\n",
            "         6.0       0.25      0.93      0.40       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.13      0.55      0.22       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.19      0.23      0.13      2708\n",
            "weighted avg       0.31      0.21      0.17      2708\n",
            "\n",
            "0.22749897007794578\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_4/transformer/mask_emb:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_4/transformer/mask_emb:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2437/2437 [==============================] - 1736s 706ms/step - loss: 2.0440 - categorical_accuracy: 0.2287 - val_loss: 3.5079 - val_categorical_accuracy: 0.1458\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 1720s 706ms/step - loss: 2.0329 - categorical_accuracy: 0.2337 - val_loss: 14.9063 - val_categorical_accuracy: 0.1541\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 1721s 706ms/step - loss: 1.9825 - categorical_accuracy: 0.2504 - val_loss: 8.6482 - val_categorical_accuracy: 0.1522\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 1721s 706ms/step - loss: 1.9711 - categorical_accuracy: 0.2612 - val_loss: 13.4391 - val_categorical_accuracy: 0.0701\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 1721s 706ms/step - loss: 1.9536 - categorical_accuracy: 0.2442 - val_loss: 7.5646 - val_categorical_accuracy: 0.1494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.43      0.04      0.07        76\n",
            "         6.0       0.85      0.70      0.77       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.10      0.98      0.18       258\n",
            "\n",
            "    accuracy                           0.15      2708\n",
            "   macro avg       0.14      0.17      0.10      2708\n",
            "weighted avg       0.08      0.15      0.07      2708\n",
            "\n",
            "0.17226579418133886\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_5 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_5 (Global  (None, 768)         0           ['tfxl_net_model_5[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 768)         3072        ['global_max_pooling1d_5[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 128)          98432       ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 128)         512         ['dense_10[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_232 (Dropout)          (None, 128)          0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 32)           4128        ['dropout_232[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 32)          128         ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_233 (Dropout)          (None, 32)           0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_233[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 512s 205ms/step - loss: 2.4376 - categorical_accuracy: 0.1566 - val_loss: 2.9213 - val_categorical_accuracy: 0.0886\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 498s 204ms/step - loss: 2.1615 - categorical_accuracy: 0.2079 - val_loss: 2.9314 - val_categorical_accuracy: 0.0950\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 493s 202ms/step - loss: 2.0949 - categorical_accuracy: 0.2258 - val_loss: 2.8561 - val_categorical_accuracy: 0.1264\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 490s 201ms/step - loss: 2.0790 - categorical_accuracy: 0.2284 - val_loss: 2.1306 - val_categorical_accuracy: 0.1550\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 489s 201ms/step - loss: 2.0524 - categorical_accuracy: 0.2443 - val_loss: 2.7716 - val_categorical_accuracy: 0.1208\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 489s 201ms/step - loss: 2.0564 - categorical_accuracy: 0.2425 - val_loss: 2.5883 - val_categorical_accuracy: 0.1208\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.02      0.03       190\n",
            "         1.0       0.26      0.05      0.08       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.53      0.01      0.02      1036\n",
            "         5.0       0.28      0.07      0.11        76\n",
            "         6.0       0.12      0.98      0.21       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.11      0.42      0.17       258\n",
            "\n",
            "    accuracy                           0.12      2708\n",
            "   macro avg       0.15      0.15      0.06      2708\n",
            "weighted avg       0.26      0.12      0.05      2708\n",
            "\n",
            "0.1543604985392577\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_5/transformer/mask_emb:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_5/transformer/mask_emb:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2332/2437 [===========================>..] - ETA: 1:12 - loss: 2.0250 - categorical_accuracy: 0.2639"
          ]
        }
      ],
      "source": [
        "from transformers import TFXLNetModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.4\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    checkpoint_filepath = DIR + 'checkpoints'\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True\n",
        "                                                  , monitor='val_categorical_accuracy', save_best_only=False)#, mode='max'\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping, model_checkpoint_callback])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGGqqLa0hGKg"
      },
      "outputs": [],
      "source": [
        "from transformers import TFXLNetModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    checkpoint_filepath = DIR + 'checkpoints'\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True\n",
        "                                                  , monitor='val_categorical_accuracy', save_best_only=False)#, mode='max'\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping, model_checkpoint_callback])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d9aNY0dPvQA"
      },
      "outputs": [],
      "source": [
        "#how to use checkpoint model\n",
        "#model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBTL8GPD1zLm"
      },
      "source": [
        "### Try smaller learning rate only transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-ax2lUm2CZz"
      },
      "outputs": [],
      "source": [
        "McNemar={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y63Cb5F11QC",
        "outputId": "349890df-ea55-4199-ed56-7002f4371bb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  1e-06 drop_out_rate: 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_1 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['tfxl_net_model_1[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          98432       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 128)         512         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_76 (Dropout)           (None, 128)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           4128        ['dropout_76[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32)          128         ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_77 (Dropout)           (None, 32)           0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_77[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 961s 389ms/step - loss: 3.0384 - categorical_accuracy: 0.1084 - val_loss: 3.7783 - val_categorical_accuracy: 0.0803\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 943s 387ms/step - loss: 3.0738 - categorical_accuracy: 0.1017 - val_loss: 3.5711 - val_categorical_accuracy: 0.0895\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 945s 388ms/step - loss: 3.0321 - categorical_accuracy: 0.1041 - val_loss: 3.5829 - val_categorical_accuracy: 0.0895\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 944s 387ms/step - loss: 3.0066 - categorical_accuracy: 0.1125 - val_loss: 3.5922 - val_categorical_accuracy: 0.0932\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 945s 388ms/step - loss: 3.0481 - categorical_accuracy: 0.1015 - val_loss: 3.6320 - val_categorical_accuracy: 0.0867\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.0346 - categorical_accuracy: 0.1071 - val_loss: 3.5457 - val_categorical_accuracy: 0.0959\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.12      0.04      0.06       173\n",
            "         2.0       0.03      0.01      0.02       135\n",
            "         3.0       0.09      0.30      0.14       216\n",
            "         4.0       0.33      0.01      0.03      1036\n",
            "         5.0       0.05      0.01      0.02        76\n",
            "         6.0       0.11      0.57      0.18       195\n",
            "         7.0       0.11      0.14      0.12       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.11      0.15      0.12       258\n",
            "\n",
            "    accuracy                           0.10      2708\n",
            "   macro avg       0.09      0.12      0.07      2708\n",
            "weighted avg       0.17      0.10      0.07      2708\n",
            "\n",
            "0.12409830683456535\n",
            "learning_rate_transfer_learning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_2 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 768)         0           ['tfxl_net_model_2[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          98432       ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128)         512         ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_115 (Dropout)          (None, 128)          0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 32)           4128        ['dropout_115[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32)          128         ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dropout_116 (Dropout)          (None, 32)           0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_116[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 965s 390ms/step - loss: 3.1055 - categorical_accuracy: 0.1016 - val_loss: 3.5723 - val_categorical_accuracy: 0.0710\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 947s 389ms/step - loss: 3.1224 - categorical_accuracy: 0.1017 - val_loss: 3.5973 - val_categorical_accuracy: 0.0729\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 947s 389ms/step - loss: 3.0816 - categorical_accuracy: 0.1047 - val_loss: 3.5828 - val_categorical_accuracy: 0.0775\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 947s 389ms/step - loss: 3.1018 - categorical_accuracy: 0.1008 - val_loss: 3.4855 - val_categorical_accuracy: 0.0720\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 948s 389ms/step - loss: 3.0707 - categorical_accuracy: 0.1014 - val_loss: 3.4815 - val_categorical_accuracy: 0.0803\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 948s 389ms/step - loss: 3.0909 - categorical_accuracy: 0.1040 - val_loss: 3.3553 - val_categorical_accuracy: 0.0793\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.06      0.07       190\n",
            "         1.0       0.08      0.29      0.12       173\n",
            "         2.0       0.04      0.19      0.07       135\n",
            "         3.0       0.06      0.10      0.08       216\n",
            "         4.0       0.37      0.01      0.03      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.11      0.06      0.08       195\n",
            "         7.0       0.14      0.07      0.09       290\n",
            "         8.0       0.08      0.22      0.11       139\n",
            "         9.0       0.09      0.10      0.10       258\n",
            "\n",
            "    accuracy                           0.08      2708\n",
            "   macro avg       0.10      0.11      0.07      2708\n",
            "weighted avg       0.19      0.08      0.06      2708\n",
            "\n",
            "0.11033694906437426\n",
            "learning_rate_transfer_learning:  1e-06 drop_out_rate: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_3 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Global  (None, 768)         0           ['tfxl_net_model_3[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          98432       ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 128)         512         ['dense_6[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_154 (Dropout)          (None, 128)          0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 32)           4128        ['dropout_154[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32)          128         ['dense_7[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_155 (Dropout)          (None, 32)           0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_155[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 964s 389ms/step - loss: 3.2667 - categorical_accuracy: 0.0984 - val_loss: 3.0720 - val_categorical_accuracy: 0.1310\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 944s 387ms/step - loss: 3.2607 - categorical_accuracy: 0.1050 - val_loss: 3.0884 - val_categorical_accuracy: 0.1273\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 943s 387ms/step - loss: 3.2518 - categorical_accuracy: 0.1068 - val_loss: 3.0777 - val_categorical_accuracy: 0.1292\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 945s 388ms/step - loss: 3.2410 - categorical_accuracy: 0.1025 - val_loss: 3.0055 - val_categorical_accuracy: 0.1384\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.2371 - categorical_accuracy: 0.1013 - val_loss: 3.0849 - val_categorical_accuracy: 0.1245\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 947s 389ms/step - loss: 3.2284 - categorical_accuracy: 0.1026 - val_loss: 3.0589 - val_categorical_accuracy: 0.1236\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.05      0.08       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.10      0.18      0.12       216\n",
            "         4.0       0.34      0.22      0.27      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.05      0.34      0.08       195\n",
            "         7.0       0.16      0.03      0.05       290\n",
            "         8.0       0.07      0.03      0.04       139\n",
            "         9.0       0.67      0.01      0.02       258\n",
            "\n",
            "    accuracy                           0.13      2708\n",
            "   macro avg       0.15      0.09      0.07      2708\n",
            "weighted avg       0.24      0.13      0.13      2708\n",
            "\n",
            "0.0851211386710367\n",
            "learning_rate_transfer_learning:  1e-06 drop_out_rate: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_4 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_4 (Global  (None, 768)         0           ['tfxl_net_model_4[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 768)         3072        ['global_max_pooling1d_4[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          98432       ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 128)         512         ['dense_8[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_193 (Dropout)          (None, 128)          0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 32)           4128        ['dropout_193[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32)          128         ['dense_9[0][0]']                \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_194 (Dropout)          (None, 32)           0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dropout_194[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,938\n",
            "Trainable params: 104,746\n",
            "Non-trainable params: 116,720,192\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 965s 390ms/step - loss: 3.3961 - categorical_accuracy: 0.1002 - val_loss: 2.7466 - val_categorical_accuracy: 0.1162\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.4001 - categorical_accuracy: 0.1024 - val_loss: 2.7075 - val_categorical_accuracy: 0.1236\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 947s 388ms/step - loss: 3.3744 - categorical_accuracy: 0.1024 - val_loss: 2.7736 - val_categorical_accuracy: 0.1135\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 947s 388ms/step - loss: 3.3828 - categorical_accuracy: 0.1015 - val_loss: 2.7965 - val_categorical_accuracy: 0.1042\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 947s 389ms/step - loss: 3.3409 - categorical_accuracy: 0.1104 - val_loss: 2.7166 - val_categorical_accuracy: 0.1172\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.07      0.08      0.07       190\n",
            "         1.0       0.06      0.24      0.10       173\n",
            "         2.0       0.06      0.01      0.01       135\n",
            "         3.0       0.11      0.01      0.02       216\n",
            "         4.0       0.42      0.17      0.24      1036\n",
            "         5.0       0.03      0.04      0.04        76\n",
            "         6.0       0.07      0.22      0.10       195\n",
            "         7.0       0.12      0.17      0.14       290\n",
            "         8.0       0.02      0.01      0.02       139\n",
            "         9.0       0.11      0.05      0.06       258\n",
            "\n",
            "    accuracy                           0.13      2708\n",
            "   macro avg       0.11      0.10      0.08      2708\n",
            "weighted avg       0.21      0.13      0.14      2708\n",
            "\n",
            "0.09965454641645531\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFXLNetModel\n",
        "\n",
        "\n",
        "drop_out_rates = [0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "#drop_out_rate = 0.2\n",
        "learning_rate_transfer_learnings = [1e-6]\n",
        "#learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "learning_rate_fine_tuning=1e-5\n",
        "\n",
        "for drop_out_rate in drop_out_rates:\n",
        "  for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    checkpoint_filepath = DIR + 'checkpoints'\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True\n",
        "                                                  , monitor='val_categorical_accuracy', save_best_only=False)#, mode='max'\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping, model_checkpoint_callback])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    del(model1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DlgNJgRLQLe",
        "outputId": "2b92a574-c334-4885-eba5-25f84f9d5322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  1e-05 drop_out_rate: 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_5 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_5 (Global  (None, 768)         0           ['tfxl_net_model_5[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 768)         3072        ['global_max_pooling1d_5[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 512)          393728      ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 512)         2048        ['dense_10[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_232 (Dropout)          (None, 512)          0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 512)          262656      ['dropout_232[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 512)         2048        ['dense_11[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_233 (Dropout)          (None, 512)          0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           5130        ['dropout_233[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 117,387,018\n",
            "Trainable params: 665,098\n",
            "Non-trainable params: 116,721,920\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 965s 390ms/step - loss: 3.0737 - categorical_accuracy: 0.1194 - val_loss: 4.4900 - val_categorical_accuracy: 0.0839\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 947s 388ms/step - loss: 2.8887 - categorical_accuracy: 0.1437 - val_loss: 4.2261 - val_categorical_accuracy: 0.0959\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 947s 388ms/step - loss: 2.8242 - categorical_accuracy: 0.1595 - val_loss: 3.8598 - val_categorical_accuracy: 0.1153\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 2.7014 - categorical_accuracy: 0.1708 - val_loss: 4.1224 - val_categorical_accuracy: 0.0987\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 945s 388ms/step - loss: 2.6567 - categorical_accuracy: 0.1797 - val_loss: 4.0787 - val_categorical_accuracy: 0.1052\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 945s 388ms/step - loss: 2.5814 - categorical_accuracy: 0.1948 - val_loss: 3.8980 - val_categorical_accuracy: 0.1107\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.09      0.11       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.08      0.01      0.01       135\n",
            "         3.0       0.10      0.10      0.10       216\n",
            "         4.0       0.56      0.04      0.08      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.10      0.98      0.17       195\n",
            "         7.0       0.18      0.01      0.02       290\n",
            "         8.0       0.07      0.05      0.06       139\n",
            "         9.0       0.17      0.09      0.12       258\n",
            "\n",
            "    accuracy                           0.11      2708\n",
            "   macro avg       0.14      0.14      0.07      2708\n",
            "weighted avg       0.28      0.11      0.07      2708\n",
            "\n",
            "0.1368824080463503\n",
            "learning_rate_transfer_learning:  1e-06 drop_out_rate: 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_6 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_6 (Global  (None, 768)         0           ['tfxl_net_model_6[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 768)         3072        ['global_max_pooling1d_6[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 512)          393728      ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 512)         2048        ['dense_12[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_271 (Dropout)          (None, 512)          0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 512)          262656      ['dropout_271[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 512)         2048        ['dense_13[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_272 (Dropout)          (None, 512)          0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           5130        ['dropout_272[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 117,387,018\n",
            "Trainable params: 665,098\n",
            "Non-trainable params: 116,721,920\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 967s 391ms/step - loss: 3.1636 - categorical_accuracy: 0.1046 - val_loss: 3.3176 - val_categorical_accuracy: 0.1513\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 949s 390ms/step - loss: 3.1377 - categorical_accuracy: 0.1095 - val_loss: 3.3196 - val_categorical_accuracy: 0.1393\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 949s 389ms/step - loss: 3.1040 - categorical_accuracy: 0.1135 - val_loss: 3.4565 - val_categorical_accuracy: 0.1338\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 949s 389ms/step - loss: 3.0814 - categorical_accuracy: 0.1151 - val_loss: 3.4354 - val_categorical_accuracy: 0.1282\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.13      0.05      0.07       173\n",
            "         2.0       0.04      0.04      0.04       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.43      0.12      0.19      1036\n",
            "         5.0       0.06      0.05      0.06        76\n",
            "         6.0       0.10      0.87      0.17       195\n",
            "         7.0       0.14      0.11      0.13       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.17      0.09      0.12       258\n",
            "\n",
            "    accuracy                           0.14      2708\n",
            "   macro avg       0.11      0.13      0.08      2708\n",
            "weighted avg       0.21      0.14      0.12      2708\n",
            "\n",
            "0.1335164027133107\n",
            "learning_rate_transfer_learning:  1e-05 drop_out_rate: 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_7 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_7 (Global  (None, 768)         0           ['tfxl_net_model_7[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 768)         3072        ['global_max_pooling1d_7[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 512)          393728      ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 512)         2048        ['dense_14[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_310 (Dropout)          (None, 512)          0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 512)          262656      ['dropout_310[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 512)         2048        ['dense_15[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_311 (Dropout)          (None, 512)          0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           5130        ['dropout_311[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 117,387,018\n",
            "Trainable params: 665,098\n",
            "Non-trainable params: 116,721,920\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 964s 390ms/step - loss: 3.2073 - categorical_accuracy: 0.1116 - val_loss: 4.0440 - val_categorical_accuracy: 0.1006\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 947s 389ms/step - loss: 3.0326 - categorical_accuracy: 0.1442 - val_loss: 4.7132 - val_categorical_accuracy: 0.0987\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 944s 387ms/step - loss: 2.9369 - categorical_accuracy: 0.1534 - val_loss: 4.8118 - val_categorical_accuracy: 0.0876\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 944s 387ms/step - loss: 2.8436 - categorical_accuracy: 0.1597 - val_loss: 4.3876 - val_categorical_accuracy: 0.1042\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 944s 387ms/step - loss: 2.7784 - categorical_accuracy: 0.1716 - val_loss: 4.5556 - val_categorical_accuracy: 0.0978\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 947s 389ms/step - loss: 2.7484 - categorical_accuracy: 0.1673 - val_loss: 4.3816 - val_categorical_accuracy: 0.0969\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.04      0.06       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.15      0.07      0.10       216\n",
            "         4.0       0.43      0.01      0.02      1036\n",
            "         5.0       0.29      0.03      0.05        76\n",
            "         6.0       0.09      0.99      0.16       195\n",
            "         7.0       0.19      0.02      0.03       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.14      0.13      0.14       258\n",
            "\n",
            "    accuracy                           0.10      2708\n",
            "   macro avg       0.15      0.13      0.06      2708\n",
            "weighted avg       0.24      0.10      0.05      2708\n",
            "\n",
            "0.12875828951842966\n",
            "learning_rate_transfer_learning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_8 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_8 (Global  (None, 768)         0           ['tfxl_net_model_8[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 768)         3072        ['global_max_pooling1d_8[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 512)          393728      ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 512)         2048        ['dense_16[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_349 (Dropout)          (None, 512)          0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 512)          262656      ['dropout_349[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 512)         2048        ['dense_17[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_350 (Dropout)          (None, 512)          0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           5130        ['dropout_350[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 117,387,018\n",
            "Trainable params: 665,098\n",
            "Non-trainable params: 116,721,920\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 965s 390ms/step - loss: 3.3793 - categorical_accuracy: 0.1090 - val_loss: 5.5645 - val_categorical_accuracy: 0.0886\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.3822 - categorical_accuracy: 0.1069 - val_loss: 5.2430 - val_categorical_accuracy: 0.0904\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 945s 388ms/step - loss: 3.3069 - categorical_accuracy: 0.1132 - val_loss: 5.1939 - val_categorical_accuracy: 0.0969\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.2680 - categorical_accuracy: 0.1165 - val_loss: 4.9176 - val_categorical_accuracy: 0.0996\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.2309 - categorical_accuracy: 0.1188 - val_loss: 4.9149 - val_categorical_accuracy: 0.1052\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 947s 388ms/step - loss: 3.1885 - categorical_accuracy: 0.1238 - val_loss: 4.9380 - val_categorical_accuracy: 0.0996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.16      0.02      0.04       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.09      0.16      0.11       216\n",
            "         4.0       0.32      0.01      0.02      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.09      0.82      0.16       195\n",
            "         7.0       0.50      0.01      0.01       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.09      0.12      0.10       258\n",
            "\n",
            "    accuracy                           0.09      2708\n",
            "   macro avg       0.12      0.11      0.04      2708\n",
            "weighted avg       0.21      0.09      0.04      2708\n",
            "\n",
            "0.11333711708489788\n",
            "learning_rate_transfer_learning:  1e-05 drop_out_rate: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_9 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_9 (Global  (None, 768)         0           ['tfxl_net_model_9[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 768)         3072        ['global_max_pooling1d_9[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 512)          393728      ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 512)         2048        ['dense_18[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_388 (Dropout)          (None, 512)          0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 512)          262656      ['dropout_388[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 512)         2048        ['dense_19[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_389 (Dropout)          (None, 512)          0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           5130        ['dropout_389[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 117,387,018\n",
            "Trainable params: 665,098\n",
            "Non-trainable params: 116,721,920\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 965s 390ms/step - loss: 3.3894 - categorical_accuracy: 0.1003 - val_loss: 3.5072 - val_categorical_accuracy: 0.0895\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.2054 - categorical_accuracy: 0.1209 - val_loss: 3.7652 - val_categorical_accuracy: 0.1089\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.0994 - categorical_accuracy: 0.1398 - val_loss: 3.9119 - val_categorical_accuracy: 0.1024\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 945s 388ms/step - loss: 3.0009 - categorical_accuracy: 0.1489 - val_loss: 3.8505 - val_categorical_accuracy: 0.1015\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 2.9626 - categorical_accuracy: 0.1521 - val_loss: 3.6424 - val_categorical_accuracy: 0.1079\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.06      0.02      0.03       173\n",
            "         2.0       0.05      0.07      0.06       135\n",
            "         3.0       0.24      0.02      0.03       216\n",
            "         4.0       0.51      0.05      0.09      1036\n",
            "         5.0       0.09      0.03      0.04        76\n",
            "         6.0       0.09      0.98      0.16       195\n",
            "         7.0       0.20      0.00      0.01       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.17      0.09      0.11       258\n",
            "\n",
            "    accuracy                           0.11      2708\n",
            "   macro avg       0.14      0.12      0.05      2708\n",
            "weighted avg       0.27      0.11      0.07      2708\n",
            "\n",
            "0.12491723404235551\n",
            "learning_rate_transfer_learning:  1e-06 drop_out_rate: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_10 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_10 (Globa  (None, 768)         0           ['tfxl_net_model_10[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 768)         3072        ['global_max_pooling1d_10[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 512)          393728      ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 512)         2048        ['dense_20[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_427 (Dropout)          (None, 512)          0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 512)          262656      ['dropout_427[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 512)         2048        ['dense_21[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_428 (Dropout)          (None, 512)          0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           5130        ['dropout_428[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 117,387,018\n",
            "Trainable params: 665,098\n",
            "Non-trainable params: 116,721,920\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 964s 389ms/step - loss: 3.5455 - categorical_accuracy: 0.0963 - val_loss: 4.1254 - val_categorical_accuracy: 0.0886\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.5229 - categorical_accuracy: 0.0979 - val_loss: 4.1108 - val_categorical_accuracy: 0.0867\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.4599 - categorical_accuracy: 0.1027 - val_loss: 4.1057 - val_categorical_accuracy: 0.0830\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.4215 - categorical_accuracy: 0.1064 - val_loss: 3.9717 - val_categorical_accuracy: 0.0895\n",
            "Epoch 5/6\n",
            "2437/2437 [==============================] - 945s 388ms/step - loss: 3.3920 - categorical_accuracy: 0.1082 - val_loss: 3.9814 - val_categorical_accuracy: 0.0904\n",
            "Epoch 6/6\n",
            "2437/2437 [==============================] - 946s 388ms/step - loss: 3.3856 - categorical_accuracy: 0.1126 - val_loss: 4.0702 - val_categorical_accuracy: 0.0904\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.05      0.03      0.04       190\n",
            "         1.0       0.13      0.05      0.07       173\n",
            "         2.0       0.06      0.16      0.09       135\n",
            "         3.0       0.13      0.02      0.03       216\n",
            "         4.0       0.43      0.00      0.01      1036\n",
            "         5.0       0.04      0.07      0.05        76\n",
            "         6.0       0.08      0.54      0.14       195\n",
            "         7.0       0.08      0.08      0.08       290\n",
            "         8.0       0.16      0.05      0.08       139\n",
            "         9.0       0.13      0.23      0.17       258\n",
            "\n",
            "    accuracy                           0.09      2708\n",
            "   macro avg       0.13      0.12      0.08      2708\n",
            "weighted avg       0.23      0.09      0.06      2708\n",
            "\n",
            "0.12248550647378542\n",
            "learning_rate_transfer_learning:  1e-05 drop_out_rate: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_11 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_11 (Globa  (None, 768)         0           ['tfxl_net_model_11[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 768)         3072        ['global_max_pooling1d_11[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 512)          393728      ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 512)         2048        ['dense_22[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_466 (Dropout)          (None, 512)          0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 512)          262656      ['dropout_466[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 512)         2048        ['dense_23[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_467 (Dropout)          (None, 512)          0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           5130        ['dropout_467[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 117,387,018\n",
            "Trainable params: 665,098\n",
            "Non-trainable params: 116,721,920\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 963s 389ms/step - loss: 3.6178 - categorical_accuracy: 0.1055 - val_loss: 2.9256 - val_categorical_accuracy: 0.1052\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 944s 387ms/step - loss: 3.4588 - categorical_accuracy: 0.1169 - val_loss: 3.4499 - val_categorical_accuracy: 0.0895\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 942s 386ms/step - loss: 3.3676 - categorical_accuracy: 0.1278 - val_loss: 3.6129 - val_categorical_accuracy: 0.0876\n",
            "Epoch 4/6\n",
            "2437/2437 [==============================] - 941s 386ms/step - loss: 3.2285 - categorical_accuracy: 0.1431 - val_loss: 4.0154 - val_categorical_accuracy: 0.0886\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.01      0.02       190\n",
            "         1.0       0.10      0.02      0.04       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.62      0.01      0.02      1036\n",
            "         5.0       0.20      0.03      0.05        76\n",
            "         6.0       0.08      0.99      0.14       195\n",
            "         7.0       0.20      0.01      0.02       290\n",
            "         8.0       0.21      0.03      0.05       139\n",
            "         9.0       0.21      0.05      0.08       258\n",
            "\n",
            "    accuracy                           0.09      2708\n",
            "   macro avg       0.17      0.11      0.04      2708\n",
            "weighted avg       0.31      0.09      0.04      2708\n",
            "\n",
            "0.11478887787486972\n",
            "learning_rate_transfer_learning:  1e-06 drop_out_rate: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 768)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_12 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 768, 768),                                                  \n",
            "                                 mems=((768, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768),                                                \n",
            "                                 (768, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_12 (Globa  (None, 768)         0           ['tfxl_net_model_12[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 768)         3072        ['global_max_pooling1d_12[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 512)          393728      ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 512)         2048        ['dense_24[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_505 (Dropout)          (None, 512)          0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 512)          262656      ['dropout_505[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 512)         2048        ['dense_25[0][0]']               \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_506 (Dropout)          (None, 512)          0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           5130        ['dropout_506[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 117,387,018\n",
            "Trainable params: 665,098\n",
            "Non-trainable params: 116,721,920\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "2437/2437 [==============================] - 958s 387ms/step - loss: 3.5809 - categorical_accuracy: 0.1128 - val_loss: 3.9337 - val_categorical_accuracy: 0.0803\n",
            "Epoch 2/6\n",
            "2437/2437 [==============================] - 940s 386ms/step - loss: 3.6429 - categorical_accuracy: 0.1057 - val_loss: 3.8760 - val_categorical_accuracy: 0.0775\n",
            "Epoch 3/6\n",
            "2437/2437 [==============================] - 940s 386ms/step - loss: 3.6016 - categorical_accuracy: 0.1049 - val_loss: 3.7921 - val_categorical_accuracy: 0.0895\n",
            "Epoch 4/6\n",
            " 340/2437 [===>..........................] - ETA: 12:14 - loss: 3.5081 - categorical_accuracy: 0.1162"
          ]
        }
      ],
      "source": [
        "from transformers import TFXLNetModel\n",
        "\n",
        "\n",
        "drop_out_rates = [0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "#drop_out_rate = 0.2\n",
        "learning_rate_transfer_learnings = [1e-5, 1e-6]\n",
        "#learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "learning_rate_fine_tuning=1e-5\n",
        "\n",
        "for drop_out_rate in drop_out_rates:\n",
        "  for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(512, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(512, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)#added\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    checkpoint_filepath = DIR + 'checkpoints'\n",
        "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True\n",
        "                                                  , monitor='val_categorical_accuracy', save_best_only=False)#, mode='max'\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping, model_checkpoint_callback])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    del(model1)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DWL5DlwVTHgV",
        "hWxfNJqYBfjD",
        "nONmunMa_h7T",
        "hb0KcNXhbUSN"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "14fk6GtSVqm1OAk2PPHSEXlhRt0nQR7-L",
      "authorship_tag": "ABX9TyNBTuwMBBwGuxzfWwzq+ZPu",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05e4551b5c31404aa62bf864e9b64e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cf785ae86c04f6690b479b9b891ef98",
            "placeholder": "​",
            "style": "IPY_MODEL_5988796af7964979b50aa7281a9b46b7",
            "value": " 539M/539M [00:22&lt;00:00, 36.6MB/s]"
          }
        },
        "06b22f1dbcdc4e4598de8fbc481e62d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2da1ecf229d4816a9a62f123c6c656b",
            "placeholder": "​",
            "style": "IPY_MODEL_5491d62ff68b4b5795642e8df264f3d8",
            "value": "Downloading config.json: 100%"
          }
        },
        "06bcef83f932418aa708baf469d9264d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aadba53b9344cf28420d825097d8706": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12db1e83cf00483bb6790cf184bb3b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1305e76e3aba4dd6884f17d1eeac2521": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14bd8e6dfbaa4e8b8650f2fb82872485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6fe1a0ecec414eafcb4080ae38de9d",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7275c390c9c4c5fa8cf13ee3bf68dfc",
            "value": 760
          }
        },
        "165cdb4cb82044319ba7d11e095e1bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c86eb452882d48b09ff9b0dbf3ccf7f4",
              "IPY_MODEL_b0612c2880f14fd1a409489f5a9e27f6",
              "IPY_MODEL_8df57050db29456a849bfba6f7176afa"
            ],
            "layout": "IPY_MODEL_06bcef83f932418aa708baf469d9264d"
          }
        },
        "1b6fe1a0ecec414eafcb4080ae38de9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e2925be3236401a8734f0efe7aa4f49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5491d62ff68b4b5795642e8df264f3d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5988796af7964979b50aa7281a9b46b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a3ca785b23b4902a9b131b35535fb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d704982ce1489d8b428f1f01953b9b",
            "max": 565485600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af1de15c65c94c828999471f5c4f05cf",
            "value": 565485600
          }
        },
        "6335406064ce4698a6bb0cc86c04fde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_911bcfae1b0e4067a2e09c36b3580fb9",
              "IPY_MODEL_8e7efdb0fc5742459dae1c35dd3af3a2",
              "IPY_MODEL_05e4551b5c31404aa62bf864e9b64e79"
            ],
            "layout": "IPY_MODEL_df6f4681101c420baa838f2f363c6df4"
          }
        },
        "65d704982ce1489d8b428f1f01953b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "699f1c785e2e440aa3da9187c78cd503": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "700a9603018e45b18c9aa621cec44874": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf785ae86c04f6690b479b9b891ef98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5720dce23c4f78b35d23695397498d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828d2b52949e4e91966e47c25932e99d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad2bc152e6e48628ceff2a83505818b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df57050db29456a849bfba6f7176afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828d2b52949e4e91966e47c25932e99d",
            "placeholder": "​",
            "style": "IPY_MODEL_b064c72cb7014010bc21b01f2aa233da",
            "value": " 779k/779k [00:00&lt;00:00, 659kB/s]"
          }
        },
        "8e7efdb0fc5742459dae1c35dd3af3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_700a9603018e45b18c9aa621cec44874",
            "max": 565485600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12db1e83cf00483bb6790cf184bb3b7a",
            "value": 565485600
          }
        },
        "8f4341b1229f4217806f24eb29726d29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "911bcfae1b0e4067a2e09c36b3580fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec54ae0c6224d8581a28e5bfaf75f44",
            "placeholder": "​",
            "style": "IPY_MODEL_c352729952e64fe5b1e082fa7a1d1855",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "92303b847b0c4c4f8e3982b0825006e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b2f83b1bc7c4dcfa03b371c66523f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af1de15c65c94c828999471f5c4f05cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af464a9ae30947d4a8433fd402e2338e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f4341b1229f4217806f24eb29726d29",
            "placeholder": "​",
            "style": "IPY_MODEL_c65d75c08a4a401ebee0495a385d2c06",
            "value": " 539M/539M [00:11&lt;00:00, 46.1MB/s]"
          }
        },
        "b03a52b26016434aad7fb5f20aab53eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ad2bc152e6e48628ceff2a83505818b",
            "placeholder": "​",
            "style": "IPY_MODEL_eb724856fa854a6fb3c0cb77c09c79fb",
            "value": " 760/760 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "b0612c2880f14fd1a409489f5a9e27f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1305e76e3aba4dd6884f17d1eeac2521",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0aadba53b9344cf28420d825097d8706",
            "value": 798011
          }
        },
        "b064c72cb7014010bc21b01f2aa233da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb9b977be1cd47228e59e249a3b7b1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06b22f1dbcdc4e4598de8fbc481e62d6",
              "IPY_MODEL_14bd8e6dfbaa4e8b8650f2fb82872485",
              "IPY_MODEL_b03a52b26016434aad7fb5f20aab53eb"
            ],
            "layout": "IPY_MODEL_bbc15d90748a43faa2a9e7d9246d3459"
          }
        },
        "bbc15d90748a43faa2a9e7d9246d3459": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec54ae0c6224d8581a28e5bfaf75f44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c352729952e64fe5b1e082fa7a1d1855": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4a7d83637f9426eb59873faa506f0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fed7359c01a242958f16286bb9265cd9",
              "IPY_MODEL_5a3ca785b23b4902a9b131b35535fb6a",
              "IPY_MODEL_af464a9ae30947d4a8433fd402e2338e"
            ],
            "layout": "IPY_MODEL_699f1c785e2e440aa3da9187c78cd503"
          }
        },
        "c65d75c08a4a401ebee0495a385d2c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c86eb452882d48b09ff9b0dbf3ccf7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d5720dce23c4f78b35d23695397498d",
            "placeholder": "​",
            "style": "IPY_MODEL_92303b847b0c4c4f8e3982b0825006e2",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "d2da1ecf229d4816a9a62f123c6c656b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df6f4681101c420baa838f2f363c6df4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb724856fa854a6fb3c0cb77c09c79fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7275c390c9c4c5fa8cf13ee3bf68dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fed7359c01a242958f16286bb9265cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e2925be3236401a8734f0efe7aa4f49",
            "placeholder": "​",
            "style": "IPY_MODEL_9b2f83b1bc7c4dcfa03b371c66523f1d",
            "value": "Downloading tf_model.h5: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
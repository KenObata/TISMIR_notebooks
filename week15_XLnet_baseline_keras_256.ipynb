{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KenObata/TISMIR_notebooks/blob/main/week15_XLnet_baseline_keras_256.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS8WVxEoWZG0"
      },
      "source": [
        "## Week15: This notebook uses Pre-Trained word matrix-> SMOTE -> undersample by EDA -> append to word vectors. -> using Word2Vec. After that I apply SMOTE to balance out. \n",
        "Added task: Grid Search for best parameter in SVM.\n",
        "\n",
        "Situation: English only (=multi-class).\n",
        "Split: StratifiedKfold.\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWL5DlwVTHgV"
      },
      "source": [
        "### set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8Fdw4QzS4FD",
        "outputId": "068ff16c-3edc-4181-8d36-6ccd772b6380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 5.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install scikit-multilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1d5F3EmWPVWZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from collections import Counter\n",
        "\n",
        "from skmultilearn.model_selection import IterativeStratification   \n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "def get_balanced_accuracy(model, McNemar, is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning):\n",
        "  test_y = test.map(map_func_only_y)\n",
        "  y_category=np.zeros((TEST_SIZE, ))\n",
        "  counter=0\n",
        "  for label_tensor in test_y.take(len(test_y)):\n",
        "    y_test = np.argmax(label_tensor, axis=1)\n",
        "    for label in y_test:\n",
        "      y_category[counter]=label\n",
        "      counter+=1\n",
        "\n",
        "  X_test, y_test = test.map(map_func_only_X), y_category\n",
        "  y_predict_test = np.asarray(model.predict(X_test))\n",
        "  y_predict_test = np.argmax(y_predict_test, axis=1)\n",
        "  print(classification_report(y_test, y_predict_test) )\n",
        "  print(balanced_accuracy_score(y_test, y_predict_test))\n",
        "\n",
        "  McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)] = []\n",
        "  for ground_truh, pred in zip(y_test, y_predict_test):\n",
        "        if ground_truh==pred:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(True)\n",
        "        else:\n",
        "          McNemar[(is_fine_tuning, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning)].append(False)\n",
        "  with open(DIR+ \"XLnet_base_256_log.txt\", \"a\") as f:\n",
        "    print(\"======================================\", file=f)\n",
        "    print(\"is_fine_tuning?:\", is_fine_tuning, \"drop_out_rate: \", drop_out_rate, \"learning_rate_transfer_learning: \", learning_rate_transfer_learning,\n",
        "          \"learning_rate_fine_tuning: \", learning_rate_fine_tuning, file=f)\n",
        "    print(classification_report(y_test, y_predict_test) , file=f)\n",
        "    print(balanced_accuracy_score(y_test, y_predict_test), file=f)\n",
        "\n",
        "  return balanced_accuracy_score(y_test, y_predict_test), McNemar"
      ],
      "metadata": {
        "id": "K6VTlTxg8JVQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWxfNJqYBfjD"
      },
      "source": [
        "### Data Preparation(Kfold split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbT7Qs4whnTX"
      },
      "source": [
        "Create dataframe for Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Le3tiKjOOp19",
        "outputId": "8acd050e-f890-47b7-ad6d-3598e056da68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                id             genres lang  \\\n",
              "0               0  0009fFIM1eYThaPg                pop   en   \n",
              "1               1  00P2bHdWFkghmDqz               soul   en   \n",
              "2               2  00b6fV3nx5z2b8Ls                pop   en   \n",
              "3               3  013QDoTqbexEwkHr                pop   en   \n",
              "4               4  01EKNot8qVgZpKM7               rock   en   \n",
              "...           ...               ...                ...  ...   \n",
              "13535       13535  zzT504Z94j1IAuc3         indie rock   en   \n",
              "13536       13536  zzgS4ZqyswamEWNj                pop   en   \n",
              "13537       13537  zzx8CWdM7qkxKQpC         indie rock   en   \n",
              "13538       13538  zzz0n04uuTUA7fNh                pop   en   \n",
              "13539       13539  zzzj3LYaZtYtbzSr  singer-songwriter   en   \n",
              "\n",
              "                                                   lyric  number_of_line  \n",
              "0      a sunny day so I got nowhere to hide Not a clo...              91  \n",
              "1      Tell me a tale that always was Sing me a song ...              36  \n",
              "2      A buh A buh You went to school to learn girl T...              74  \n",
              "3      like a conversation where stops to breathe Is ...              20  \n",
              "4      Say the words I cannot say Say them on another...              31  \n",
              "...                                                  ...             ...  \n",
              "13535  think what afraid of come in you know been mad...              18  \n",
              "13536  Oh yeah yeah Last night I took a walk in the s...              75  \n",
              "13537  Innocence it come easy in a sense it never wil...              34  \n",
              "13538  Girl you know how I feel I really Since you be...              65  \n",
              "13539  wwI oh must go on standing You break that whic...              64  \n",
              "\n",
              "[13540 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0fe5d0b-6809-4931-a0da-ebc25f978af5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>genres</th>\n",
              "      <th>lang</th>\n",
              "      <th>lyric</th>\n",
              "      <th>number_of_line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0009fFIM1eYThaPg</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>a sunny day so I got nowhere to hide Not a clo...</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>00P2bHdWFkghmDqz</td>\n",
              "      <td>soul</td>\n",
              "      <td>en</td>\n",
              "      <td>Tell me a tale that always was Sing me a song ...</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>00b6fV3nx5z2b8Ls</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>A buh A buh You went to school to learn girl T...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>013QDoTqbexEwkHr</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>like a conversation where stops to breathe Is ...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>01EKNot8qVgZpKM7</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Say the words I cannot say Say them on another...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>13535</td>\n",
              "      <td>zzT504Z94j1IAuc3</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>think what afraid of come in you know been mad...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>13536</td>\n",
              "      <td>zzgS4ZqyswamEWNj</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Oh yeah yeah Last night I took a walk in the s...</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>13537</td>\n",
              "      <td>zzx8CWdM7qkxKQpC</td>\n",
              "      <td>indie rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Innocence it come easy in a sense it never wil...</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>13538</td>\n",
              "      <td>zzz0n04uuTUA7fNh</td>\n",
              "      <td>pop</td>\n",
              "      <td>en</td>\n",
              "      <td>Girl you know how I feel I really Since you be...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>13539</td>\n",
              "      <td>zzzj3LYaZtYtbzSr</td>\n",
              "      <td>singer-songwriter</td>\n",
              "      <td>en</td>\n",
              "      <td>wwI oh must go on standing You break that whic...</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0fe5d0b-6809-4931-a0da-ebc25f978af5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0fe5d0b-6809-4931-a0da-ebc25f978af5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0fe5d0b-6809-4931-a0da-ebc25f978af5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "DIR = '/content/drive/MyDrive/music4all/'\n",
        "df_genre_by_lang = pd.read_csv(DIR + 'df_genre_by_lang_full.csv')\n",
        "df_genre_by_lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PrRidTBHhmYp"
      },
      "outputs": [],
      "source": [
        "def load_data(df_col, y):\n",
        "    texts, labels = [], []\n",
        "    \n",
        "    for line in df_col:\n",
        "        # texts are already tokenized, just split on space\n",
        "        # in a real use-case we would put more effort in preprocessing\n",
        "        texts.append(line.split(' '))\n",
        "    return pd.DataFrame({'texts': texts, 'labels': y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n5VJWiA6iJu2"
      },
      "outputs": [],
      "source": [
        "data = load_data(df_genre_by_lang[\"lyric\"], df_genre_by_lang[\"genres\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bWI4V7oXiWw6",
        "outputId": "a27419e7-67c0-4e9a-f893-40772d0ed39e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   texts             labels\n",
              "0      [a, sunny, day, so, I, got, nowhere, to, hide,...                pop\n",
              "1      [Tell, me, a, tale, that, always, was, Sing, m...               soul\n",
              "2      [A, buh, A, buh, You, went, to, school, to, le...                pop\n",
              "3      [like, a, conversation, where, stops, to, brea...                pop\n",
              "4      [Say, the, words, I, cannot, say, Say, them, o...               rock\n",
              "...                                                  ...                ...\n",
              "13535  [think, what, afraid, of, come, in, you, know,...         indie rock\n",
              "13536  [Oh, yeah, yeah, Last, night, I, took, a, walk...                pop\n",
              "13537  [Innocence, it, come, easy, in, a, sense, it, ...         indie rock\n",
              "13538  [Girl, you, know, how, I, feel, I, really, Sin...                pop\n",
              "13539  [wwI, oh, must, go, on, standing, You, break, ...  singer-songwriter\n",
              "\n",
              "[13540 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aacc864d-179c-41bf-a444-ee4c383009f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[a, sunny, day, so, I, got, nowhere, to, hide,...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Tell, me, a, tale, that, always, was, Sing, m...</td>\n",
              "      <td>soul</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[A, buh, A, buh, You, went, to, school, to, le...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[like, a, conversation, where, stops, to, brea...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Say, the, words, I, cannot, say, Say, them, o...</td>\n",
              "      <td>rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13535</th>\n",
              "      <td>[think, what, afraid, of, come, in, you, know,...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13536</th>\n",
              "      <td>[Oh, yeah, yeah, Last, night, I, took, a, walk...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13537</th>\n",
              "      <td>[Innocence, it, come, easy, in, a, sense, it, ...</td>\n",
              "      <td>indie rock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13538</th>\n",
              "      <td>[Girl, you, know, how, I, feel, I, really, Sin...</td>\n",
              "      <td>pop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13539</th>\n",
              "      <td>[wwI, oh, must, go, on, standing, You, break, ...</td>\n",
              "      <td>singer-songwriter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13540 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aacc864d-179c-41bf-a444-ee4c383009f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aacc864d-179c-41bf-a444-ee4c383009f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aacc864d-179c-41bf-a444-ee4c383009f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iTROinyfjc6u"
      },
      "outputs": [],
      "source": [
        "data['labels'] = data['labels'].astype('category')\n",
        "label_mapping = data['labels'].cat.categories\n",
        "data['labels'] = data['labels'].cat.codes\n",
        "X = data['texts']\n",
        "y = data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32Ub0-kjoOj",
        "outputId": "5279c893-0ede-4abd-a7a5-7cac138c883c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "type(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GnAEWk_Lza7f"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df_glove(df, feature_list, y_name):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  y = df[y_name]\n",
        "  skf.get_n_splits(df[ feature_list ], y)\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(df[ feature_list ], y):\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = df[ feature_list ].loc[train_index], df[ feature_list ].loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1qOv6pF0BcrV"
      },
      "outputs": [],
      "source": [
        "def StratifiedKFold_feature_and_df(X, y):\n",
        "  skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1209)  # 20% for test set \n",
        "  #y = df[y_name]\n",
        "  skf.get_n_splits(X, y)#df[ feature_list ]\n",
        "\n",
        "  splits = []\n",
        "\n",
        "  for train_index, test_index in skf.split(X, y):#df[ feature_list ]\n",
        "      print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "      X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
        "      y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
        "      splits.append({'X_train': X_train, 'X_test': X_test, 'y_train':y_train, 'y_test':y_test })\n",
        "  return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGZPLOeBg4R",
        "outputId": "3260acc5-258d-4c63-dee3-fb8d8b47a495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN: [    0     1     3 ... 13537 13538 13539] TEST: [    2     4     5 ... 13526 13532 13535]\n",
            "TRAIN: [    0     2     4 ... 13535 13536 13539] TEST: [    1     3     7 ... 13530 13537 13538]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [    8    14    22 ... 13521 13531 13536]\n",
            "TRAIN: [    0     1     2 ... 13537 13538 13539] TEST: [   10    12    15 ... 13523 13525 13534]\n",
            "TRAIN: [    1     2     3 ... 13536 13537 13538] TEST: [    0     6    11 ... 13529 13533 13539]\n"
          ]
        }
      ],
      "source": [
        "#feature_list = [\"texts\"] #this is BOW and TF-IDF\n",
        "#splits = StratifiedKFold_feature_and_df( data, feature_list, 'labels')\n",
        "splits = StratifiedKFold_feature_and_df( X,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsQYbmVUWPU9",
        "outputId": "adf9a11f-d394-4c16-9fd7-4ffbafb7c5d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDMBs_gWCSLa",
        "outputId": "e1faa03d-23dd-4943-cf95-e660c9705d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832,)\n",
            "(10832,)\n",
            "(2708,)\n",
            "(2708,)\n"
          ]
        }
      ],
      "source": [
        "split0=splits[0]\n",
        "print(split0['X_train'].shape)\n",
        "print(split0['y_train'].shape)\n",
        "print(split0['X_test'].shape)\n",
        "print(split0['y_test'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaMmpM44is_p",
        "outputId": "e5bac888-edc7-4acd-975d-7139599eb3d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [a, sunny, day, so, I, got, nowhere, to, hide,...\n",
              "1        [Tell, me, a, tale, that, always, was, Sing, m...\n",
              "3        [like, a, conversation, where, stops, to, brea...\n",
              "6        [Locked, up, tight, Like, I, would, never, fee...\n",
              "7        [sittin, in, the, crib, dreamin, about, leer, ...\n",
              "                               ...                        \n",
              "13534    [grandma, cookies, nigga, Shout, out, to, fron...\n",
              "13536    [Oh, yeah, yeah, Last, night, I, took, a, walk...\n",
              "13537    [Innocence, it, come, easy, in, a, sense, it, ...\n",
              "13538    [Girl, you, know, how, I, feel, I, really, Sin...\n",
              "13539    [wwI, oh, must, go, on, standing, You, break, ...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "split0['X_train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qTuHLEe8Aqg",
        "outputId": "7f4fd357-7909-460e-9026-294e9a2ee24e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "split0['y_train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nONmunMa_h7T"
      },
      "source": [
        "### Use my self programmed balanced accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot3KP7Dl_kdf",
        "outputId": "b39a20db-171b-4ef7-bd3a-e1a9522eb463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "339/339 [==============================] - 225s 645ms/step - loss: 0.5565 - categorical_accuracy: 0.3878 - val_loss: 1.9337 - val_categorical_accuracy: 0.3273\n",
            "Epoch 2/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5397 - categorical_accuracy: 0.3626 - val_loss: 2.0651 - val_categorical_accuracy: 0.2764\n",
            "Epoch 3/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5375 - categorical_accuracy: 0.3392 - val_loss: 2.0931 - val_categorical_accuracy: 0.2273\n",
            "Epoch 4/10\n",
            "339/339 [==============================] - 218s 645ms/step - loss: 0.5378 - categorical_accuracy: 0.3197 - val_loss: 2.0576 - val_categorical_accuracy: 0.2459\n",
            "Epoch 5/10\n",
            "339/339 [==============================] - 219s 645ms/step - loss: 0.5333 - categorical_accuracy: 0.3077 - val_loss: 2.0292 - val_categorical_accuracy: 0.2816\n",
            "Epoch 6/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5373 - categorical_accuracy: 0.2967 - val_loss: 2.1738 - val_categorical_accuracy: 0.1895\n",
            "Epoch 7/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5396 - categorical_accuracy: 0.2930 - val_loss: 2.1382 - val_categorical_accuracy: 0.2181\n",
            "Epoch 8/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5431 - categorical_accuracy: 0.2710 - val_loss: 2.1512 - val_categorical_accuracy: 0.1965\n",
            "Epoch 9/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5450 - categorical_accuracy: 0.2729 - val_loss: 2.1854 - val_categorical_accuracy: 0.1092\n",
            "Epoch 10/10\n",
            "339/339 [==============================] - 219s 646ms/step - loss: 0.5495 - categorical_accuracy: 0.2553 - val_loss: 2.1354 - val_categorical_accuracy: 0.1594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'balanced_accuracy': 0.09744849916749872},\n",
              " {'balanced_accuracy': 0.10420636932765996},\n",
              " {'balanced_accuracy': 0.10970405736872939},\n",
              " {'balanced_accuracy': 0.10356561320774078},\n",
              " {'balanced_accuracy': 0.10792864804613309},\n",
              " {'balanced_accuracy': 0.09168989857066105},\n",
              " {'balanced_accuracy': 0.09926135499834263},\n",
              " {'balanced_accuracy': 0.10014630125778516},\n",
              " {'balanced_accuracy': 0.09807505457274496},\n",
              " {'balanced_accuracy': 0.09881853716030842}]"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics = Metrics()\n",
        "history = model.fit(train, validation_data=val, epochs=10, class_weight=my_weight ,callbacks=[metrics])\n",
        "metrics.get_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzqLBSC6H175"
      },
      "source": [
        "## From here, separate X_train, X_test from KFoldSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb0KcNXhbUSN"
      },
      "source": [
        "### Preprocess my lyrics data (Official train and test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "m4lLLyF-bUSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d19bb82c-f5d3-4994-ecc2-f22f1f75f82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 12.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "!pip3 install transformers\n",
        "SEQ_LEN = 256#512"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUA-ps2gyvt",
        "outputId": "ea0c0128-10a8-45c8-b3f4-0e083960eb99"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2        [A, buh, A, buh, You, went, to, school, to, le...\n",
              "4        [Say, the, words, I, cannot, say, Say, them, o...\n",
              "5        [I, was, alone, I, was, made, of, stone, You, ...\n",
              "9        [Again, the, burden, of, losing, rests, upon, ...\n",
              "20       [only, been, three, weeks, And, a, bag, of, sp...\n",
              "                               ...                        \n",
              "13517    [Like, the, legend, of, the, Phoenix, All, end...\n",
              "13522    [Mr, Telephone, man, something, wrong, with, m...\n",
              "13526    [can, you, imagine, what, it, would, be, like,...\n",
              "13532    [Love, of, my, life, hurt, me, broken, my, hea...\n",
              "13535    [think, what, afraid, of, come, in, you, know,...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_lyrics(X_series):\n",
        "  for i, token_list in X_series.items():\n",
        "    if type(token_list) is list:\n",
        "      X_series.loc[i] = ' '.join(token_list)\n",
        "  return X_series"
      ],
      "metadata": {
        "id": "PqFwOGTIbhiZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "split0['X_test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzTIRCW1cUwV",
        "outputId": "2b5c98c0-536e-47ce-88da-700498914a55"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2        A buh A buh You went to school to learn girl T...\n",
              "4        Say the words I cannot say Say them on another...\n",
              "5        I was alone I was made of stone You took me ho...\n",
              "9        Again the burden of losing rests upon my shoul...\n",
              "20       only been three weeks And a bag of speed from ...\n",
              "                               ...                        \n",
              "13517    Like the legend of the Phoenix All ends with b...\n",
              "13522    Mr Telephone man something wrong with my line ...\n",
              "13526    can you imagine what it would be like we never...\n",
              "13532    Love of my life hurt me broken my heart and no...\n",
              "13535    think what afraid of come in you know been mad...\n",
              "Name: texts, Length: 2708, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_train'] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxixg4yAcAfe",
        "outputId": "46076631-7a20-4757-fb3e-fe33ec50dbde"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        a sunny day so I got nowhere to hide Not a clo...\n",
              "1        Tell me a tale that always was Sing me a song ...\n",
              "3        like a conversation where stops to breathe Is ...\n",
              "6        Locked up tight Like I would never feel again ...\n",
              "7        sittin in the crib dreamin about leer jets and...\n",
              "                               ...                        \n",
              "13534    grandma cookies nigga Shout out to fronto leaf...\n",
              "13536    Oh yeah yeah Last night I took a walk in the s...\n",
              "13537    Innocence it come easy in a sense it never wil...\n",
              "13538    Girl you know how I feel I really Since you be...\n",
              "13539    wwI oh must go on standing You break that whic...\n",
              "Name: texts, Length: 10832, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split0['y_train'] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9UxO1GAcfoI",
        "outputId": "e5c67842-f01f-4642-8546-22b3aeccfc5f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        4\n",
              "1        9\n",
              "3        4\n",
              "6        4\n",
              "7        6\n",
              "        ..\n",
              "13534    6\n",
              "13536    4\n",
              "13537    3\n",
              "13538    4\n",
              "13539    8\n",
              "Name: labels, Length: 10832, dtype: int8"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use ALBERT\n",
        "Be careful, you need sentencepiece library:https://stackoverflow.com/questions/65854722/huggingface-albert-tokenizer-nonetype-error-with-colab"
      ],
      "metadata": {
        "id": "9zWdtsKTSIjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QClJ2DWKVs0Q",
        "outputId": "6f713cb8-5c29-421c-a0f6-7c6b1bc9e157"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 12.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFXLNetModel, XLNetTokenizer\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
      ],
      "metadata": {
        "id": "Hva6XApHsWRY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "42f4332cc6fd41efabceca28cf3fb621",
            "67f4d6fc8c95497a9e0d573cb4e59602",
            "5b20223e1557405bbb44f67e79a473cb",
            "eb7eec523f7d4c748cd5eff30591214b",
            "d67c1d03efd94a9d9e4cebdb328d9132",
            "dc00b70cab304efda04f01db28ff1a0d",
            "3f6b0ec6ada64353b3a44bceda5de3cf",
            "38745d83f48749aca4a7937d56c8fc28",
            "8bc7bd47e3254236ad10cf858cf71e08",
            "0c3922a9067940f8818f3d66d23f0f66",
            "6c673dfc9263460095a6db511e45f12d",
            "c2c999450bd54d9496426c1c1df959ee",
            "3b3319c9d71f4dc7b12e028b3e220ecc",
            "4529b585c3bf4268be47b8cf746b3e51",
            "b73fdde92f164c9593b4962b0c180d94",
            "ee6e50199dfd4dc39382888295a7c089",
            "7d2b7171620c4f93979f8232140d4672",
            "863a645cf22640abbaaef2dc762b2258",
            "f38f0d5991a6429c95fdcc5b38ced72d",
            "93a6278ed1e041bdb3f93ff6868257c4",
            "5ddbd37d030544d7b3c11b9c74625d37",
            "29cda64bb9b342459bc67a3e38887277"
          ]
        },
        "outputId": "e2c88310-946a-4cd4-e56b-f0c2e525f877"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/779k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42f4332cc6fd41efabceca28cf3fb621"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2c999450bd54d9496426c1c1df959ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy as np\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "print(Xids_train.shape, Xids_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt_zTUp0SKST",
        "outputId": "00f06c6d-f6ee-43b7-e5e1-4b4aa37b738e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4YypbKsbUSQ"
      },
      "source": [
        "Create y labels in transformer format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "VFYtD7rybUSQ"
      },
      "outputs": [],
      "source": [
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-FgpLfmjtZW",
        "outputId": "3fda6640-32ec-4a86-9349-a8c92486ecf0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10832"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "J7xk5236bUSR"
      },
      "outputs": [],
      "source": [
        "def map_func(input_ids, masks, labels):\n",
        "  return {'input_ids': input_ids, 'attention_mask':masks}, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nXygicJBbUSR"
      },
      "outputs": [],
      "source": [
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed436ac-4e16-4656-ce13-8516080cb455",
        "id": "jqWHoZJebUSR"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "677"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "DS_LEN = len(list(dataset_train))\n",
        "DS_LEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVuShbZzbUSS"
      },
      "source": [
        "339 because 10800/32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed853a8-a1d8-4221-ac21-ebf85caa27ce",
        "id": "cg9c-e5jbUSS"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "609"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "SPLIT = 0.9\n",
        "round(DS_LEN*SPLIT)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(split0['X_train'])-int(len(split0['X_train'])*0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-e9iZTaasAJ",
        "outputId": "c535ed5d-701d-42d7-b554-564f1bb21aca"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1084"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "b1VgA6bIbUSS"
      },
      "outputs": [],
      "source": [
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))#remainer is for val."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "id": "1GzPKw9sXgOB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "77foZE_rZc9E"
      },
      "outputs": [],
      "source": [
        "def map_func_only_X(val_dictionary, labels):\n",
        "  return {'input_ids': val_dictionary['input_ids'], 'attention_mask':val_dictionary['attention_mask']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-n1WkoHFZc9H"
      },
      "outputs": [],
      "source": [
        "def map_func_only_y(val_dictionary, labels):\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_SIZE=1088"
      ],
      "metadata": {
        "id": "Q-VGMZy5bRfN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "006b40d2-e15d-44a8-e659-d1e00b2c9edf",
        "id": "wZDVrP0QYC_n"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10832"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "counter = Counter(split0['y_train'])\n",
        "SUM=0\n",
        "for item in list(counter.values()) :\n",
        "  SUM+=item\n",
        "#SUM = sum(counter.values())\n",
        "SUM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tutorial\n",
        "#weight_for_0 = (1 / neg) * (total / 2.0)\n",
        "#weight_for_1 = (1 / pos) * (total / 2.0)\n",
        "\n",
        "counter = Counter(split0['y_train'])\n",
        "my_weight2 = {}\n",
        "print(counter)\n",
        "\n",
        "for genre in counter:\n",
        "  #print(genre, counter[genre])\n",
        "  my_weight2[genre] = (1/counter[genre]) * (SUM/10)\n",
        "my_weight2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbDe9DVFAvjP",
        "outputId": "76a244be-f622-4d52-8c85-91ebe1d36776"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({4: 4143, 7: 1159, 9: 1030, 3: 865, 6: 783, 0: 763, 1: 690, 8: 556, 2: 537, 5: 306})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 0.2614530533429882,\n",
              " 9: 1.051650485436893,\n",
              " 6: 1.383397190293742,\n",
              " 2: 2.0171322160148977,\n",
              " 0: 1.4196592398427261,\n",
              " 7: 0.9345987920621226,\n",
              " 1: 1.569855072463768,\n",
              " 5: 3.539869281045752,\n",
              " 8: 1.948201438848921,\n",
              " 3: 1.2522543352601156}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter tuning"
      ],
      "metadata": {
        "id": "CLARPbncyjEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetLMHeadModel, XLNetTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[0]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "TEST_SIZE = len(split0['y_test'])\n",
        "print(\"TEST_SIZE:\", TEST_SIZE)\n",
        "SEQ_LEN=256\n",
        "SEQ_LEN2=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKF0fs_C8g_k",
        "outputId": "6e7d587e-546e-438f-ec19-6cad884453fc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST_SIZE: 2708\n",
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_transfer_learning=[]\n",
        "balanced_accuracies_fine_tuning=[]\n",
        "McNemar={}"
      ],
      "metadata": {
        "id": "IkkZzVFNCkKt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(model1)"
      ],
      "metadata": {
        "id": "E04ahVfRCrMe"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.1\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEMPSMEKym_P",
        "outputId": "e63f886d-26a4-4f66-b50b-1cc2b5b4701d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_13 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_13 (Globa  (None, 768)         0           ['tfxl_net_model_13[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 768)         3072        ['global_max_pooling1d_13[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 128)          98432       ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_531 (Dropout)          (None, 128)          0           ['dense_26[0][0]']               \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 32)           4128        ['dropout_531[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_27[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 172ms/step - loss: 2.1953 - categorical_accuracy: 0.2026 - val_loss: 2.1161 - val_categorical_accuracy: 0.1951\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.0024 - categorical_accuracy: 0.2623 - val_loss: 2.0834 - val_categorical_accuracy: 0.2812\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 1.9166 - categorical_accuracy: 0.2898 - val_loss: 2.1318 - val_categorical_accuracy: 0.2485\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 1.8870 - categorical_accuracy: 0.2865 - val_loss: 2.0287 - val_categorical_accuracy: 0.2255\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 1.8481 - categorical_accuracy: 0.3060 - val_loss: 2.1361 - val_categorical_accuracy: 0.2493\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.09      0.01      0.02       190\n",
            "         1.0       0.36      0.05      0.08       173\n",
            "         2.0       0.06      0.08      0.07       135\n",
            "         3.0       0.50      0.01      0.02       216\n",
            "         4.0       0.61      0.31      0.41      1036\n",
            "         5.0       0.07      0.62      0.13        76\n",
            "         6.0       0.66      0.51      0.58       195\n",
            "         7.0       0.11      0.01      0.01       290\n",
            "         8.0       0.11      0.51      0.19       139\n",
            "         9.0       0.21      0.37      0.27       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.28      0.25      0.18      2708\n",
            "weighted avg       0.39      0.24      0.25      2708\n",
            "\n",
            "0.24803084002112685\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_13/transformer/mask_emb:0', 'tfxl_net_model_13/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_13/transformer/mask_emb:0', 'tfxl_net_model_13/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_13/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_13/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 206s 316ms/step - loss: 1.9293 - categorical_accuracy: 0.2843 - val_loss: 2.0569 - val_categorical_accuracy: 0.2482\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 191s 313ms/step - loss: 1.8015 - categorical_accuracy: 0.3214 - val_loss: 2.6434 - val_categorical_accuracy: 0.1631\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.7528 - categorical_accuracy: 0.3161 - val_loss: 2.8639 - val_categorical_accuracy: 0.1914\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.6384 - categorical_accuracy: 0.3586 - val_loss: 2.1170 - val_categorical_accuracy: 0.3134\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 191s 313ms/step - loss: 1.5488 - categorical_accuracy: 0.3810 - val_loss: 2.1810 - val_categorical_accuracy: 0.3564\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.4556 - categorical_accuracy: 0.3994 - val_loss: 2.1870 - val_categorical_accuracy: 0.2698\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.18      0.18       190\n",
            "         1.0       0.27      0.10      0.15       173\n",
            "         2.0       0.07      0.35      0.11       135\n",
            "         3.0       0.19      0.01      0.03       216\n",
            "         4.0       0.65      0.25      0.36      1036\n",
            "         5.0       0.14      0.45      0.21        76\n",
            "         6.0       0.82      0.68      0.74       195\n",
            "         7.0       0.15      0.01      0.02       290\n",
            "         8.0       0.13      0.48      0.21       139\n",
            "         9.0       0.26      0.40      0.32       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.29      0.29      0.23      2708\n",
            "weighted avg       0.41      0.26      0.27      2708\n",
            "\n",
            "0.2922277747604768\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_14 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_14 (Globa  (None, 768)         0           ['tfxl_net_model_14[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 768)         3072        ['global_max_pooling1d_14[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_28 (Dense)               (None, 128)          98432       ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_569 (Dropout)          (None, 128)          0           ['dense_28[0][0]']               \n",
            "                                                                                                  \n",
            " dense_29 (Dense)               (None, 32)           4128        ['dropout_569[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_29[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 116s 172ms/step - loss: 2.1683 - categorical_accuracy: 0.2245 - val_loss: 2.0236 - val_categorical_accuracy: 0.2720\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 1.9835 - categorical_accuracy: 0.2732 - val_loss: 2.2819 - val_categorical_accuracy: 0.1743\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 1.9195 - categorical_accuracy: 0.2915 - val_loss: 2.0827 - val_categorical_accuracy: 0.2200\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 1.8870 - categorical_accuracy: 0.2952 - val_loss: 2.0572 - val_categorical_accuracy: 0.2545\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.06      0.08       190\n",
            "         1.0       0.22      0.13      0.16       173\n",
            "         2.0       0.06      0.26      0.10       135\n",
            "         3.0       0.15      0.05      0.08       216\n",
            "         4.0       0.67      0.29      0.41      1036\n",
            "         5.0       0.08      0.54      0.14        76\n",
            "         6.0       0.66      0.67      0.66       195\n",
            "         7.0       0.14      0.03      0.05       290\n",
            "         8.0       0.11      0.33      0.16       139\n",
            "         9.0       0.26      0.23      0.24       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.25      0.26      0.21      2708\n",
            "weighted avg       0.39      0.25      0.27      2708\n",
            "\n",
            "0.2587156030764534\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_14/transformer/mask_emb:0', 'tfxl_net_model_14/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_14/transformer/mask_emb:0', 'tfxl_net_model_14/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_14/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_14/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 208s 317ms/step - loss: 1.8219 - categorical_accuracy: 0.3264 - val_loss: 2.0177 - val_categorical_accuracy: 0.2701\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.8069 - categorical_accuracy: 0.3175 - val_loss: 2.0142 - val_categorical_accuracy: 0.2559\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 191s 313ms/step - loss: 1.7672 - categorical_accuracy: 0.3255 - val_loss: 2.0242 - val_categorical_accuracy: 0.2562\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.7598 - categorical_accuracy: 0.3216 - val_loss: 2.0510 - val_categorical_accuracy: 0.2331\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.09      0.04      0.06       190\n",
            "         1.0       0.20      0.13      0.16       173\n",
            "         2.0       0.06      0.19      0.09       135\n",
            "         3.0       0.17      0.04      0.07       216\n",
            "         4.0       0.65      0.18      0.28      1036\n",
            "         5.0       0.08      0.63      0.14        76\n",
            "         6.0       0.67      0.71      0.69       195\n",
            "         7.0       0.15      0.02      0.04       290\n",
            "         8.0       0.12      0.40      0.19       139\n",
            "         9.0       0.22      0.37      0.28       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.24      0.27      0.20      2708\n",
            "weighted avg       0.38      0.22      0.23      2708\n",
            "\n",
            "0.2724610523582771\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_15 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_15 (Globa  (None, 768)         0           ['tfxl_net_model_15[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 768)         3072        ['global_max_pooling1d_15[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_30 (Dense)               (None, 128)          98432       ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_607 (Dropout)          (None, 128)          0           ['dense_30[0][0]']               \n",
            "                                                                                                  \n",
            " dense_31 (Dense)               (None, 32)           4128        ['dropout_607[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_31[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 172ms/step - loss: 2.4281 - categorical_accuracy: 0.1332 - val_loss: 2.3919 - val_categorical_accuracy: 0.1443\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.2128 - categorical_accuracy: 0.1964 - val_loss: 2.2412 - val_categorical_accuracy: 0.1862\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 103s 168ms/step - loss: 2.1130 - categorical_accuracy: 0.2301 - val_loss: 2.1092 - val_categorical_accuracy: 0.2210\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0581 - categorical_accuracy: 0.2451 - val_loss: 2.1396 - val_categorical_accuracy: 0.2252\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.0085 - categorical_accuracy: 0.2596 - val_loss: 2.0014 - val_categorical_accuracy: 0.2787\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 1.9708 - categorical_accuracy: 0.2709 - val_loss: 1.9535 - val_categorical_accuracy: 0.2805\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.07      0.09       190\n",
            "         1.0       0.19      0.16      0.17       173\n",
            "         2.0       0.11      0.15      0.12       135\n",
            "         3.0       0.17      0.05      0.08       216\n",
            "         4.0       0.53      0.33      0.41      1036\n",
            "         5.0       0.13      0.28      0.17        76\n",
            "         6.0       0.45      0.84      0.59       195\n",
            "         7.0       0.15      0.01      0.02       290\n",
            "         8.0       0.13      0.35      0.19       139\n",
            "         9.0       0.18      0.44      0.26       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.22      0.27      0.21      2708\n",
            "weighted avg       0.32      0.28      0.27      2708\n",
            "\n",
            "0.2677674946948079\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_15/transformer/mask_emb:0', 'tfxl_net_model_15/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_15/transformer/mask_emb:0', 'tfxl_net_model_15/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_15/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_15/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 209s 318ms/step - loss: 1.9879 - categorical_accuracy: 0.2592 - val_loss: 2.0233 - val_categorical_accuracy: 0.2856\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 191s 314ms/step - loss: 1.8869 - categorical_accuracy: 0.2865 - val_loss: 6.1443 - val_categorical_accuracy: 0.3666\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 191s 314ms/step - loss: 1.8226 - categorical_accuracy: 0.3009 - val_loss: 4.3485 - val_categorical_accuracy: 0.2802\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 191s 313ms/step - loss: 1.7227 - categorical_accuracy: 0.3339 - val_loss: 4.6214 - val_categorical_accuracy: 0.1456\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.6156 - categorical_accuracy: 0.3559 - val_loss: 6.6776 - val_categorical_accuracy: 0.1159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.25      0.01      0.02       173\n",
            "         2.0       0.07      0.16      0.10       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.73      0.03      0.06      1036\n",
            "         5.0       0.50      0.01      0.03        76\n",
            "         6.0       0.82      0.51      0.63       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.06      0.92      0.11       139\n",
            "         9.0       0.25      0.10      0.14       258\n",
            "\n",
            "    accuracy                           0.11      2708\n",
            "   macro avg       0.27      0.17      0.11      2708\n",
            "weighted avg       0.40      0.11      0.10      2708\n",
            "\n",
            "0.1739512769568827\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_16 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_16 (Globa  (None, 768)         0           ['tfxl_net_model_16[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 768)         3072        ['global_max_pooling1d_16[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 128)          98432       ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_645 (Dropout)          (None, 128)          0           ['dense_32[0][0]']               \n",
            "                                                                                                  \n",
            " dense_33 (Dense)               (None, 32)           4128        ['dropout_645[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_33[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 172ms/step - loss: 2.4271 - categorical_accuracy: 0.1521 - val_loss: 2.3569 - val_categorical_accuracy: 0.1475\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1985 - categorical_accuracy: 0.2094 - val_loss: 2.2086 - val_categorical_accuracy: 0.1891\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1084 - categorical_accuracy: 0.2414 - val_loss: 2.1632 - val_categorical_accuracy: 0.2059\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0499 - categorical_accuracy: 0.2490 - val_loss: 2.0591 - val_categorical_accuracy: 0.2473\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0253 - categorical_accuracy: 0.2703 - val_loss: 2.0636 - val_categorical_accuracy: 0.2470\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 1.9846 - categorical_accuracy: 0.2787 - val_loss: 2.0201 - val_categorical_accuracy: 0.2455\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.19      0.19       190\n",
            "         1.0       0.22      0.23      0.22       173\n",
            "         2.0       0.09      0.07      0.08       135\n",
            "         3.0       0.26      0.11      0.15       216\n",
            "         4.0       0.61      0.23      0.33      1036\n",
            "         5.0       0.12      0.28      0.17        76\n",
            "         6.0       0.36      0.87      0.51       195\n",
            "         7.0       0.21      0.08      0.11       290\n",
            "         8.0       0.13      0.17      0.15       139\n",
            "         9.0       0.17      0.53      0.25       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.24      0.27      0.22      2708\n",
            "weighted avg       0.36      0.26      0.25      2708\n",
            "\n",
            "0.2745442405906864\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_16/transformer/mask_emb:0', 'tfxl_net_model_16/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_16/transformer/mask_emb:0', 'tfxl_net_model_16/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_16/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_16/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 207s 316ms/step - loss: 1.9318 - categorical_accuracy: 0.2902 - val_loss: 1.9878 - val_categorical_accuracy: 0.2535\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8873 - categorical_accuracy: 0.2937 - val_loss: 2.0418 - val_categorical_accuracy: 0.2456\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8748 - categorical_accuracy: 0.2935 - val_loss: 2.0333 - val_categorical_accuracy: 0.2453\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8636 - categorical_accuracy: 0.3052 - val_loss: 2.0202 - val_categorical_accuracy: 0.2550\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8476 - categorical_accuracy: 0.3110 - val_loss: 2.0260 - val_categorical_accuracy: 0.2562\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8344 - categorical_accuracy: 0.3118 - val_loss: 1.9949 - val_categorical_accuracy: 0.2648\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.23      0.20       190\n",
            "         1.0       0.24      0.29      0.26       173\n",
            "         2.0       0.04      0.03      0.04       135\n",
            "         3.0       0.14      0.08      0.10       216\n",
            "         4.0       0.65      0.22      0.33      1036\n",
            "         5.0       0.14      0.36      0.20        76\n",
            "         6.0       0.40      0.85      0.55       195\n",
            "         7.0       0.09      0.04      0.06       290\n",
            "         8.0       0.10      0.17      0.13       139\n",
            "         9.0       0.19      0.54      0.29       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.22      0.28      0.22      2708\n",
            "weighted avg       0.36      0.26      0.25      2708\n",
            "\n",
            "0.28092515477857566\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.2\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_njkok5CwfP",
        "outputId": "664386c9-6bb5-4438-b25a-992b6e3515b0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_2 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 768)         0           ['tfxl_net_model_2[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          98432       ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_113 (Dropout)          (None, 128)          0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 32)           4128        ['dropout_113[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 202s 309ms/step - loss: 2.2430 - categorical_accuracy: 0.2252 - val_loss: 2.0167 - val_categorical_accuracy: 0.3401\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0258 - categorical_accuracy: 0.2670 - val_loss: 2.3655 - val_categorical_accuracy: 0.2290\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.9627 - categorical_accuracy: 0.2763 - val_loss: 2.0816 - val_categorical_accuracy: 0.2904\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9256 - categorical_accuracy: 0.2824 - val_loss: 2.2910 - val_categorical_accuracy: 0.2428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.04      0.07       190\n",
            "         1.0       0.23      0.14      0.18       173\n",
            "         2.0       0.04      0.03      0.03       135\n",
            "         3.0       0.16      0.04      0.07       216\n",
            "         4.0       0.64      0.26      0.37      1036\n",
            "         5.0       0.07      0.66      0.12        76\n",
            "         6.0       0.35      0.85      0.49       195\n",
            "         7.0       0.05      0.00      0.01       290\n",
            "         8.0       0.14      0.31      0.20       139\n",
            "         9.0       0.17      0.29      0.22       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.20      0.26      0.17      2708\n",
            "weighted avg       0.34      0.24      0.23      2708\n",
            "\n",
            "0.2627327277990376\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 369s 577ms/step - loss: 1.9240 - categorical_accuracy: 0.2931 - val_loss: 2.2020 - val_categorical_accuracy: 0.2527\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8386 - categorical_accuracy: 0.3155 - val_loss: 2.2041 - val_categorical_accuracy: 0.2411\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8290 - categorical_accuracy: 0.3075 - val_loss: 2.1767 - val_categorical_accuracy: 0.2985\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.7350 - categorical_accuracy: 0.3206 - val_loss: 3.0592 - val_categorical_accuracy: 0.1503\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.9707 - categorical_accuracy: 0.2560 - val_loss: 12.0946 - val_categorical_accuracy: 0.0946\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 2.4446 - categorical_accuracy: 0.1250 - val_loss: 15.6374 - val_categorical_accuracy: 0.0945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.00      0.00      0.00       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.10      1.00      0.17       258\n",
            "\n",
            "    accuracy                           0.10      2708\n",
            "   macro avg       0.01      0.10      0.02      2708\n",
            "weighted avg       0.01      0.10      0.02      2708\n",
            "\n",
            "0.1\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_3 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Global  (None, 768)         0           ['tfxl_net_model_3[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          98432       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_151 (Dropout)          (None, 128)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 32)           4128        ['dropout_151[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 201s 308ms/step - loss: 2.2220 - categorical_accuracy: 0.2040 - val_loss: 2.1401 - val_categorical_accuracy: 0.2042\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0502 - categorical_accuracy: 0.2494 - val_loss: 2.3225 - val_categorical_accuracy: 0.2143\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9760 - categorical_accuracy: 0.2607 - val_loss: 2.2573 - val_categorical_accuracy: 0.1614\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.9281 - categorical_accuracy: 0.2443 - val_loss: 2.1015 - val_categorical_accuracy: 0.2305\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.8948 - categorical_accuracy: 0.2845 - val_loss: 2.1753 - val_categorical_accuracy: 0.2039\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.8613 - categorical_accuracy: 0.2822 - val_loss: 2.4666 - val_categorical_accuracy: 0.1674\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.12      0.03      0.04       190\n",
            "         1.0       0.11      0.03      0.05       173\n",
            "         2.0       0.03      0.13      0.05       135\n",
            "         3.0       0.12      0.01      0.02       216\n",
            "         4.0       0.66      0.18      0.28      1036\n",
            "         5.0       0.06      0.67      0.11        76\n",
            "         6.0       0.79      0.21      0.33       195\n",
            "         7.0       0.08      0.00      0.01       290\n",
            "         8.0       0.10      0.58      0.17       139\n",
            "         9.0       0.31      0.04      0.07       258\n",
            "\n",
            "    accuracy                           0.15      2708\n",
            "   macro avg       0.24      0.19      0.11      2708\n",
            "weighted avg       0.38      0.15      0.16      2708\n",
            "\n",
            "0.18874735852687982\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_3/transformer/mask_emb:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_3/transformer/mask_emb:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 367s 576ms/step - loss: 1.8295 - categorical_accuracy: 0.3034 - val_loss: 2.4806 - val_categorical_accuracy: 0.1780\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 348s 571ms/step - loss: 1.7853 - categorical_accuracy: 0.3122 - val_loss: 2.3538 - val_categorical_accuracy: 0.2040\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.7576 - categorical_accuracy: 0.3161 - val_loss: 2.3363 - val_categorical_accuracy: 0.2007\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.7461 - categorical_accuracy: 0.3177 - val_loss: 2.3384 - val_categorical_accuracy: 0.1968\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.7087 - categorical_accuracy: 0.3186 - val_loss: 2.2781 - val_categorical_accuracy: 0.2136\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.6835 - categorical_accuracy: 0.3368 - val_loss: 2.3187 - val_categorical_accuracy: 0.1975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.05      0.08       190\n",
            "         1.0       0.13      0.06      0.08       173\n",
            "         2.0       0.05      0.16      0.08       135\n",
            "         3.0       0.18      0.02      0.04       216\n",
            "         4.0       0.67      0.18      0.29      1036\n",
            "         5.0       0.07      0.70      0.13        76\n",
            "         6.0       0.75      0.63      0.69       195\n",
            "         7.0       0.20      0.01      0.01       290\n",
            "         8.0       0.11      0.63      0.19       139\n",
            "         9.0       0.30      0.10      0.16       258\n",
            "\n",
            "    accuracy                           0.19      2708\n",
            "   macro avg       0.26      0.26      0.17      2708\n",
            "weighted avg       0.41      0.19      0.21      2708\n",
            "\n",
            "0.2550792231250308\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_4 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_4 (Global  (None, 768)         0           ['tfxl_net_model_4[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          98432       ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_189 (Dropout)          (None, 128)          0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 32)           4128        ['dropout_189[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 201s 308ms/step - loss: 2.5020 - categorical_accuracy: 0.1349 - val_loss: 2.4125 - val_categorical_accuracy: 0.1557\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 2.2725 - categorical_accuracy: 0.2079 - val_loss: 2.2459 - val_categorical_accuracy: 0.1842\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 2.2003 - categorical_accuracy: 0.2145 - val_loss: 2.2117 - val_categorical_accuracy: 0.1977\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 184s 303ms/step - loss: 2.1255 - categorical_accuracy: 0.2326 - val_loss: 2.1517 - val_categorical_accuracy: 0.2060\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 2.0844 - categorical_accuracy: 0.2553 - val_loss: 2.0014 - val_categorical_accuracy: 0.2753\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0318 - categorical_accuracy: 0.2590 - val_loss: 2.0014 - val_categorical_accuracy: 0.2582\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.06      0.09       190\n",
            "         1.0       0.23      0.20      0.21       173\n",
            "         2.0       0.08      0.02      0.03       135\n",
            "         3.0       0.06      0.01      0.02       216\n",
            "         4.0       0.53      0.26      0.35      1036\n",
            "         5.0       0.10      0.33      0.16        76\n",
            "         6.0       0.44      0.76      0.56       195\n",
            "         7.0       0.09      0.02      0.03       290\n",
            "         8.0       0.09      0.15      0.11       139\n",
            "         9.0       0.14      0.59      0.23       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.20      0.24      0.18      2708\n",
            "weighted avg       0.30      0.25      0.23      2708\n",
            "\n",
            "0.23947849298607835\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_4/transformer/mask_emb:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_4/transformer/mask_emb:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 369s 577ms/step - loss: 2.0249 - categorical_accuracy: 0.2527 - val_loss: 2.6242 - val_categorical_accuracy: 0.1529\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.9373 - categorical_accuracy: 0.2810 - val_loss: 4.4791 - val_categorical_accuracy: 0.1430\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8812 - categorical_accuracy: 0.2906 - val_loss: 7.0807 - val_categorical_accuracy: 0.1131\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.7942 - categorical_accuracy: 0.3058 - val_loss: 9.3602 - val_categorical_accuracy: 0.1087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.25      0.01      0.03        76\n",
            "         6.0       1.00      0.01      0.01       195\n",
            "         7.0       0.11      0.98      0.19       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.13      0.03      0.06       258\n",
            "\n",
            "    accuracy                           0.11      2708\n",
            "   macro avg       0.15      0.10      0.03      2708\n",
            "weighted avg       0.10      0.11      0.03      2708\n",
            "\n",
            "0.10290318897607971\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_5 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_5 (Global  (None, 768)         0           ['tfxl_net_model_5[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 128)          98432       ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_227 (Dropout)          (None, 128)          0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 32)           4128        ['dropout_227[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 200s 308ms/step - loss: 2.4779 - categorical_accuracy: 0.1665 - val_loss: 2.3052 - val_categorical_accuracy: 0.1589\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.2438 - categorical_accuracy: 0.1999 - val_loss: 2.2409 - val_categorical_accuracy: 0.1883\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.1590 - categorical_accuracy: 0.2287 - val_loss: 2.1356 - val_categorical_accuracy: 0.2143\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.1102 - categorical_accuracy: 0.2432 - val_loss: 2.0546 - val_categorical_accuracy: 0.2393\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0367 - categorical_accuracy: 0.2646 - val_loss: 1.9889 - val_categorical_accuracy: 0.2720\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 2.0104 - categorical_accuracy: 0.2822 - val_loss: 1.9709 - val_categorical_accuracy: 0.2812\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.07      0.01      0.01       190\n",
            "         1.0       0.16      0.28      0.20       173\n",
            "         2.0       0.10      0.11      0.11       135\n",
            "         3.0       0.15      0.06      0.09       216\n",
            "         4.0       0.59      0.34      0.43      1036\n",
            "         5.0       0.10      0.45      0.17        76\n",
            "         6.0       0.51      0.76      0.61       195\n",
            "         7.0       0.19      0.08      0.11       290\n",
            "         8.0       0.14      0.12      0.13       139\n",
            "         9.0       0.16      0.43      0.23       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.22      0.26      0.21      2708\n",
            "weighted avg       0.34      0.28      0.28      2708\n",
            "\n",
            "0.26247630728901494\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_5/transformer/mask_emb:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_5/transformer/mask_emb:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 369s 577ms/step - loss: 1.9664 - categorical_accuracy: 0.2898 - val_loss: 1.9759 - val_categorical_accuracy: 0.2849\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.9583 - categorical_accuracy: 0.2884 - val_loss: 1.9425 - val_categorical_accuracy: 0.2985\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.9420 - categorical_accuracy: 0.2900 - val_loss: 1.9710 - val_categorical_accuracy: 0.2837\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.9492 - categorical_accuracy: 0.2941 - val_loss: 1.9589 - val_categorical_accuracy: 0.2797\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8985 - categorical_accuracy: 0.3052 - val_loss: 1.9899 - val_categorical_accuracy: 0.2626\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.01      0.02       190\n",
            "         1.0       0.18      0.31      0.22       173\n",
            "         2.0       0.10      0.14      0.12       135\n",
            "         3.0       0.18      0.09      0.12       216\n",
            "         4.0       0.62      0.25      0.35      1036\n",
            "         5.0       0.10      0.54      0.17        76\n",
            "         6.0       0.51      0.83      0.63       195\n",
            "         7.0       0.19      0.07      0.10       290\n",
            "         8.0       0.13      0.14      0.13       139\n",
            "         9.0       0.16      0.45      0.23       258\n",
            "\n",
            "    accuracy                           0.26      2708\n",
            "   macro avg       0.23      0.28      0.21      2708\n",
            "weighted avg       0.36      0.26      0.26      2708\n",
            "\n",
            "0.28047864299564673\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.3\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0fx9c7cGku7",
        "outputId": "1a3bf159-c6da-4ef6-d094-e0cf545640de"
      },
      "execution_count": 55,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_6 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_6 (Global  (None, 768)         0           ['tfxl_net_model_6[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 128)          98432       ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_265 (Dropout)          (None, 128)          0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 32)           4128        ['dropout_265[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 201s 308ms/step - loss: 2.2416 - categorical_accuracy: 0.2213 - val_loss: 2.0220 - val_categorical_accuracy: 0.2852\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 2.0450 - categorical_accuracy: 0.2611 - val_loss: 1.9561 - val_categorical_accuracy: 0.3354\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9813 - categorical_accuracy: 0.2771 - val_loss: 1.9792 - val_categorical_accuracy: 0.2784\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 184s 303ms/step - loss: 1.9513 - categorical_accuracy: 0.2738 - val_loss: 1.9643 - val_categorical_accuracy: 0.3020\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 184s 303ms/step - loss: 1.9146 - categorical_accuracy: 0.2956 - val_loss: 2.1042 - val_categorical_accuracy: 0.2834\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.02      0.03       190\n",
            "         1.0       0.23      0.21      0.22       173\n",
            "         2.0       0.06      0.12      0.08       135\n",
            "         3.0       0.13      0.05      0.07       216\n",
            "         4.0       0.61      0.45      0.52      1036\n",
            "         5.0       0.06      0.66      0.10        76\n",
            "         6.0       0.58      0.58      0.58       195\n",
            "         7.0       0.10      0.04      0.06       290\n",
            "         8.0       0.14      0.12      0.13       139\n",
            "         9.0       0.21      0.07      0.11       258\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.22      0.23      0.19      2708\n",
            "weighted avg       0.35      0.27      0.29      2708\n",
            "\n",
            "0.23162926029551842\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_6/transformer/mask_emb:0', 'tfxl_net_model_6/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_6/transformer/mask_emb:0', 'tfxl_net_model_6/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "609/609 [==============================] - 370s 577ms/step - loss: 1.8932 - categorical_accuracy: 0.2919 - val_loss: 2.3228 - val_categorical_accuracy: 0.2220\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8394 - categorical_accuracy: 0.3015 - val_loss: 3.0788 - val_categorical_accuracy: 0.1644\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.7437 - categorical_accuracy: 0.3261 - val_loss: 5.7411 - val_categorical_accuracy: 0.0772\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.6705 - categorical_accuracy: 0.3432 - val_loss: 4.0015 - val_categorical_accuracy: 0.1953\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.20      0.31      0.24       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.07      0.00      0.01       216\n",
            "         4.0       0.53      0.28      0.37      1036\n",
            "         5.0       0.06      0.32      0.10        76\n",
            "         6.0       0.00      0.00      0.00       195\n",
            "         7.0       0.13      0.45      0.20       290\n",
            "         8.0       0.07      0.18      0.11       139\n",
            "         9.0       0.18      0.08      0.11       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.12      0.16      0.11      2708\n",
            "weighted avg       0.26      0.20      0.20      2708\n",
            "\n",
            "0.16206411175809188\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_7 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_7 (Global  (None, 768)         0           ['tfxl_net_model_7[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_7[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 128)          98432       ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_303 (Dropout)          (None, 128)          0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 32)           4128        ['dropout_303[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 201s 308ms/step - loss: 2.2598 - categorical_accuracy: 0.2005 - val_loss: 2.0799 - val_categorical_accuracy: 0.2487\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0399 - categorical_accuracy: 0.2453 - val_loss: 2.1803 - val_categorical_accuracy: 0.2369\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 1.9557 - categorical_accuracy: 0.2683 - val_loss: 2.1664 - val_categorical_accuracy: 0.2431\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 1.9367 - categorical_accuracy: 0.2683 - val_loss: 2.0847 - val_categorical_accuracy: 0.2352\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.09      0.02      0.03       190\n",
            "         1.0       0.30      0.03      0.06       173\n",
            "         2.0       0.05      0.04      0.04       135\n",
            "         3.0       0.11      0.01      0.02       216\n",
            "         4.0       0.56      0.25      0.34      1036\n",
            "         5.0       0.09      0.59      0.15        76\n",
            "         6.0       0.42      0.82      0.56       195\n",
            "         7.0       0.06      0.00      0.01       290\n",
            "         8.0       0.09      0.57      0.15       139\n",
            "         9.0       0.23      0.26      0.25       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.20      0.26      0.16      2708\n",
            "weighted avg       0.32      0.23      0.22      2708\n",
            "\n",
            "0.259281492372152\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_7/transformer/mask_emb:0', 'tfxl_net_model_7/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_7/transformer/mask_emb:0', 'tfxl_net_model_7/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 369s 577ms/step - loss: 1.8582 - categorical_accuracy: 0.2908 - val_loss: 2.0708 - val_categorical_accuracy: 0.2356\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8510 - categorical_accuracy: 0.2937 - val_loss: 2.0226 - val_categorical_accuracy: 0.2510\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8142 - categorical_accuracy: 0.3007 - val_loss: 2.1393 - val_categorical_accuracy: 0.2248\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8372 - categorical_accuracy: 0.2980 - val_loss: 2.0585 - val_categorical_accuracy: 0.2468\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.7871 - categorical_accuracy: 0.2939 - val_loss: 1.9868 - val_categorical_accuracy: 0.2574\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.7708 - categorical_accuracy: 0.3079 - val_loss: 2.0328 - val_categorical_accuracy: 0.2497\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.04      0.06       190\n",
            "         1.0       0.27      0.08      0.12       173\n",
            "         2.0       0.06      0.04      0.05       135\n",
            "         3.0       0.06      0.00      0.01       216\n",
            "         4.0       0.60      0.25      0.35      1036\n",
            "         5.0       0.09      0.63      0.16        76\n",
            "         6.0       0.46      0.85      0.60       195\n",
            "         7.0       0.33      0.01      0.02       290\n",
            "         8.0       0.09      0.52      0.16       139\n",
            "         9.0       0.24      0.36      0.29       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.24      0.28      0.18      2708\n",
            "weighted avg       0.37      0.25      0.23      2708\n",
            "\n",
            "0.2781438881796395\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_8 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_8 (Global  (None, 768)         0           ['tfxl_net_model_8[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_8[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 128)          98432       ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_341 (Dropout)          (None, 128)          0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 32)           4128        ['dropout_341[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 201s 309ms/step - loss: 2.5543 - categorical_accuracy: 0.0905 - val_loss: 2.3156 - val_categorical_accuracy: 0.1285\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.3260 - categorical_accuracy: 0.1447 - val_loss: 2.2775 - val_categorical_accuracy: 0.1342\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 303ms/step - loss: 2.2298 - categorical_accuracy: 0.1845 - val_loss: 2.2929 - val_categorical_accuracy: 0.1337\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.1808 - categorical_accuracy: 0.2055 - val_loss: 2.1733 - val_categorical_accuracy: 0.1747\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.1212 - categorical_accuracy: 0.2235 - val_loss: 2.1249 - val_categorical_accuracy: 0.1993\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 184s 303ms/step - loss: 2.0788 - categorical_accuracy: 0.2282 - val_loss: 2.1082 - val_categorical_accuracy: 0.2106\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.03      0.05       190\n",
            "         1.0       0.16      0.20      0.18       173\n",
            "         2.0       0.12      0.08      0.10       135\n",
            "         3.0       0.17      0.03      0.05       216\n",
            "         4.0       0.58      0.20      0.30      1036\n",
            "         5.0       0.12      0.22      0.16        76\n",
            "         6.0       0.19      0.93      0.32       195\n",
            "         7.0       0.14      0.03      0.06       290\n",
            "         8.0       0.12      0.22      0.16       139\n",
            "         9.0       0.18      0.40      0.25       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.20      0.23      0.16      2708\n",
            "weighted avg       0.32      0.22      0.20      2708\n",
            "\n",
            "0.2341511908052322\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_8/transformer/mask_emb:0', 'tfxl_net_model_8/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_8/transformer/mask_emb:0', 'tfxl_net_model_8/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 368s 577ms/step - loss: 2.0581 - categorical_accuracy: 0.2268 - val_loss: 2.0726 - val_categorical_accuracy: 0.2698\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 349s 573ms/step - loss: 2.0124 - categorical_accuracy: 0.2342 - val_loss: 4.6652 - val_categorical_accuracy: 0.1186\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 349s 573ms/step - loss: 1.9310 - categorical_accuracy: 0.2498 - val_loss: 5.4144 - val_categorical_accuracy: 0.0966\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.8356 - categorical_accuracy: 0.2740 - val_loss: 9.1374 - val_categorical_accuracy: 0.1012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.08      0.24      0.12       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.00      0.00      0.00       195\n",
            "         7.0       1.00      0.00      0.01       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.10      0.93      0.19       258\n",
            "\n",
            "    accuracy                           0.10      2708\n",
            "   macro avg       0.12      0.12      0.03      2708\n",
            "weighted avg       0.12      0.10      0.02      2708\n",
            "\n",
            "0.11781252784460483\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_9 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_9 (Global  (None, 768)         0           ['tfxl_net_model_9[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_9[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 128)          98432       ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_379 (Dropout)          (None, 128)          0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 32)           4128        ['dropout_379[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 203s 309ms/step - loss: 2.4832 - categorical_accuracy: 0.1201 - val_loss: 2.4002 - val_categorical_accuracy: 0.1200\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.2840 - categorical_accuracy: 0.1626 - val_loss: 2.2861 - val_categorical_accuracy: 0.1591\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.1864 - categorical_accuracy: 0.1960 - val_loss: 2.1740 - val_categorical_accuracy: 0.1980\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.1366 - categorical_accuracy: 0.2112 - val_loss: 2.0730 - val_categorical_accuracy: 0.2367\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.1095 - categorical_accuracy: 0.2174 - val_loss: 2.0760 - val_categorical_accuracy: 0.2206\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 185s 304ms/step - loss: 2.0651 - categorical_accuracy: 0.2323 - val_loss: 2.0459 - val_categorical_accuracy: 0.2364\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.14      0.15       190\n",
            "         1.0       0.21      0.09      0.12       173\n",
            "         2.0       0.09      0.04      0.05       135\n",
            "         3.0       0.17      0.03      0.05       216\n",
            "         4.0       0.51      0.25      0.33      1036\n",
            "         5.0       0.09      0.22      0.13        76\n",
            "         6.0       0.29      0.90      0.44       195\n",
            "         7.0       0.20      0.01      0.02       290\n",
            "         8.0       0.08      0.09      0.09       139\n",
            "         9.0       0.15      0.53      0.24       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.20      0.23      0.16      2708\n",
            "weighted avg       0.30      0.24      0.22      2708\n",
            "\n",
            "0.23041327896217098\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_9/transformer/mask_emb:0', 'tfxl_net_model_9/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_9/transformer/mask_emb:0', 'tfxl_net_model_9/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 370s 577ms/step - loss: 2.0362 - categorical_accuracy: 0.2447 - val_loss: 2.0282 - val_categorical_accuracy: 0.2475\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 349s 573ms/step - loss: 2.0138 - categorical_accuracy: 0.2553 - val_loss: 2.0398 - val_categorical_accuracy: 0.2334\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 348s 572ms/step - loss: 1.9878 - categorical_accuracy: 0.2644 - val_loss: 2.0514 - val_categorical_accuracy: 0.2314\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 349s 573ms/step - loss: 1.9687 - categorical_accuracy: 0.2664 - val_loss: 2.0502 - val_categorical_accuracy: 0.2317\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.13      0.14       190\n",
            "         1.0       0.20      0.16      0.18       173\n",
            "         2.0       0.03      0.01      0.01       135\n",
            "         3.0       0.24      0.04      0.07       216\n",
            "         4.0       0.57      0.17      0.26      1036\n",
            "         5.0       0.09      0.42      0.15        76\n",
            "         6.0       0.32      0.88      0.47       195\n",
            "         7.0       0.23      0.02      0.03       290\n",
            "         8.0       0.08      0.10      0.09       139\n",
            "         9.0       0.16      0.58      0.24       258\n",
            "\n",
            "    accuracy                           0.23      2708\n",
            "   macro avg       0.21      0.25      0.17      2708\n",
            "weighted avg       0.33      0.23      0.20      2708\n",
            "\n",
            "0.2506673092625805\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.4\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c992a06f792b4d158747c636b390f648",
            "0c78dff24c254be992f0a1d2f51ae375",
            "33aa1b0d7c4d47ed90b01974b38ce121",
            "7261064cb3ec46269b336e08d8b59962",
            "7987c66c7fb04e9c9f83fcad09efc069",
            "f8513e843b4741c49b92b46178e6129f",
            "5b9c80d47cbe44babef162f7e25348f5",
            "36069839ef8a4db6a80bb77da38fd8b2",
            "66fbd7f7f7e74d72ae5317829a1968c9",
            "408a92e9d6a94570a50961ca51d4e46f",
            "d28abc35c7e2438e803f8bd1fc07967b"
          ]
        },
        "id": "uopcWqIhYxgA",
        "outputId": "5b6ea8df-75ab-4f35-ef75-35ee79ec4c3e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/539M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c992a06f792b4d158747c636b390f648"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model (TFXLNetModel)  TFXLNetModelOutput(  116718336   ['input_ids[0][0]',              \n",
            "                                last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tfxl_net_model[0][0]']         \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 171ms/step - loss: 2.3128 - categorical_accuracy: 0.1942 - val_loss: 2.2133 - val_categorical_accuracy: 0.2012\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0816 - categorical_accuracy: 0.2432 - val_loss: 2.6120 - val_categorical_accuracy: 0.1587\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 1.9952 - categorical_accuracy: 0.2623 - val_loss: 1.9427 - val_categorical_accuracy: 0.2720\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 1.9684 - categorical_accuracy: 0.2572 - val_loss: 2.1083 - val_categorical_accuracy: 0.2163\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 1.9259 - categorical_accuracy: 0.2640 - val_loss: 2.1085 - val_categorical_accuracy: 0.2059\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 1.9005 - categorical_accuracy: 0.2662 - val_loss: 2.1256 - val_categorical_accuracy: 0.2128\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.04      0.06       190\n",
            "         1.0       0.21      0.08      0.12       173\n",
            "         2.0       0.06      0.11      0.07       135\n",
            "         3.0       0.60      0.01      0.03       216\n",
            "         4.0       0.68      0.21      0.32      1036\n",
            "         5.0       0.12      0.26      0.16        76\n",
            "         6.0       0.77      0.45      0.57       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.09      0.76      0.16       139\n",
            "         9.0       0.21      0.39      0.27       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.28      0.23      0.18      2708\n",
            "weighted avg       0.41      0.21      0.22      2708\n",
            "\n",
            "0.2324590166368452\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 207s 317ms/step - loss: 1.9209 - categorical_accuracy: 0.2631 - val_loss: 2.8431 - val_categorical_accuracy: 0.1302\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8238 - categorical_accuracy: 0.2755 - val_loss: 6.9801 - val_categorical_accuracy: 0.1188\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.7483 - categorical_accuracy: 0.3032 - val_loss: 9.6620 - val_categorical_accuracy: 0.1107\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.6547 - categorical_accuracy: 0.3313 - val_loss: 10.0965 - val_categorical_accuracy: 0.1012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.42      0.03      0.05       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.39      0.02      0.04      1036\n",
            "         5.0       0.00      0.00      0.00        76\n",
            "         6.0       0.00      0.00      0.00       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.10      1.00      0.18       258\n",
            "\n",
            "    accuracy                           0.10      2708\n",
            "   macro avg       0.09      0.10      0.03      2708\n",
            "weighted avg       0.19      0.10      0.03      2708\n",
            "\n",
            "0.10446555578134527\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_1 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['tfxl_net_model_1[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          98432       ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 128)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           4128        ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 114s 171ms/step - loss: 2.3457 - categorical_accuracy: 0.2190 - val_loss: 2.1854 - val_categorical_accuracy: 0.2015\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1078 - categorical_accuracy: 0.2564 - val_loss: 2.0946 - val_categorical_accuracy: 0.2364\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0124 - categorical_accuracy: 0.2769 - val_loss: 2.1718 - val_categorical_accuracy: 0.2341\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 2.0043 - categorical_accuracy: 0.2748 - val_loss: 2.0104 - val_categorical_accuracy: 0.2963\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 1.9572 - categorical_accuracy: 0.2880 - val_loss: 2.0624 - val_categorical_accuracy: 0.2349\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 1.9535 - categorical_accuracy: 0.2759 - val_loss: 2.4118 - val_categorical_accuracy: 0.1466\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.13      0.11       190\n",
            "         1.0       0.29      0.07      0.11       173\n",
            "         2.0       0.04      0.04      0.04       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.70      0.09      0.17      1036\n",
            "         5.0       0.06      0.66      0.11        76\n",
            "         6.0       0.55      0.29      0.38       195\n",
            "         7.0       0.09      0.02      0.03       290\n",
            "         8.0       0.09      0.65      0.16       139\n",
            "         9.0       0.25      0.16      0.20       258\n",
            "\n",
            "    accuracy                           0.14      2708\n",
            "   macro avg       0.22      0.21      0.13      2708\n",
            "weighted avg       0.37      0.14      0.14      2708\n",
            "\n",
            "0.2099899898349872\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_1/transformer/mask_emb:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_1/transformer/mask_emb:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 207s 317ms/step - loss: 1.8970 - categorical_accuracy: 0.2724 - val_loss: 2.4457 - val_categorical_accuracy: 0.1560\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8660 - categorical_accuracy: 0.2820 - val_loss: 2.3347 - val_categorical_accuracy: 0.1784\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8513 - categorical_accuracy: 0.2927 - val_loss: 2.3587 - val_categorical_accuracy: 0.1757\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8178 - categorical_accuracy: 0.2972 - val_loss: 2.3349 - val_categorical_accuracy: 0.1775\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8024 - categorical_accuracy: 0.3007 - val_loss: 2.3418 - val_categorical_accuracy: 0.1758\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.15      0.12       190\n",
            "         1.0       0.24      0.06      0.09       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.69      0.07      0.12      1036\n",
            "         5.0       0.07      0.68      0.12        76\n",
            "         6.0       0.62      0.66      0.64       195\n",
            "         7.0       0.06      0.01      0.01       290\n",
            "         8.0       0.09      0.60      0.16       139\n",
            "         9.0       0.25      0.29      0.27       258\n",
            "\n",
            "    accuracy                           0.17      2708\n",
            "   macro avg       0.21      0.25      0.15      2708\n",
            "weighted avg       0.37      0.17      0.14      2708\n",
            "\n",
            "0.25172164795214164\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_2 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 768)         0           ['tfxl_net_model_2[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          98432       ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_113 (Dropout)          (None, 128)          0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 32)           4128        ['dropout_113[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 171ms/step - loss: 2.5537 - categorical_accuracy: 0.1521 - val_loss: 2.2356 - val_categorical_accuracy: 0.1968\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 103s 168ms/step - loss: 2.3372 - categorical_accuracy: 0.1917 - val_loss: 2.1913 - val_categorical_accuracy: 0.2050\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.2449 - categorical_accuracy: 0.2059 - val_loss: 2.0890 - val_categorical_accuracy: 0.2409\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1653 - categorical_accuracy: 0.2215 - val_loss: 2.0696 - val_categorical_accuracy: 0.2314\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 103s 168ms/step - loss: 2.1174 - categorical_accuracy: 0.2231 - val_loss: 2.0347 - val_categorical_accuracy: 0.2367\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1041 - categorical_accuracy: 0.2422 - val_loss: 2.0149 - val_categorical_accuracy: 0.2356\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.21      0.07      0.10       190\n",
            "         1.0       0.18      0.06      0.09       173\n",
            "         2.0       0.06      0.01      0.02       135\n",
            "         3.0       0.19      0.06      0.09       216\n",
            "         4.0       0.55      0.19      0.28      1036\n",
            "         5.0       0.18      0.30      0.23        76\n",
            "         6.0       0.36      0.81      0.50       195\n",
            "         7.0       0.18      0.03      0.05       290\n",
            "         8.0       0.07      0.17      0.10       139\n",
            "         9.0       0.13      0.62      0.22       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.21      0.23      0.17      2708\n",
            "weighted avg       0.32      0.22      0.20      2708\n",
            "\n",
            "0.23204959532240785\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 206s 316ms/step - loss: 2.1026 - categorical_accuracy: 0.2231 - val_loss: 2.7049 - val_categorical_accuracy: 0.3622\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0098 - categorical_accuracy: 0.2430 - val_loss: 7.3358 - val_categorical_accuracy: 0.1314\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.9447 - categorical_accuracy: 0.2580 - val_loss: 21.9067 - val_categorical_accuracy: 0.0683\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8625 - categorical_accuracy: 0.2709 - val_loss: 7.0840 - val_categorical_accuracy: 0.1208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.31      0.01      0.02      1036\n",
            "         5.0       1.00      0.01      0.03        76\n",
            "         6.0       1.00      0.06      0.12       195\n",
            "         7.0       0.16      0.12      0.14       290\n",
            "         8.0       0.08      0.73      0.14       139\n",
            "         9.0       0.16      0.69      0.26       258\n",
            "\n",
            "    accuracy                           0.12      2708\n",
            "   macro avg       0.27      0.16      0.07      2708\n",
            "weighted avg       0.26      0.12      0.06      2708\n",
            "\n",
            "0.1628236393525598\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_3 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Global  (None, 768)         0           ['tfxl_net_model_3[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          98432       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_151 (Dropout)          (None, 128)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 32)           4128        ['dropout_151[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 172ms/step - loss: 2.6529 - categorical_accuracy: 0.0915 - val_loss: 2.3496 - val_categorical_accuracy: 0.1275\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.4187 - categorical_accuracy: 0.1431 - val_loss: 2.2230 - val_categorical_accuracy: 0.1572\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.2930 - categorical_accuracy: 0.1714 - val_loss: 2.1563 - val_categorical_accuracy: 0.1911\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.2284 - categorical_accuracy: 0.1827 - val_loss: 2.1152 - val_categorical_accuracy: 0.2124\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1654 - categorical_accuracy: 0.1964 - val_loss: 2.0491 - val_categorical_accuracy: 0.2441\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1223 - categorical_accuracy: 0.2161 - val_loss: 1.9985 - val_categorical_accuracy: 0.2752\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.04      0.05       190\n",
            "         1.0       0.14      0.06      0.08       173\n",
            "         2.0       0.08      0.04      0.05       135\n",
            "         3.0       0.13      0.15      0.14       216\n",
            "         4.0       0.55      0.39      0.45      1036\n",
            "         5.0       0.07      0.04      0.05        76\n",
            "         6.0       0.27      0.91      0.42       195\n",
            "         7.0       0.15      0.17      0.16       290\n",
            "         8.0       0.07      0.03      0.04       139\n",
            "         9.0       0.19      0.32      0.24       258\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.17      0.21      0.17      2708\n",
            "weighted avg       0.30      0.28      0.27      2708\n",
            "\n",
            "0.2128885192484952\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_3/transformer/mask_emb:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_3/transformer/mask_emb:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 205s 315ms/step - loss: 2.1169 - categorical_accuracy: 0.2190 - val_loss: 2.0114 - val_categorical_accuracy: 0.2599\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 311ms/step - loss: 2.0638 - categorical_accuracy: 0.2217 - val_loss: 2.0052 - val_categorical_accuracy: 0.2634\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0595 - categorical_accuracy: 0.2336 - val_loss: 1.9836 - val_categorical_accuracy: 0.2728\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 311ms/step - loss: 2.0490 - categorical_accuracy: 0.2416 - val_loss: 1.9680 - val_categorical_accuracy: 0.2824\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0231 - categorical_accuracy: 0.2379 - val_loss: 1.9774 - val_categorical_accuracy: 0.2725\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.9928 - categorical_accuracy: 0.2486 - val_loss: 1.9590 - val_categorical_accuracy: 0.2792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.11      0.13       190\n",
            "         1.0       0.23      0.12      0.16       173\n",
            "         2.0       0.08      0.04      0.05       135\n",
            "         3.0       0.14      0.17      0.15       216\n",
            "         4.0       0.60      0.33      0.43      1036\n",
            "         5.0       0.18      0.21      0.19        76\n",
            "         6.0       0.30      0.91      0.45       195\n",
            "         7.0       0.15      0.18      0.16       290\n",
            "         8.0       0.10      0.03      0.04       139\n",
            "         9.0       0.21      0.42      0.28       258\n",
            "\n",
            "    accuracy                           0.29      2708\n",
            "   macro avg       0.22      0.25      0.21      2708\n",
            "weighted avg       0.34      0.29      0.28      2708\n",
            "\n",
            "0.25202302002203886\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "#drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "drop_out_rate = 0.5\n",
        "learning_rate_transfer_learnings = [1e-3, 1e-4]\n",
        "learning_rate_fine_tunings = [1e-5, 1e-6]\n",
        "\n",
        "for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "  for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "    print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "    , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "    #step1\n",
        "    #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "    xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "    mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "    embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "    X = tf.keras.layers.BatchNormalization()(X)\n",
        "    X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "    X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "    X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "    y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "    model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "    model1.layers[2].trainable = False\n",
        "    print(model1.summary())\n",
        "\n",
        "    #step2\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "    #model2.summary() #Check trainable params increased.\n",
        "\n",
        "    #step3: transfer learning\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "    #step4: predict\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "    #step5: fine tune\n",
        "    print(\"Fine tuning---------------\")\n",
        "    model1.layers[2].trainable = True\n",
        "\n",
        "    # It's important to recompile your model after you make any changes\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "    metrics = []\n",
        "    metrics.append(\n",
        "        tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "    model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "    history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "    balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "    balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "    print(\"----------------------------------------\")\n",
        "    del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYk5hfgpknUG",
        "outputId": "797cdd00-05fa-41a9-fc44-8ac4ad137db9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_4 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_4 (Global  (None, 768)         0           ['tfxl_net_model_4[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_4[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 128)          98432       ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_189 (Dropout)          (None, 128)          0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 32)           4128        ['dropout_189[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 171ms/step - loss: 2.3302 - categorical_accuracy: 0.2126 - val_loss: 2.2504 - val_categorical_accuracy: 0.1820\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1073 - categorical_accuracy: 0.2172 - val_loss: 2.1631 - val_categorical_accuracy: 0.1846\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0337 - categorical_accuracy: 0.2506 - val_loss: 2.1172 - val_categorical_accuracy: 0.2117\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.0141 - categorical_accuracy: 0.2549 - val_loss: 2.1543 - val_categorical_accuracy: 0.1973\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 1.9952 - categorical_accuracy: 0.2609 - val_loss: 2.0661 - val_categorical_accuracy: 0.2523\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 1.9524 - categorical_accuracy: 0.2644 - val_loss: 2.2388 - val_categorical_accuracy: 0.2005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.02      0.03       190\n",
            "         1.0       0.21      0.03      0.05       173\n",
            "         2.0       0.10      0.06      0.07       135\n",
            "         3.0       0.05      0.01      0.02       216\n",
            "         4.0       0.70      0.23      0.34      1036\n",
            "         5.0       0.08      0.61      0.14        76\n",
            "         6.0       0.52      0.63      0.57       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.08      0.72      0.15       139\n",
            "         9.0       0.21      0.15      0.18       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.21      0.24      0.15      2708\n",
            "weighted avg       0.36      0.21      0.21      2708\n",
            "\n",
            "0.24415351378058436\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_4/transformer/mask_emb:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_4/transformer/mask_emb:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_4/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 207s 316ms/step - loss: 1.9833 - categorical_accuracy: 0.2646 - val_loss: 3.1798 - val_categorical_accuracy: 0.1099\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.9190 - categorical_accuracy: 0.2794 - val_loss: 2.0034 - val_categorical_accuracy: 0.2742\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8169 - categorical_accuracy: 0.3032 - val_loss: 2.7708 - val_categorical_accuracy: 0.2070\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.7891 - categorical_accuracy: 0.3118 - val_loss: 2.4375 - val_categorical_accuracy: 0.2336\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.7465 - categorical_accuracy: 0.3212 - val_loss: 2.5147 - val_categorical_accuracy: 0.2497\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.01      0.02       190\n",
            "         1.0       0.15      0.02      0.03       173\n",
            "         2.0       0.04      0.03      0.03       135\n",
            "         3.0       0.10      0.09      0.09       216\n",
            "         4.0       0.67      0.31      0.42      1036\n",
            "         5.0       0.10      0.64      0.17        76\n",
            "         6.0       0.68      0.70      0.69       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.09      0.68      0.16       139\n",
            "         9.0       0.21      0.08      0.12       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.23      0.26      0.17      2708\n",
            "weighted avg       0.37      0.24      0.25      2708\n",
            "\n",
            "0.2563292085443747\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_5 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_5 (Global  (None, 768)         0           ['tfxl_net_model_5[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_5[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 128)          98432       ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_227 (Dropout)          (None, 128)          0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 32)           4128        ['dropout_227[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 116s 173ms/step - loss: 2.3331 - categorical_accuracy: 0.1782 - val_loss: 2.1752 - val_categorical_accuracy: 0.1807\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.1484 - categorical_accuracy: 0.2137 - val_loss: 2.0811 - val_categorical_accuracy: 0.2471\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.0589 - categorical_accuracy: 0.2317 - val_loss: 2.1276 - val_categorical_accuracy: 0.2228\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.0135 - categorical_accuracy: 0.2527 - val_loss: 2.0291 - val_categorical_accuracy: 0.2418\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 1.9736 - categorical_accuracy: 0.2551 - val_loss: 2.0176 - val_categorical_accuracy: 0.2634\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 1.9529 - categorical_accuracy: 0.2510 - val_loss: 2.0771 - val_categorical_accuracy: 0.2109\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.08      0.01      0.01       190\n",
            "         1.0       0.22      0.08      0.12       173\n",
            "         2.0       0.07      0.07      0.07       135\n",
            "         3.0       1.00      0.00      0.01       216\n",
            "         4.0       0.71      0.16      0.26      1036\n",
            "         5.0       0.06      0.68      0.12        76\n",
            "         6.0       0.40      0.78      0.53       195\n",
            "         7.0       0.16      0.21      0.18       290\n",
            "         8.0       0.11      0.19      0.14       139\n",
            "         9.0       0.20      0.35      0.25       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.30      0.25      0.17      2708\n",
            "weighted avg       0.45      0.21      0.20      2708\n",
            "\n",
            "0.25372859319576146\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_5/transformer/mask_emb:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_5/transformer/mask_emb:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_5/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 208s 317ms/step - loss: 1.9150 - categorical_accuracy: 0.2523 - val_loss: 2.0578 - val_categorical_accuracy: 0.2114\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8968 - categorical_accuracy: 0.2631 - val_loss: 2.0795 - val_categorical_accuracy: 0.2086\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.8696 - categorical_accuracy: 0.2713 - val_loss: 2.0684 - val_categorical_accuracy: 0.2112\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.8661 - categorical_accuracy: 0.2728 - val_loss: 2.0843 - val_categorical_accuracy: 0.2097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.27      0.12      0.17       173\n",
            "         2.0       0.07      0.04      0.05       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.75      0.13      0.21      1036\n",
            "         5.0       0.07      0.72      0.13        76\n",
            "         6.0       0.39      0.83      0.53       195\n",
            "         7.0       0.14      0.16      0.15       290\n",
            "         8.0       0.14      0.28      0.18       139\n",
            "         9.0       0.20      0.42      0.27       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.20      0.27      0.17      2708\n",
            "weighted avg       0.38      0.21      0.19      2708\n",
            "\n",
            "0.26983573071646233\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-05 drop_out_rate: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_6 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_6 (Global  (None, 768)         0           ['tfxl_net_model_6[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_6[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 128)          98432       ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_265 (Dropout)          (None, 128)          0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 32)           4128        ['dropout_265[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 116s 172ms/step - loss: 2.6393 - categorical_accuracy: 0.1174 - val_loss: 2.4973 - val_categorical_accuracy: 0.1047\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.4074 - categorical_accuracy: 0.1470 - val_loss: 2.4840 - val_categorical_accuracy: 0.1045\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.3057 - categorical_accuracy: 0.1716 - val_loss: 2.3156 - val_categorical_accuracy: 0.1401\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.2487 - categorical_accuracy: 0.1853 - val_loss: 2.3137 - val_categorical_accuracy: 0.1411\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.2101 - categorical_accuracy: 0.1991 - val_loss: 2.2310 - val_categorical_accuracy: 0.1770\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1527 - categorical_accuracy: 0.2165 - val_loss: 2.1517 - val_categorical_accuracy: 0.2114\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.11      0.03      0.05       190\n",
            "         1.0       0.15      0.16      0.15       173\n",
            "         2.0       0.08      0.08      0.08       135\n",
            "         3.0       0.14      0.03      0.05       216\n",
            "         4.0       0.53      0.19      0.28      1036\n",
            "         5.0       0.08      0.16      0.11        76\n",
            "         6.0       0.21      0.89      0.34       195\n",
            "         7.0       0.16      0.04      0.06       290\n",
            "         8.0       0.00      0.00      0.00       139\n",
            "         9.0       0.14      0.47      0.22       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.16      0.21      0.13      2708\n",
            "weighted avg       0.28      0.21      0.18      2708\n",
            "\n",
            "0.2050762819329918\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_6/transformer/mask_emb:0', 'tfxl_net_model_6/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_6/transformer/mask_emb:0', 'tfxl_net_model_6/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_6/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_6/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 207s 316ms/step - loss: 2.1784 - categorical_accuracy: 0.2092 - val_loss: 2.3639 - val_categorical_accuracy: 0.1119\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 191s 314ms/step - loss: 2.0784 - categorical_accuracy: 0.2360 - val_loss: 2.4108 - val_categorical_accuracy: 0.1545\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 191s 314ms/step - loss: 2.0315 - categorical_accuracy: 0.2541 - val_loss: 6.3086 - val_categorical_accuracy: 0.1054\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 191s 314ms/step - loss: 1.9695 - categorical_accuracy: 0.2564 - val_loss: 4.7776 - val_categorical_accuracy: 0.1198\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 191s 314ms/step - loss: 1.9131 - categorical_accuracy: 0.2701 - val_loss: 6.1689 - val_categorical_accuracy: 0.0466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       190\n",
            "         1.0       0.00      0.00      0.00       173\n",
            "         2.0       0.00      0.00      0.00       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.00      0.00      0.00      1036\n",
            "         5.0       0.03      0.91      0.05        76\n",
            "         6.0       1.00      0.16      0.28       195\n",
            "         7.0       0.00      0.00      0.00       290\n",
            "         8.0       0.11      0.15      0.12       139\n",
            "         9.0       0.00      0.00      0.00       258\n",
            "\n",
            "    accuracy                           0.05      2708\n",
            "   macro avg       0.11      0.12      0.05      2708\n",
            "weighted avg       0.08      0.05      0.03      2708\n",
            "\n",
            "0.12230764376353169\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-06 drop_out_rate: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_7 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_7 (Global  (None, 768)         0           ['tfxl_net_model_7[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_7[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 128)          98432       ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_303 (Dropout)          (None, 128)          0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 32)           4128        ['dropout_303[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 116s 172ms/step - loss: 2.7251 - categorical_accuracy: 0.1127 - val_loss: 2.2965 - val_categorical_accuracy: 0.1537\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.4823 - categorical_accuracy: 0.1507 - val_loss: 2.2557 - val_categorical_accuracy: 0.1676\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.3287 - categorical_accuracy: 0.1821 - val_loss: 2.1656 - val_categorical_accuracy: 0.2032\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.2701 - categorical_accuracy: 0.2112 - val_loss: 2.1909 - val_categorical_accuracy: 0.1864\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.1989 - categorical_accuracy: 0.2172 - val_loss: 2.1342 - val_categorical_accuracy: 0.2034\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.1664 - categorical_accuracy: 0.2336 - val_loss: 2.1004 - val_categorical_accuracy: 0.2225\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.22      0.06      0.09       190\n",
            "         1.0       0.15      0.09      0.11       173\n",
            "         2.0       0.09      0.01      0.03       135\n",
            "         3.0       0.19      0.06      0.09       216\n",
            "         4.0       0.59      0.21      0.31      1036\n",
            "         5.0       0.08      0.13      0.10        76\n",
            "         6.0       0.21      0.92      0.35       195\n",
            "         7.0       0.21      0.07      0.10       290\n",
            "         8.0       0.10      0.05      0.07       139\n",
            "         9.0       0.14      0.52      0.22       258\n",
            "\n",
            "    accuracy                           0.22      2708\n",
            "   macro avg       0.20      0.21      0.15      2708\n",
            "weighted avg       0.33      0.22      0.20      2708\n",
            "\n",
            "0.21155471026591047\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_7/transformer/mask_emb:0', 'tfxl_net_model_7/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_7/transformer/mask_emb:0', 'tfxl_net_model_7/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_7/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_7/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 208s 316ms/step - loss: 2.1149 - categorical_accuracy: 0.2434 - val_loss: 2.0989 - val_categorical_accuracy: 0.2143\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 2.1155 - categorical_accuracy: 0.2440 - val_loss: 2.0738 - val_categorical_accuracy: 0.2319\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 191s 313ms/step - loss: 2.0958 - categorical_accuracy: 0.2479 - val_loss: 2.0429 - val_categorical_accuracy: 0.2483\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0865 - categorical_accuracy: 0.2580 - val_loss: 2.0242 - val_categorical_accuracy: 0.2515\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 2.0683 - categorical_accuracy: 0.2469 - val_loss: 2.0400 - val_categorical_accuracy: 0.2406\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 191s 313ms/step - loss: 2.0439 - categorical_accuracy: 0.2670 - val_loss: 2.0403 - val_categorical_accuracy: 0.2314\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.18      0.08      0.11       190\n",
            "         1.0       0.19      0.21      0.20       173\n",
            "         2.0       0.07      0.01      0.02       135\n",
            "         3.0       0.16      0.06      0.09       216\n",
            "         4.0       0.62      0.20      0.30      1036\n",
            "         5.0       0.08      0.25      0.12        76\n",
            "         6.0       0.28      0.91      0.43       195\n",
            "         7.0       0.21      0.08      0.11       290\n",
            "         8.0       0.10      0.06      0.08       139\n",
            "         9.0       0.15      0.53      0.23       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.20      0.24      0.17      2708\n",
            "weighted avg       0.34      0.24      0.22      2708\n",
            "\n",
            "0.2406308711493444\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "drop_out_rates = [0.1, 0.2, 0.3,0.4, 0.5]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "#drop_out_rate = 0.5\n",
        "learning_rate_transfer_learnings = [1e-4]\n",
        "learning_rate_fine_tunings = [1e-7]\n",
        "\n",
        "for drop_out_rate in drop_out_rates:\n",
        "  for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "    for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "      print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "      , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "      #step1\n",
        "      #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "      xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "      input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "      mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "      embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "      X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "      X = tf.keras.layers.BatchNormalization()(X)\n",
        "      X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "      X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "      X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "      y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "      model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "      model1.layers[2].trainable = False\n",
        "      print(model1.summary())\n",
        "\n",
        "      #step2\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "      metrics = []\n",
        "      metrics.append(\n",
        "          tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "      model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "      #model2.summary() #Check trainable params increased.\n",
        "\n",
        "      #step3: transfer learning\n",
        "      early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "      history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "      #step4: predict\n",
        "      balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "      balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "      #step5: fine tune\n",
        "      print(\"Fine tuning---------------\")\n",
        "      model1.layers[2].trainable = True\n",
        "\n",
        "      # It's important to recompile your model after you make any changes\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "      metrics = []\n",
        "      metrics.append(\n",
        "          tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "      model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "      history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "      balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "      balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "      print(\"----------------------------------------\")\n",
        "      del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0KFqA4qkxsz",
        "outputId": "f2606983-40b5-41f5-d189-9c9ea507ae57"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-07 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_8 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_8 (Global  (None, 768)         0           ['tfxl_net_model_8[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_8[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 128)          98432       ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_341 (Dropout)          (None, 128)          0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 32)           4128        ['dropout_341[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 116s 173ms/step - loss: 2.4853 - categorical_accuracy: 0.1010 - val_loss: 2.2656 - val_categorical_accuracy: 0.1846\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.2159 - categorical_accuracy: 0.2063 - val_loss: 2.2176 - val_categorical_accuracy: 0.2007\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.1401 - categorical_accuracy: 0.2449 - val_loss: 2.1437 - val_categorical_accuracy: 0.2166\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.0755 - categorical_accuracy: 0.2560 - val_loss: 2.0810 - val_categorical_accuracy: 0.2309\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 103s 170ms/step - loss: 2.0229 - categorical_accuracy: 0.2672 - val_loss: 2.0384 - val_categorical_accuracy: 0.2450\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 1.9862 - categorical_accuracy: 0.2826 - val_loss: 2.0758 - val_categorical_accuracy: 0.2376\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.03      0.04       190\n",
            "         1.0       0.19      0.06      0.09       173\n",
            "         2.0       0.18      0.04      0.07       135\n",
            "         3.0       0.20      0.11      0.14       216\n",
            "         4.0       0.63      0.22      0.32      1036\n",
            "         5.0       0.08      0.41      0.13        76\n",
            "         6.0       0.39      0.78      0.52       195\n",
            "         7.0       0.14      0.06      0.09       290\n",
            "         8.0       0.15      0.29      0.19       139\n",
            "         9.0       0.16      0.57      0.25       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.22      0.26      0.19      2708\n",
            "weighted avg       0.36      0.24      0.23      2708\n",
            "\n",
            "0.2574134817155695\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_8/transformer/mask_emb:0', 'tfxl_net_model_8/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_8/transformer/mask_emb:0', 'tfxl_net_model_8/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_8/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_8/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 209s 318ms/step - loss: 1.9500 - categorical_accuracy: 0.3101 - val_loss: 2.0697 - val_categorical_accuracy: 0.2391\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.9482 - categorical_accuracy: 0.2952 - val_loss: 2.0646 - val_categorical_accuracy: 0.2435\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.9626 - categorical_accuracy: 0.2986 - val_loss: 2.0668 - val_categorical_accuracy: 0.2393\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.9450 - categorical_accuracy: 0.3079 - val_loss: 2.0785 - val_categorical_accuracy: 0.2351\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 1.9394 - categorical_accuracy: 0.3034 - val_loss: 2.0763 - val_categorical_accuracy: 0.2374\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.04      0.06       190\n",
            "         1.0       0.21      0.09      0.12       173\n",
            "         2.0       0.13      0.03      0.05       135\n",
            "         3.0       0.16      0.08      0.11       216\n",
            "         4.0       0.64      0.21      0.31      1036\n",
            "         5.0       0.07      0.39      0.12        76\n",
            "         6.0       0.39      0.80      0.52       195\n",
            "         7.0       0.13      0.06      0.08       290\n",
            "         8.0       0.14      0.26      0.18       139\n",
            "         9.0       0.16      0.56      0.25       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.22      0.25      0.18      2708\n",
            "weighted avg       0.36      0.24      0.23      2708\n",
            "\n",
            "0.25110808246047\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-07 drop_out_rate: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_9 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_9 (Global  (None, 768)         0           ['tfxl_net_model_9[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_9[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 128)          98432       ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_379 (Dropout)          (None, 128)          0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 32)           4128        ['dropout_379[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 116s 172ms/step - loss: 2.4658 - categorical_accuracy: 0.1271 - val_loss: 2.3107 - val_categorical_accuracy: 0.1235\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.2498 - categorical_accuracy: 0.1739 - val_loss: 2.2316 - val_categorical_accuracy: 0.1362\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.1765 - categorical_accuracy: 0.1870 - val_loss: 2.2240 - val_categorical_accuracy: 0.1550\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.0941 - categorical_accuracy: 0.2124 - val_loss: 2.1064 - val_categorical_accuracy: 0.1983\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0356 - categorical_accuracy: 0.2289 - val_loss: 2.0901 - val_categorical_accuracy: 0.2003\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0066 - categorical_accuracy: 0.2449 - val_loss: 2.0618 - val_categorical_accuracy: 0.2121\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.12      0.15       190\n",
            "         1.0       0.18      0.08      0.11       173\n",
            "         2.0       0.03      0.01      0.02       135\n",
            "         3.0       0.11      0.02      0.03       216\n",
            "         4.0       0.57      0.12      0.20      1036\n",
            "         5.0       0.09      0.28      0.13        76\n",
            "         6.0       0.29      0.85      0.43       195\n",
            "         7.0       0.16      0.19      0.17       290\n",
            "         8.0       0.11      0.15      0.13       139\n",
            "         9.0       0.14      0.46      0.21       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.19      0.23      0.16      2708\n",
            "weighted avg       0.31      0.20      0.18      2708\n",
            "\n",
            "0.22697545450509193\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_9/transformer/mask_emb:0', 'tfxl_net_model_9/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_9/transformer/mask_emb:0', 'tfxl_net_model_9/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_9/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_9/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 208s 316ms/step - loss: 2.0144 - categorical_accuracy: 0.2486 - val_loss: 2.0625 - val_categorical_accuracy: 0.2138\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.9736 - categorical_accuracy: 0.2621 - val_loss: 2.0540 - val_categorical_accuracy: 0.2171\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0013 - categorical_accuracy: 0.2373 - val_loss: 2.0562 - val_categorical_accuracy: 0.2119\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.9743 - categorical_accuracy: 0.2619 - val_loss: 2.0530 - val_categorical_accuracy: 0.2158\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 1.9695 - categorical_accuracy: 0.2549 - val_loss: 2.0598 - val_categorical_accuracy: 0.2141\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.20      0.13      0.15       190\n",
            "         1.0       0.24      0.12      0.16       173\n",
            "         2.0       0.07      0.04      0.06       135\n",
            "         3.0       0.09      0.01      0.02       216\n",
            "         4.0       0.58      0.12      0.20      1036\n",
            "         5.0       0.09      0.29      0.14        76\n",
            "         6.0       0.30      0.85      0.44       195\n",
            "         7.0       0.16      0.18      0.17       290\n",
            "         8.0       0.12      0.19      0.15       139\n",
            "         9.0       0.14      0.47      0.22       258\n",
            "\n",
            "    accuracy                           0.21      2708\n",
            "   macro avg       0.20      0.24      0.17      2708\n",
            "weighted avg       0.32      0.21      0.18      2708\n",
            "\n",
            "0.23926075911466627\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-07 drop_out_rate: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_10 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_10 (Globa  (None, 768)         0           ['tfxl_net_model_10[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 768)         3072        ['global_max_pooling1d_10[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 128)          98432       ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_417 (Dropout)          (None, 128)          0           ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 32)           4128        ['dropout_417[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 171ms/step - loss: 2.6057 - categorical_accuracy: 0.0866 - val_loss: 2.4976 - val_categorical_accuracy: 0.1089\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 2.2936 - categorical_accuracy: 0.1667 - val_loss: 2.2931 - val_categorical_accuracy: 0.1552\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 167ms/step - loss: 2.2148 - categorical_accuracy: 0.2063 - val_loss: 2.1476 - val_categorical_accuracy: 0.2072\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1472 - categorical_accuracy: 0.2305 - val_loss: 2.0821 - val_categorical_accuracy: 0.2411\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0907 - categorical_accuracy: 0.2570 - val_loss: 2.0976 - val_categorical_accuracy: 0.2435\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.0753 - categorical_accuracy: 0.2617 - val_loss: 2.0369 - val_categorical_accuracy: 0.2539\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.07      0.10       190\n",
            "         1.0       0.17      0.24      0.20       173\n",
            "         2.0       0.08      0.04      0.05       135\n",
            "         3.0       0.22      0.04      0.07       216\n",
            "         4.0       0.60      0.27      0.37      1036\n",
            "         5.0       0.10      0.21      0.13        76\n",
            "         6.0       0.24      0.90      0.37       195\n",
            "         7.0       0.15      0.07      0.10       290\n",
            "         8.0       0.07      0.06      0.07       139\n",
            "         9.0       0.16      0.40      0.23       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.19      0.23      0.17      2708\n",
            "weighted avg       0.33      0.25      0.24      2708\n",
            "\n",
            "0.2310109839347388\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_10/transformer/mask_emb:0', 'tfxl_net_model_10/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_10/transformer/mask_emb:0', 'tfxl_net_model_10/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_10/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_10/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 208s 316ms/step - loss: 2.0511 - categorical_accuracy: 0.2642 - val_loss: 2.0350 - val_categorical_accuracy: 0.2534\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 191s 313ms/step - loss: 2.0504 - categorical_accuracy: 0.2658 - val_loss: 2.0388 - val_categorical_accuracy: 0.2482\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 2.0361 - categorical_accuracy: 0.2646 - val_loss: 2.0300 - val_categorical_accuracy: 0.2522\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 313ms/step - loss: 2.0338 - categorical_accuracy: 0.2722 - val_loss: 2.0375 - val_categorical_accuracy: 0.2529\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.07      0.10       190\n",
            "         1.0       0.17      0.25      0.21       173\n",
            "         2.0       0.07      0.03      0.04       135\n",
            "         3.0       0.21      0.04      0.07       216\n",
            "         4.0       0.59      0.25      0.35      1036\n",
            "         5.0       0.09      0.21      0.13        76\n",
            "         6.0       0.24      0.91      0.37       195\n",
            "         7.0       0.13      0.06      0.08       290\n",
            "         8.0       0.10      0.09      0.09       139\n",
            "         9.0       0.17      0.43      0.24       258\n",
            "\n",
            "    accuracy                           0.24      2708\n",
            "   macro avg       0.19      0.23      0.17      2708\n",
            "weighted avg       0.32      0.24      0.23      2708\n",
            "\n",
            "0.23276834798608775\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-07 drop_out_rate: 0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_11 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_11 (Globa  (None, 768)         0           ['tfxl_net_model_11[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 768)         3072        ['global_max_pooling1d_11[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 128)          98432       ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_455 (Dropout)          (None, 128)          0           ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 32)           4128        ['dropout_455[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 115s 172ms/step - loss: 2.6113 - categorical_accuracy: 0.1443 - val_loss: 2.4353 - val_categorical_accuracy: 0.0975\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.3608 - categorical_accuracy: 0.1685 - val_loss: 2.3379 - val_categorical_accuracy: 0.1247\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.2401 - categorical_accuracy: 0.1853 - val_loss: 2.2465 - val_categorical_accuracy: 0.1448\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1915 - categorical_accuracy: 0.2014 - val_loss: 2.1848 - val_categorical_accuracy: 0.1663\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1504 - categorical_accuracy: 0.2032 - val_loss: 2.1455 - val_categorical_accuracy: 0.1772\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.1014 - categorical_accuracy: 0.2287 - val_loss: 2.1056 - val_categorical_accuracy: 0.1921\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.31      0.03      0.05       190\n",
            "         1.0       0.18      0.14      0.16       173\n",
            "         2.0       0.07      0.04      0.05       135\n",
            "         3.0       0.11      0.01      0.02       216\n",
            "         4.0       0.62      0.11      0.18      1036\n",
            "         5.0       0.06      0.22      0.10        76\n",
            "         6.0       0.21      0.93      0.34       195\n",
            "         7.0       0.13      0.14      0.13       290\n",
            "         8.0       0.07      0.05      0.06       139\n",
            "         9.0       0.16      0.45      0.24       258\n",
            "\n",
            "    accuracy                           0.19      2708\n",
            "   macro avg       0.19      0.21      0.13      2708\n",
            "weighted avg       0.33      0.19      0.15      2708\n",
            "\n",
            "0.21153083381142196\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_11/transformer/mask_emb:0', 'tfxl_net_model_11/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_11/transformer/mask_emb:0', 'tfxl_net_model_11/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_11/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_11/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 207s 316ms/step - loss: 2.0868 - categorical_accuracy: 0.2243 - val_loss: 2.0994 - val_categorical_accuracy: 0.1931\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0616 - categorical_accuracy: 0.2354 - val_loss: 2.0937 - val_categorical_accuracy: 0.1935\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 311ms/step - loss: 2.0695 - categorical_accuracy: 0.2282 - val_loss: 2.0944 - val_categorical_accuracy: 0.1951\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0863 - categorical_accuracy: 0.2291 - val_loss: 2.0998 - val_categorical_accuracy: 0.1966\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0828 - categorical_accuracy: 0.2274 - val_loss: 2.0972 - val_categorical_accuracy: 0.1926\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.0676 - categorical_accuracy: 0.2362 - val_loss: 2.0886 - val_categorical_accuracy: 0.1946\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.02      0.03       190\n",
            "         1.0       0.20      0.16      0.17       173\n",
            "         2.0       0.06      0.03      0.04       135\n",
            "         3.0       0.00      0.00      0.00       216\n",
            "         4.0       0.63      0.11      0.19      1036\n",
            "         5.0       0.08      0.30      0.13        76\n",
            "         6.0       0.22      0.94      0.35       195\n",
            "         7.0       0.14      0.16      0.15       290\n",
            "         8.0       0.08      0.05      0.06       139\n",
            "         9.0       0.16      0.47      0.24       258\n",
            "\n",
            "    accuracy                           0.20      2708\n",
            "   macro avg       0.17      0.22      0.14      2708\n",
            "weighted avg       0.32      0.20      0.16      2708\n",
            "\n",
            "0.22383298177238625\n",
            "----------------------------------------\n",
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  1e-07 drop_out_rate: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_12 (TFXLNetMode  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " l)                             last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_12 (Globa  (None, 768)         0           ['tfxl_net_model_12[0][0]']      \n",
            " lMaxPooling1D)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 768)         3072        ['global_max_pooling1d_12[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 128)          98432       ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_493 (Dropout)          (None, 128)          0           ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 32)           4128        ['dropout_493[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_25[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 116s 172ms/step - loss: 2.6373 - categorical_accuracy: 0.1215 - val_loss: 2.3249 - val_categorical_accuracy: 0.1242\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.4141 - categorical_accuracy: 0.1480 - val_loss: 2.2655 - val_categorical_accuracy: 0.1466\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 102s 168ms/step - loss: 2.2983 - categorical_accuracy: 0.1658 - val_loss: 2.2350 - val_categorical_accuracy: 0.1554\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.2667 - categorical_accuracy: 0.1810 - val_loss: 2.2203 - val_categorical_accuracy: 0.1663\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.1957 - categorical_accuracy: 0.1866 - val_loss: 2.1825 - val_categorical_accuracy: 0.1790\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 103s 169ms/step - loss: 2.1791 - categorical_accuracy: 0.1933 - val_loss: 2.1528 - val_categorical_accuracy: 0.1822\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.06      0.08       190\n",
            "         1.0       0.17      0.32      0.22       173\n",
            "         2.0       0.08      0.20      0.11       135\n",
            "         3.0       0.20      0.03      0.05       216\n",
            "         4.0       0.62      0.08      0.15      1036\n",
            "         5.0       0.06      0.14      0.09        76\n",
            "         6.0       0.21      0.88      0.34       195\n",
            "         7.0       0.15      0.01      0.01       290\n",
            "         8.0       0.07      0.09      0.08       139\n",
            "         9.0       0.17      0.38      0.24       258\n",
            "\n",
            "    accuracy                           0.18      2708\n",
            "   macro avg       0.18      0.22      0.14      2708\n",
            "weighted avg       0.33      0.18      0.14      2708\n",
            "\n",
            "0.21946376210705004\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_12/transformer/mask_emb:0', 'tfxl_net_model_12/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_12/transformer/mask_emb:0', 'tfxl_net_model_12/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_12/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_12/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 206s 316ms/step - loss: 2.1277 - categorical_accuracy: 0.2120 - val_loss: 2.1546 - val_categorical_accuracy: 0.1826\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.1578 - categorical_accuracy: 0.1913 - val_loss: 2.1524 - val_categorical_accuracy: 0.1814\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.1135 - categorical_accuracy: 0.2098 - val_loss: 2.1543 - val_categorical_accuracy: 0.1839\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.1190 - categorical_accuracy: 0.2094 - val_loss: 2.1499 - val_categorical_accuracy: 0.1836\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.1220 - categorical_accuracy: 0.2161 - val_loss: 2.1485 - val_categorical_accuracy: 0.1846\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 190s 312ms/step - loss: 2.1391 - categorical_accuracy: 0.2157 - val_loss: 2.1482 - val_categorical_accuracy: 0.1834\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.10      0.06      0.07       190\n",
            "         1.0       0.17      0.34      0.23       173\n",
            "         2.0       0.07      0.19      0.10       135\n",
            "         3.0       0.21      0.04      0.06       216\n",
            "         4.0       0.61      0.08      0.14      1036\n",
            "         5.0       0.07      0.17      0.10        76\n",
            "         6.0       0.23      0.90      0.36       195\n",
            "         7.0       0.12      0.01      0.01       290\n",
            "         8.0       0.10      0.11      0.10       139\n",
            "         9.0       0.18      0.40      0.25       258\n",
            "\n",
            "    accuracy                           0.18      2708\n",
            "   macro avg       0.19      0.23      0.14      2708\n",
            "weighted avg       0.32      0.18      0.14      2708\n",
            "\n",
            "0.22928009817336376\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### try dropout=0.1, 1e-4, 5e-7"
      ],
      "metadata": {
        "id": "OECOmt0YI9LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "\n",
        "drop_out_rates = [0.1]\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "#drop_out_rate = 0.5\n",
        "learning_rate_transfer_learnings = [1e-4]\n",
        "learning_rate_fine_tunings = [5e-7]\n",
        "\n",
        "for drop_out_rate in drop_out_rates:\n",
        "  for learning_rate_transfer_learning in learning_rate_transfer_learnings:\n",
        "    for learning_rate_fine_tuning in learning_rate_fine_tunings:\n",
        "      print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        "      , learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "      #step1\n",
        "      #bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "      xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "      input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "      mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "      embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "      X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "      X = tf.keras.layers.BatchNormalization()(X)\n",
        "      X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "      X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "      X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "      y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "      model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "      model1.layers[2].trainable = False\n",
        "      print(model1.summary())\n",
        "\n",
        "      #step2\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "      metrics = []\n",
        "      metrics.append(\n",
        "          tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "      model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "      #model2.summary() #Check trainable params increased.\n",
        "\n",
        "      #step3: transfer learning\n",
        "      early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "      history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "      #step4: predict\n",
        "      balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "      balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "      #step5: fine tune\n",
        "      print(\"Fine tuning---------------\")\n",
        "      model1.layers[2].trainable = True\n",
        "\n",
        "      # It's important to recompile your model after you make any changes\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "      metrics = []\n",
        "      metrics.append(\n",
        "          tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "      model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "      history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "      balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "      balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "      print(\"----------------------------------------\")\n",
        "      del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "13df26bf722541888d29fd53af1dfcd4",
            "ba53c0bf8c6e4343b46da600068017d1",
            "71badff5e63947f791f7f93318d2b8b9",
            "0327a4b06baf4612bd6bc5e1a3dbe6a8",
            "7f15bb64413047f48d5220bd7bd6a410",
            "ac3d3afaee484fd89015e3d33b09383d",
            "7423fbd767a9413d89af60aeb5309a7e",
            "a9426f08ff4241ecb26687f8cec9f79a",
            "a19c97d4c8184facb26b5d559c4ef686",
            "92f48867bfe2403284ae12545b36856b",
            "d9109a1d245e4c0e9ea5771c6da491c3"
          ]
        },
        "id": "_78Kvg0AJCzG",
        "outputId": "02fbcb44-a01f-497a-af9e-fbc272773cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  5e-07 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/539M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13df26bf722541888d29fd53af1dfcd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model (TFXLNetModel)  TFXLNetModelOutput(  116718336   ['input_ids[0][0]',              \n",
            "                                last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tfxl_net_model[0][0]']         \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 112s 165ms/step - loss: 2.3186 - categorical_accuracy: 0.1876 - val_loss: 2.2360 - val_categorical_accuracy: 0.1857\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 99s 162ms/step - loss: 2.1293 - categorical_accuracy: 0.2567 - val_loss: 2.0503 - val_categorical_accuracy: 0.2500\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 99s 162ms/step - loss: 2.0418 - categorical_accuracy: 0.2783 - val_loss: 2.0027 - val_categorical_accuracy: 0.2665\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 99s 162ms/step - loss: 2.0001 - categorical_accuracy: 0.2897 - val_loss: 1.9742 - val_categorical_accuracy: 0.2647\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 99s 163ms/step - loss: 1.9524 - categorical_accuracy: 0.2964 - val_loss: 1.9079 - val_categorical_accuracy: 0.2987\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 99s 162ms/step - loss: 1.9374 - categorical_accuracy: 0.3093 - val_loss: 1.8920 - val_categorical_accuracy: 0.2969\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.15      0.14       190\n",
            "         1.0       0.29      0.28      0.28       173\n",
            "         2.0       0.06      0.08      0.07       135\n",
            "         3.0       0.20      0.14      0.16       216\n",
            "         4.0       0.62      0.36      0.46      1036\n",
            "         5.0       0.22      0.22      0.22        76\n",
            "         6.0       0.43      0.84      0.57       195\n",
            "         7.0       0.18      0.11      0.14       290\n",
            "         8.0       0.16      0.09      0.11       139\n",
            "         9.0       0.19      0.48      0.27       258\n",
            "\n",
            "    accuracy                           0.31      2708\n",
            "   macro avg       0.25      0.28      0.24      2708\n",
            "weighted avg       0.37      0.31      0.31      2708\n",
            "\n",
            "0.27595252707362816\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 290s 453ms/step - loss: 1.8959 - categorical_accuracy: 0.3071 - val_loss: 1.8912 - val_categorical_accuracy: 0.2978\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 273s 449ms/step - loss: 1.8820 - categorical_accuracy: 0.3135 - val_loss: 1.9036 - val_categorical_accuracy: 0.2858\n",
            "Epoch 3/6\n",
            "115/609 [====>.........................] - ETA: 3:34 - loss: 1.8770 - categorical_accuracy: 0.3196"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "Y03wII_tq80K",
        "outputId": "b43471d9-e8cf-4c6d-d418-c692b4dcc9d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1d4e64b5f8db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbalanced_accuracies_fine_tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'balanced_accuracies_fine_tuning' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best parameters are 0.1, 1e-4, 5e-7"
      ],
      "metadata": {
        "id": "B-ZVTDealfoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fold1"
      ],
      "metadata": {
        "id": "aMmgGpVirxFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetLMHeadModel, XLNetTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[1]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "TEST_SIZE = len(split0['y_test'])\n",
        "print(\"TEST_SIZE:\", TEST_SIZE)\n",
        "SEQ_LEN=256\n",
        "SEQ_LEN2=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77b8753-4dd6-4b9b-f701-07bfae521dd7",
        "id": "3e3lb0zVdrZt"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST_SIZE: 2708\n",
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_accuracies_transfer_learning=[]\n",
        "balanced_accuracies_fine_tuning=[]\n",
        "McNemar={}"
      ],
      "metadata": {
        "id": "fG8MKqA1drZu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_out_rate = 0.1\n",
        "learning_rate_transfer_learning =1e-4\n",
        "learning_rate_fine_tuning =5e-7"
      ],
      "metadata": {
        "id": "xSWFhl83d0g3"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "balanced_accuracies_transfer_learning = []\n",
        "balanced_accuracies_fine_tuning = []\n",
        "\n",
        "\n",
        "print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        ", learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "#step1\n",
        "#bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model1.layers[2].trainable = False\n",
        "print(model1.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "#model2.summary() #Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "#step5: fine tune\n",
        "print(\"Fine tuning---------------\")\n",
        "model1.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "print(\"----------------------------------------\")\n",
        "del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "382ec56a6b094d59a999c0e8b796019c",
            "1ac4d2e3a5684dc29e06974d8876d69b",
            "135845e43d3d43ae9caff9852daebf3b",
            "daeaae5814e64f30b4c3880cd0c62999",
            "198912fdf1254559a27bca5731273fcc",
            "91c9f54d43314784a27a4d28cd90bbf5",
            "83297a873f764f4d97d03083d7101555",
            "f799a08cf41842e5aba9b99062624a62",
            "e642959dcce74b7b83d4fc4c15f83764",
            "f1416e0ee92f4c4bbbe954f0bf77a95e",
            "42cde8fa96a44c28a1ef62cf61a4d3c8"
          ]
        },
        "id": "svbzJvr8dxjv",
        "outputId": "eec5570d-2903-4423-e6d8-288db139d785"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  5e-07 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/539M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "382ec56a6b094d59a999c0e8b796019c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model (TFXLNetModel)  TFXLNetModelOutput(  116718336   ['input_ids[0][0]',              \n",
            "                                last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tfxl_net_model[0][0]']         \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 768)         3072        ['global_max_pooling1d[0][0]']   \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout_37 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           4128        ['dropout_37[0][0]']             \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 200s 304ms/step - loss: 2.4361 - categorical_accuracy: 0.1433 - val_loss: 2.2440 - val_categorical_accuracy: 0.1719\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.1797 - categorical_accuracy: 0.2147 - val_loss: 2.1013 - val_categorical_accuracy: 0.2114\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.0868 - categorical_accuracy: 0.2467 - val_loss: 2.0195 - val_categorical_accuracy: 0.2399\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.0430 - categorical_accuracy: 0.2586 - val_loss: 1.9841 - val_categorical_accuracy: 0.2436\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 182s 298ms/step - loss: 1.9894 - categorical_accuracy: 0.2694 - val_loss: 1.9963 - val_categorical_accuracy: 0.2509\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 182s 298ms/step - loss: 1.9521 - categorical_accuracy: 0.2883 - val_loss: 2.0029 - val_categorical_accuracy: 0.2463\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.13      0.38      0.20       191\n",
            "         1.0       0.19      0.25      0.22       173\n",
            "         2.0       0.05      0.06      0.06       134\n",
            "         3.0       0.14      0.09      0.11       216\n",
            "         4.0       0.65      0.19      0.30      1036\n",
            "         5.0       0.25      0.22      0.24        76\n",
            "         6.0       0.38      0.90      0.54       196\n",
            "         7.0       0.12      0.04      0.06       289\n",
            "         8.0       0.03      0.01      0.02       139\n",
            "         9.0       0.20      0.50      0.29       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.22      0.27      0.20      2708\n",
            "weighted avg       0.35      0.25      0.23      2708\n",
            "\n",
            "0.2663569655784262\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 520s 824ms/step - loss: 1.9311 - categorical_accuracy: 0.2944 - val_loss: 1.9999 - val_categorical_accuracy: 0.2472\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 498s 818ms/step - loss: 1.9092 - categorical_accuracy: 0.2971 - val_loss: 1.9867 - val_categorical_accuracy: 0.2491\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 498s 818ms/step - loss: 1.8977 - categorical_accuracy: 0.2926 - val_loss: 2.0099 - val_categorical_accuracy: 0.2491\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 498s 818ms/step - loss: 1.8793 - categorical_accuracy: 0.3049 - val_loss: 1.9867 - val_categorical_accuracy: 0.2528\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 498s 818ms/step - loss: 1.8662 - categorical_accuracy: 0.3143 - val_loss: 1.9775 - val_categorical_accuracy: 0.2665\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 498s 818ms/step - loss: 1.8466 - categorical_accuracy: 0.3125 - val_loss: 1.9847 - val_categorical_accuracy: 0.2610\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.14      0.37      0.20       191\n",
            "         1.0       0.17      0.31      0.22       173\n",
            "         2.0       0.07      0.07      0.07       134\n",
            "         3.0       0.14      0.09      0.11       216\n",
            "         4.0       0.68      0.16      0.25      1036\n",
            "         5.0       0.19      0.39      0.25        76\n",
            "         6.0       0.45      0.89      0.59       196\n",
            "         7.0       0.12      0.03      0.05       289\n",
            "         8.0       0.08      0.04      0.06       139\n",
            "         9.0       0.22      0.57      0.32       258\n",
            "\n",
            "    accuracy                           0.25      2708\n",
            "   macro avg       0.22      0.29      0.21      2708\n",
            "weighted avg       0.37      0.25      0.23      2708\n",
            "\n",
            "0.29261448658472894\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fold2"
      ],
      "metadata": {
        "id": "UWd2aFkLr4zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetLMHeadModel, XLNetTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[2]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "TEST_SIZE = len(split0['y_test'])\n",
        "print(\"TEST_SIZE:\", TEST_SIZE)\n",
        "SEQ_LEN=256\n",
        "SEQ_LEN2=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVvNlPezr4zi",
        "outputId": "dacd58b3-abb0-4b89-9263-fa6fa194bb4f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST_SIZE: 2708\n",
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "#balanced_accuracies_transfer_learning = []\n",
        "#balanced_accuracies_fine_tuning = []\n",
        "\n",
        "\n",
        "print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        ", learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "#step1\n",
        "#bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model1.layers[2].trainable = False\n",
        "print(model1.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "#model2.summary() #Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "#step5: fine tune\n",
        "print(\"Fine tuning---------------\")\n",
        "model1.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "print(\"----------------------------------------\")\n",
        "del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk_mxeGhr4zj",
        "outputId": "c263e82a-532b-4218-9df4-ffe9f2d248e9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  5e-07 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_1 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['tfxl_net_model_1[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_1[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 128)          98432       ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 128)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 32)           4128        ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 199s 304ms/step - loss: 2.3625 - categorical_accuracy: 0.1857 - val_loss: 2.5148 - val_categorical_accuracy: 0.1480\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.1534 - categorical_accuracy: 0.2314 - val_loss: 2.2427 - val_categorical_accuracy: 0.1756\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.0778 - categorical_accuracy: 0.2554 - val_loss: 2.1508 - val_categorical_accuracy: 0.1949\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.0148 - categorical_accuracy: 0.2787 - val_loss: 2.0812 - val_categorical_accuracy: 0.2086\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 1.9623 - categorical_accuracy: 0.2842 - val_loss: 1.9939 - val_categorical_accuracy: 0.2344\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 1.9339 - categorical_accuracy: 0.2973 - val_loss: 1.9733 - val_categorical_accuracy: 0.2399\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.20      0.19       191\n",
            "         1.0       0.25      0.19      0.22       172\n",
            "         2.0       0.07      0.04      0.05       134\n",
            "         3.0       0.13      0.06      0.09       216\n",
            "         4.0       0.60      0.22      0.32      1036\n",
            "         5.0       0.16      0.25      0.19        77\n",
            "         6.0       0.44      0.85      0.58       196\n",
            "         7.0       0.15      0.26      0.19       290\n",
            "         8.0       0.10      0.06      0.07       139\n",
            "         9.0       0.19      0.54      0.29       257\n",
            "\n",
            "    accuracy                           0.27      2708\n",
            "   macro avg       0.23      0.27      0.22      2708\n",
            "weighted avg       0.35      0.27      0.26      2708\n",
            "\n",
            "0.26763362864129914\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_1/transformer/mask_emb:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_1/transformer/mask_emb:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_1/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 520s 825ms/step - loss: 1.8954 - categorical_accuracy: 0.2958 - val_loss: 1.9573 - val_categorical_accuracy: 0.2463\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 498s 818ms/step - loss: 1.8885 - categorical_accuracy: 0.3025 - val_loss: 1.9610 - val_categorical_accuracy: 0.2592\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 498s 818ms/step - loss: 1.8634 - categorical_accuracy: 0.3041 - val_loss: 1.9486 - val_categorical_accuracy: 0.2656\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8508 - categorical_accuracy: 0.3058 - val_loss: 1.9694 - val_categorical_accuracy: 0.2574\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 503s 825ms/step - loss: 1.8451 - categorical_accuracy: 0.3035 - val_loss: 1.9488 - val_categorical_accuracy: 0.2638\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 498s 818ms/step - loss: 1.8204 - categorical_accuracy: 0.3110 - val_loss: 1.9384 - val_categorical_accuracy: 0.2638\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.17      0.25      0.20       191\n",
            "         1.0       0.26      0.28      0.27       172\n",
            "         2.0       0.09      0.05      0.07       134\n",
            "         3.0       0.12      0.06      0.08       216\n",
            "         4.0       0.64      0.22      0.33      1036\n",
            "         5.0       0.15      0.30      0.20        77\n",
            "         6.0       0.49      0.88      0.63       196\n",
            "         7.0       0.15      0.22      0.18       290\n",
            "         8.0       0.11      0.06      0.08       139\n",
            "         9.0       0.21      0.57      0.31       257\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.24      0.29      0.23      2708\n",
            "weighted avg       0.37      0.28      0.27      2708\n",
            "\n",
            "0.28901074881319105\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fold3"
      ],
      "metadata": {
        "id": "6W2nFmLMsC6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetLMHeadModel, XLNetTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[3]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "TEST_SIZE = len(split0['y_test'])\n",
        "print(\"TEST_SIZE:\", TEST_SIZE)\n",
        "SEQ_LEN=256\n",
        "SEQ_LEN2=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9CG8gkLsC6k",
        "outputId": "31700049-63c0-4306-a07b-c48c80208e7c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST_SIZE: 2708\n",
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "#balanced_accuracies_transfer_learning = []\n",
        "#balanced_accuracies_fine_tuning = []\n",
        "\n",
        "\n",
        "print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        ", learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "#step1\n",
        "#bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model1.layers[2].trainable = False\n",
        "print(model1.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "#model2.summary() #Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "#step5: fine tune\n",
        "print(\"Fine tuning---------------\")\n",
        "model1.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "print(\"----------------------------------------\")\n",
        "del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1etgdeeOsC6k",
        "outputId": "ed8a47b8-fb65-4219-a1a8-3d74c191409d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  5e-07 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_2 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_2 (Global  (None, 768)         0           ['tfxl_net_model_2[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_2[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          98432       ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_113 (Dropout)          (None, 128)          0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 32)           4128        ['dropout_113[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 199s 303ms/step - loss: 2.3721 - categorical_accuracy: 0.1461 - val_loss: 2.4237 - val_categorical_accuracy: 0.1590\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.1360 - categorical_accuracy: 0.2376 - val_loss: 2.1677 - val_categorical_accuracy: 0.2050\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.0622 - categorical_accuracy: 0.2713 - val_loss: 2.0665 - val_categorical_accuracy: 0.2344\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 2.0026 - categorical_accuracy: 0.2817 - val_loss: 2.0103 - val_categorical_accuracy: 0.2463\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 1.9572 - categorical_accuracy: 0.2935 - val_loss: 2.0371 - val_categorical_accuracy: 0.2298\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 182s 299ms/step - loss: 1.9261 - categorical_accuracy: 0.2992 - val_loss: 1.9502 - val_categorical_accuracy: 0.2711\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.27      0.20       191\n",
            "         1.0       0.14      0.12      0.13       172\n",
            "         2.0       0.07      0.10      0.08       134\n",
            "         3.0       0.17      0.11      0.13       216\n",
            "         4.0       0.61      0.28      0.38      1036\n",
            "         5.0       0.27      0.17      0.21        77\n",
            "         6.0       0.43      0.89      0.58       196\n",
            "         7.0       0.16      0.03      0.05       290\n",
            "         8.0       0.11      0.08      0.09       139\n",
            "         9.0       0.19      0.58      0.28       257\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.23      0.26      0.21      2708\n",
            "weighted avg       0.35      0.28      0.27      2708\n",
            "\n",
            "0.2628917129806431\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_2/transformer/mask_emb:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_2/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 520s 826ms/step - loss: 1.8937 - categorical_accuracy: 0.3092 - val_loss: 1.9539 - val_categorical_accuracy: 0.2757\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8684 - categorical_accuracy: 0.3106 - val_loss: 1.9393 - val_categorical_accuracy: 0.2840\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8487 - categorical_accuracy: 0.3135 - val_loss: 1.9279 - val_categorical_accuracy: 0.2904\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8356 - categorical_accuracy: 0.3187 - val_loss: 1.9102 - val_categorical_accuracy: 0.2767\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8288 - categorical_accuracy: 0.3177 - val_loss: 1.9261 - val_categorical_accuracy: 0.2812\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 498s 819ms/step - loss: 1.8136 - categorical_accuracy: 0.3185 - val_loss: 1.9067 - val_categorical_accuracy: 0.2858\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.16      0.35      0.22       191\n",
            "         1.0       0.18      0.21      0.20       172\n",
            "         2.0       0.07      0.08      0.07       134\n",
            "         3.0       0.17      0.16      0.16       216\n",
            "         4.0       0.63      0.24      0.35      1036\n",
            "         5.0       0.22      0.35      0.27        77\n",
            "         6.0       0.54      0.89      0.67       196\n",
            "         7.0       0.10      0.02      0.03       290\n",
            "         8.0       0.12      0.10      0.11       139\n",
            "         9.0       0.19      0.54      0.28       257\n",
            "\n",
            "    accuracy                           0.28      2708\n",
            "   macro avg       0.24      0.29      0.24      2708\n",
            "weighted avg       0.36      0.28      0.27      2708\n",
            "\n",
            "0.29319178013843417\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fold4"
      ],
      "metadata": {
        "id": "CLyESbgksHv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetLMHeadModel, XLNetTokenizer\n",
        "import numpy as np\n",
        "\n",
        "split0=splits[4]\n",
        "split0['X_train'] = prepare_lyrics(split0['X_train'] )\n",
        "split0['X_test'] = prepare_lyrics(split0['X_test'] )\n",
        "TEST_SIZE = len(split0['y_test'])\n",
        "print(\"TEST_SIZE:\", TEST_SIZE)\n",
        "SEQ_LEN=256\n",
        "SEQ_LEN2=256\n",
        "print(split0['X_train'].shape, split0['X_test'].shape)\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "Xids_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xmask_train = np.zeros((split0['X_train'].shape[0], SEQ_LEN))\n",
        "Xids_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "Xmask_test = np.zeros((split0['X_test'].shape[0], SEQ_LEN))\n",
        "\n",
        "for i, lyric in enumerate(split0['X_train']):\n",
        "  tokens = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\", add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_train[i,:], Xmask_train[i,:] = tokens['input_ids'], tokens['attention_mask']\n",
        "\n",
        "for i, lyric in enumerate(split0['X_test']):\n",
        "  tokens_test = tokenizer.encode_plus(lyric, max_length=SEQ_LEN, truncation =True, padding=\"max_length\"\n",
        "    , add_special_tokens = True, return_token_type_ids= False, return_attention_mask = True, return_tensors= 'tf')\n",
        "  Xids_test[i,:], Xmask_test[i,:] = tokens_test['input_ids'], tokens_test['attention_mask']\n",
        "\n",
        "print(\"Xids_train.shape, Xids_test.shape: \",Xids_train.shape, Xids_test.shape)\n",
        "\n",
        "labels_train = np.zeros((split0['y_train'].shape[0], 10))\n",
        "labels_train[ np.arange(split0['y_train'].shape[0]), split0['y_train'].values] =1\n",
        "labels_test = np.zeros((split0['y_test'].shape[0], 10))\n",
        "labels_test[ np.arange(split0['y_test'].shape[0]), split0['y_test'].values] =1\n",
        "\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices((Xids_train, Xmask_train, labels_train))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((Xids_test, Xmask_test, labels_test))\n",
        "\n",
        "dataset_train = dataset_train.map(map_func)\n",
        "dataset_test = dataset_test.map(map_func)\n",
        "dataset_train = dataset_train.shuffle(42).batch(16)\n",
        "\n",
        "train = dataset_train.take(round(DS_LEN*SPLIT))\n",
        "val = dataset_train.skip(round(DS_LEN*SPLIT))\n",
        "test = dataset_test.batch(16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT3XwBTrsHv6",
        "outputId": "bbbea89f-294e-4bf7-d835-cf3f3765a881"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST_SIZE: 2708\n",
            "(10832,) (2708,)\n",
            "Xids_train.shape, Xids_test.shape:  (10832, 256) (2708, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "#balanced_accuracies_transfer_learning = []\n",
        "#balanced_accuracies_fine_tuning = []\n",
        "\n",
        "\n",
        "print(\"learning_rate_transfer_learning: \",learning_rate_transfer_learning, \"learning_rate_fine_tuning: \"\n",
        ", learning_rate_fine_tuning, \"drop_out_rate:\", drop_out_rate)\n",
        "#step1\n",
        "#bert_base = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "xlnet_base = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "input_ids = tf.keras.layers.Input(shape=(SEQ_LEN2,), name= 'input_ids', dtype='int32')\n",
        "mask = tf.keras.layers.Input(shape=(SEQ_LEN2,), name='attention_mask')\n",
        "\n",
        "embeddings = xlnet_base(input_ids, attention_mask= mask)[0]\n",
        "X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "X = tf.keras.layers.BatchNormalization()(X)\n",
        "X = tf.keras.layers.Dense(128, activation = 'relu')(X)\n",
        "X = tf.keras.layers.Dropout(drop_out_rate)(X)\n",
        "X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "y= tf.keras.layers.Dense(10, activation = 'softmax' , name= 'outputs')(X)\n",
        "\n",
        "model1 = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model1.layers[2].trainable = False\n",
        "print(model1.summary())\n",
        "\n",
        "#step2\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_transfer_learning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "#model2.summary() #Check trainable params increased.\n",
        "\n",
        "#step3: transfer learning\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', patience=3)\n",
        "history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "\n",
        "#step4: predict\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, False, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_transfer_learning.append( balanced_acc )\n",
        "\n",
        "#step5: fine tune\n",
        "print(\"Fine tuning---------------\")\n",
        "model1.layers[2].trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate_fine_tuning)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')#from_logits=False,label_smoothing=0.0,axis=-1,\n",
        "metrics = []\n",
        "metrics.append(\n",
        "    tf.metrics.CategoricalAccuracy(name='categorical_accuracy', dtype=None))\n",
        "model1.compile(optimizer=optimizer, loss= loss, metrics=metrics)\n",
        "\n",
        "history = model1.fit(train, validation_data=val, epochs=6, class_weight=my_weight2 ,callbacks=[ early_stopping])\n",
        "balanced_acc, McNemar=get_balanced_accuracy(model1, McNemar, True, drop_out_rate,learning_rate_transfer_learning, learning_rate_fine_tuning )\n",
        "balanced_accuracies_fine_tuning.append( balanced_acc )\n",
        "print(\"----------------------------------------\")\n",
        "del(model1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQK0HnYssHv6",
        "outputId": "ad674395-7ef7-4fda-9ed9-d4af66892682"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate_transfer_learning:  0.0001 learning_rate_fine_tuning:  5e-07 drop_out_rate: 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tfxl_net_model_3 (TFXLNetModel  TFXLNetModelOutput(  116718336  ['input_ids[0][0]',              \n",
            " )                              last_hidden_state=(               'attention_mask[0][0]']         \n",
            "                                None, 256, 768),                                                  \n",
            "                                 mems=((256, None,                                                \n",
            "                                768),                                                             \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768),                                                \n",
            "                                 (256, None, 768)),                                               \n",
            "                                 hidden_states=None                                               \n",
            "                                , attentions=None)                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_3 (Global  (None, 768)         0           ['tfxl_net_model_3[0][0]']       \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 768)         3072        ['global_max_pooling1d_3[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 128)          98432       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_151 (Dropout)          (None, 128)          0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 32)           4128        ['dropout_151[0][0]']            \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 10)           330         ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 116,824,298\n",
            "Trainable params: 104,426\n",
            "Non-trainable params: 116,719,872\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/6\n",
            "609/609 [==============================] - 199s 303ms/step - loss: 2.3545 - categorical_accuracy: 0.1703 - val_loss: 2.3396 - val_categorical_accuracy: 0.1618\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 182s 298ms/step - loss: 2.1648 - categorical_accuracy: 0.2524 - val_loss: 2.1717 - val_categorical_accuracy: 0.2353\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 182s 298ms/step - loss: 2.0824 - categorical_accuracy: 0.2820 - val_loss: 2.0799 - val_categorical_accuracy: 0.2794\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 182s 298ms/step - loss: 2.0279 - categorical_accuracy: 0.2968 - val_loss: 2.0029 - val_categorical_accuracy: 0.2978\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 182s 298ms/step - loss: 1.9863 - categorical_accuracy: 0.3078 - val_loss: 1.9776 - val_categorical_accuracy: 0.3042\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 182s 298ms/step - loss: 1.9590 - categorical_accuracy: 0.3155 - val_loss: 1.9962 - val_categorical_accuracy: 0.2794\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.30      0.20       190\n",
            "         1.0       0.19      0.32      0.24       173\n",
            "         2.0       0.08      0.13      0.10       135\n",
            "         3.0       0.16      0.18      0.17       217\n",
            "         4.0       0.67      0.29      0.41      1035\n",
            "         5.0       0.20      0.32      0.24        76\n",
            "         6.0       0.51      0.86      0.64       195\n",
            "         7.0       0.09      0.03      0.05       290\n",
            "         8.0       0.09      0.04      0.06       139\n",
            "         9.0       0.22      0.40      0.28       258\n",
            "\n",
            "    accuracy                           0.29      2708\n",
            "   macro avg       0.23      0.29      0.24      2708\n",
            "weighted avg       0.37      0.29      0.29      2708\n",
            "\n",
            "0.287910255353114\n",
            "Fine tuning---------------\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_3/transformer/mask_emb:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model_3/transformer/mask_emb:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model_3/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609/609 [==============================] - 520s 826ms/step - loss: 1.9117 - categorical_accuracy: 0.3163 - val_loss: 1.9945 - val_categorical_accuracy: 0.2849\n",
            "Epoch 2/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.9042 - categorical_accuracy: 0.3229 - val_loss: 1.9825 - val_categorical_accuracy: 0.2840\n",
            "Epoch 3/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8897 - categorical_accuracy: 0.3230 - val_loss: 1.9848 - val_categorical_accuracy: 0.2932\n",
            "Epoch 4/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8791 - categorical_accuracy: 0.3195 - val_loss: 1.9979 - val_categorical_accuracy: 0.2868\n",
            "Epoch 5/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8518 - categorical_accuracy: 0.3347 - val_loss: 1.9938 - val_categorical_accuracy: 0.2904\n",
            "Epoch 6/6\n",
            "609/609 [==============================] - 499s 819ms/step - loss: 1.8460 - categorical_accuracy: 0.3344 - val_loss: 1.9675 - val_categorical_accuracy: 0.2941\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.15      0.31      0.20       190\n",
            "         1.0       0.20      0.38      0.26       173\n",
            "         2.0       0.08      0.13      0.10       135\n",
            "         3.0       0.20      0.19      0.19       217\n",
            "         4.0       0.64      0.29      0.40      1035\n",
            "         5.0       0.17      0.50      0.25        76\n",
            "         6.0       0.56      0.87      0.68       195\n",
            "         7.0       0.12      0.04      0.06       290\n",
            "         8.0       0.12      0.08      0.10       139\n",
            "         9.0       0.22      0.33      0.27       258\n",
            "\n",
            "    accuracy                           0.30      2708\n",
            "   macro avg       0.25      0.31      0.25      2708\n",
            "weighted avg       0.37      0.30      0.30      2708\n",
            "\n",
            "0.3111991904923318\n",
            "----------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DWL5DlwVTHgV",
        "hWxfNJqYBfjD",
        "nONmunMa_h7T",
        "hb0KcNXhbUSN",
        "CLARPbncyjEw",
        "OECOmt0YI9LX"
      ],
      "machine_shape": "hm",
      "name": "week15_XLnet_baseline_keras_256.ipynb",
      "provenance": [],
      "background_execution": "on",
      "mount_file_id": "1Hd43OxBq1loj_RyqJC9g5fUievYbVF5l",
      "authorship_tag": "ABX9TyNXyXWK3e9vR9Ep2C4uvgOH",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42f4332cc6fd41efabceca28cf3fb621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67f4d6fc8c95497a9e0d573cb4e59602",
              "IPY_MODEL_5b20223e1557405bbb44f67e79a473cb",
              "IPY_MODEL_eb7eec523f7d4c748cd5eff30591214b"
            ],
            "layout": "IPY_MODEL_d67c1d03efd94a9d9e4cebdb328d9132"
          }
        },
        "67f4d6fc8c95497a9e0d573cb4e59602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc00b70cab304efda04f01db28ff1a0d",
            "placeholder": "​",
            "style": "IPY_MODEL_3f6b0ec6ada64353b3a44bceda5de3cf",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "5b20223e1557405bbb44f67e79a473cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38745d83f48749aca4a7937d56c8fc28",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bc7bd47e3254236ad10cf858cf71e08",
            "value": 798011
          }
        },
        "eb7eec523f7d4c748cd5eff30591214b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c3922a9067940f8818f3d66d23f0f66",
            "placeholder": "​",
            "style": "IPY_MODEL_6c673dfc9263460095a6db511e45f12d",
            "value": " 779k/779k [00:00&lt;00:00, 2.04MB/s]"
          }
        },
        "d67c1d03efd94a9d9e4cebdb328d9132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc00b70cab304efda04f01db28ff1a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6b0ec6ada64353b3a44bceda5de3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38745d83f48749aca4a7937d56c8fc28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc7bd47e3254236ad10cf858cf71e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c3922a9067940f8818f3d66d23f0f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c673dfc9263460095a6db511e45f12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2c999450bd54d9496426c1c1df959ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b3319c9d71f4dc7b12e028b3e220ecc",
              "IPY_MODEL_4529b585c3bf4268be47b8cf746b3e51",
              "IPY_MODEL_b73fdde92f164c9593b4962b0c180d94"
            ],
            "layout": "IPY_MODEL_ee6e50199dfd4dc39382888295a7c089"
          }
        },
        "3b3319c9d71f4dc7b12e028b3e220ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d2b7171620c4f93979f8232140d4672",
            "placeholder": "​",
            "style": "IPY_MODEL_863a645cf22640abbaaef2dc762b2258",
            "value": "Downloading config.json: 100%"
          }
        },
        "4529b585c3bf4268be47b8cf746b3e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38f0d5991a6429c95fdcc5b38ced72d",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93a6278ed1e041bdb3f93ff6868257c4",
            "value": 760
          }
        },
        "b73fdde92f164c9593b4962b0c180d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ddbd37d030544d7b3c11b9c74625d37",
            "placeholder": "​",
            "style": "IPY_MODEL_29cda64bb9b342459bc67a3e38887277",
            "value": " 760/760 [00:00&lt;00:00, 19.6kB/s]"
          }
        },
        "ee6e50199dfd4dc39382888295a7c089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d2b7171620c4f93979f8232140d4672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863a645cf22640abbaaef2dc762b2258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f38f0d5991a6429c95fdcc5b38ced72d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a6278ed1e041bdb3f93ff6868257c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ddbd37d030544d7b3c11b9c74625d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cda64bb9b342459bc67a3e38887277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c992a06f792b4d158747c636b390f648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c78dff24c254be992f0a1d2f51ae375",
              "IPY_MODEL_33aa1b0d7c4d47ed90b01974b38ce121",
              "IPY_MODEL_7261064cb3ec46269b336e08d8b59962"
            ],
            "layout": "IPY_MODEL_7987c66c7fb04e9c9f83fcad09efc069"
          }
        },
        "0c78dff24c254be992f0a1d2f51ae375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8513e843b4741c49b92b46178e6129f",
            "placeholder": "​",
            "style": "IPY_MODEL_5b9c80d47cbe44babef162f7e25348f5",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "33aa1b0d7c4d47ed90b01974b38ce121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36069839ef8a4db6a80bb77da38fd8b2",
            "max": 565485600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66fbd7f7f7e74d72ae5317829a1968c9",
            "value": 565485600
          }
        },
        "7261064cb3ec46269b336e08d8b59962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_408a92e9d6a94570a50961ca51d4e46f",
            "placeholder": "​",
            "style": "IPY_MODEL_d28abc35c7e2438e803f8bd1fc07967b",
            "value": " 539M/539M [00:08&lt;00:00, 65.1MB/s]"
          }
        },
        "7987c66c7fb04e9c9f83fcad09efc069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8513e843b4741c49b92b46178e6129f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9c80d47cbe44babef162f7e25348f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36069839ef8a4db6a80bb77da38fd8b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66fbd7f7f7e74d72ae5317829a1968c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "408a92e9d6a94570a50961ca51d4e46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d28abc35c7e2438e803f8bd1fc07967b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13df26bf722541888d29fd53af1dfcd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba53c0bf8c6e4343b46da600068017d1",
              "IPY_MODEL_71badff5e63947f791f7f93318d2b8b9",
              "IPY_MODEL_0327a4b06baf4612bd6bc5e1a3dbe6a8"
            ],
            "layout": "IPY_MODEL_7f15bb64413047f48d5220bd7bd6a410"
          }
        },
        "ba53c0bf8c6e4343b46da600068017d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac3d3afaee484fd89015e3d33b09383d",
            "placeholder": "​",
            "style": "IPY_MODEL_7423fbd767a9413d89af60aeb5309a7e",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "71badff5e63947f791f7f93318d2b8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9426f08ff4241ecb26687f8cec9f79a",
            "max": 565485600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a19c97d4c8184facb26b5d559c4ef686",
            "value": 565485600
          }
        },
        "0327a4b06baf4612bd6bc5e1a3dbe6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f48867bfe2403284ae12545b36856b",
            "placeholder": "​",
            "style": "IPY_MODEL_d9109a1d245e4c0e9ea5771c6da491c3",
            "value": " 539M/539M [00:08&lt;00:00, 66.9MB/s]"
          }
        },
        "7f15bb64413047f48d5220bd7bd6a410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac3d3afaee484fd89015e3d33b09383d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7423fbd767a9413d89af60aeb5309a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9426f08ff4241ecb26687f8cec9f79a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19c97d4c8184facb26b5d559c4ef686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92f48867bfe2403284ae12545b36856b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9109a1d245e4c0e9ea5771c6da491c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "382ec56a6b094d59a999c0e8b796019c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ac4d2e3a5684dc29e06974d8876d69b",
              "IPY_MODEL_135845e43d3d43ae9caff9852daebf3b",
              "IPY_MODEL_daeaae5814e64f30b4c3880cd0c62999"
            ],
            "layout": "IPY_MODEL_198912fdf1254559a27bca5731273fcc"
          }
        },
        "1ac4d2e3a5684dc29e06974d8876d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91c9f54d43314784a27a4d28cd90bbf5",
            "placeholder": "​",
            "style": "IPY_MODEL_83297a873f764f4d97d03083d7101555",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "135845e43d3d43ae9caff9852daebf3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f799a08cf41842e5aba9b99062624a62",
            "max": 565485600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e642959dcce74b7b83d4fc4c15f83764",
            "value": 565485600
          }
        },
        "daeaae5814e64f30b4c3880cd0c62999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1416e0ee92f4c4bbbe954f0bf77a95e",
            "placeholder": "​",
            "style": "IPY_MODEL_42cde8fa96a44c28a1ef62cf61a4d3c8",
            "value": " 539M/539M [00:13&lt;00:00, 43.2MB/s]"
          }
        },
        "198912fdf1254559a27bca5731273fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c9f54d43314784a27a4d28cd90bbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83297a873f764f4d97d03083d7101555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f799a08cf41842e5aba9b99062624a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e642959dcce74b7b83d4fc4c15f83764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1416e0ee92f4c4bbbe954f0bf77a95e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42cde8fa96a44c28a1ef62cf61a4d3c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
